
> [!NOTE]
> Documentation auto-generated by [ai-docs.](https://github.com/connor-john/ai-docs)

I'll create comprehensive documentation for this module. Let's break it down into sections:

# Module Overview

This module implements a system for composable and chainable runnable components in Python, with support for both synchronous and asynchronous execution patterns. The core components are:

- `RunnableCallable`: A simplified version of RunnableLambda that handles both sync and async functions
- `RunnableSeq`: A simpler version of RunnableSequence for chaining operations
- Helper functions for type checking and coercion of runnables

## Key Features
- Support for both sync and async execution
- Stream processing capabilities
- Configurable execution context
- Callback and tracing support
- Type-safe implementations
- Chainable operations using | operator

## Dependencies
```toml
[dependencies]
langchain-core = ">=0.1.0"
typing-extensions = ">=4.5.0"
```

# Installation and Setup

```bash
pip install langchain-core typing-extensions
```

# Usage Guide

## Basic Usage

```python
from langgraph.runnables import RunnableCallable, RunnableSeq

# Create a simple sync function runnable
def add_one(x: int) -> int:
    return x + 1

add_one_runnable = RunnableCallable(add_one)

# Create an async function runnable
async def multiply_two(x: int) -> int:
    return x * 2

multiply_two_runnable = RunnableCallable(None, multiply_two)

# Chain operations
pipeline = RunnableSeq(add_one_runnable, multiply_two_runnable)

# Execute synchronously
result = pipeline.invoke(5)  # Returns 12 ((5 + 1) * 2)

# Execute asynchronously
result = await pipeline.ainvoke(5)
```

## Streaming Example

```python
async def number_stream(start: int):
    for i in range(start, start + 5):
        yield i
        await asyncio.sleep(0.1)

async def process_stream():
    stream = RunnableCallable(None, number_stream)
    async for number in stream.astream(1):
        print(number)
```

# Testing Guide

## Test Cases

### 1. Basic Runnable Tests

```python
import pytest
from langgraph.runnables import RunnableCallable, RunnableSeq

def test_sync_runnable():
    def add_one(x: int) -> int:
        return x + 1

    runnable = RunnableCallable(add_one)
    result = runnable.invoke(1)
    assert result == 2

@pytest.mark.asyncio
async def test_async_runnable():
    async def add_one(x: int) -> int:
        return x + 1

    runnable = RunnableCallable(None, add_one)
    result = await runnable.ainvoke(1)
    assert result == 2
```

### 2. Sequence Tests

```python
@pytest.mark.asyncio
async def test_runnable_sequence():
    def step1(x: int) -> int:
        return x + 1

    async def step2(x: int) -> int:
        return x * 2

    pipeline = RunnableSeq(
        RunnableCallable(step1),
        RunnableCallable(None, step2)
    )

    result = await pipeline.ainvoke(5)
    assert result == 12  # (5 + 1) * 2
```

### 3. Streaming Tests

```python
@pytest.mark.asyncio
async def test_stream_processing():
    async def number_generator(start: int):
        for i in range(start, start + 3):
            yield i

    async def double_numbers(x: int):
        return x * 2

    gen = RunnableCallable(None, number_generator)
    doubler = RunnableCallable(None, double_numbers)
    pipeline = RunnableSeq(gen, doubler)

    results = []
    async for number in pipeline.astream(1):
        results.append(number)

    assert results == [2, 4, 6]
```

### 4. Error Handling Tests

```python
def test_runnable_error_handling():
    def failing_function(x: int) -> int:
        raise ValueError("Test error")

    runnable = RunnableCallable(failing_function)

    with pytest.raises(ValueError) as exc_info:
        runnable.invoke(1)
    assert str(exc_info.value) == "Test error"
```

### 5. Configuration Tests

```python
from typing import Optional
from langchain_core.runnables import RunnableConfig

def test_runnable_with_config():
    def func_with_config(x: int, config: Optional[RunnableConfig] = None) -> int:
        return x + (config.get("add", 0) if config else 0)

    runnable = RunnableCallable(func_with_config)
    result = runnable.invoke(1, {"add": 2})
    assert result == 3
```

## Test Fixtures

```python
@pytest.fixture
def basic_pipeline():
    def step1(x: int) -> int:
        return x + 1

    def step2(x: int) -> int:
        return x * 2

    return RunnableSeq(
        RunnableCallable(step1),
        RunnableCallable(step2)
    )

@pytest.fixture
async def async_pipeline():
    async def step1(x: int) -> int:
        return x + 1

    async def step2(x: int) -> int:
        return x * 2

    return RunnableSeq(
        RunnableCallable(None, step1),
        RunnableCallable(None, step2)
    )
```

## Performance Testing

```python
import time
import asyncio

@pytest.mark.benchmark
async def test_pipeline_performance(benchmark):
    async def expensive_operation(x: int) -> int:
        await asyncio.sleep(0.1)
        return x * 2

    pipeline = RunnableSeq(
        RunnableCallable(None, expensive_operation),
        RunnableCallable(None, expensive_operation)
    )

    start = time.perf_counter()
    result = await pipeline.ainvoke(1)
    duration = time.perf_counter() - start

    assert duration < 0.25  # Should complete in less than 250ms
```

# Best Practices

1. Always provide type hints for your functions
2. Use async functions when dealing with I/O operations
3. Implement proper error handling in your runnables
4. Use meaningful names for your runnables
5. Keep functions focused and single-purpose
6. Test both sync and async paths
7. Consider memory usage when working with streams

This module provides a powerful foundation for building composable pipelines with both synchronous and asynchronous execution capabilities. The test suite ensures reliability and proper behavior across different usage patterns.
