
> [!NOTE]
> Documentation auto-generated by [ai-docs.](https://github.com/connor-john/ai-docs)

I'll create comprehensive documentation and testing examples for the ValidationNode module.

# ValidationNode Module Documentation

## Module Overview

The ValidationNode module provides a validation layer for tool calls in LangChain graphs. It ensures that AI model outputs conform to predefined Pydantic schemas before tool execution.

### Key Features
- Schema validation for tool calls
- Support for multiple schema types (Pydantic BaseModel, BaseTool, callable functions)
- Parallel validation of multiple tool calls
- Custom error formatting
- Integration with both StateGraph and MessageGraph

### Dependencies
- langchain-core
- pydantic (v1 and v2 compatible)
- langgraph

## Installation and Setup

```bash
pip install langchain-core pydantic langgraph
```

Required Dependencies:
- langchain-core>=0.1.0
- pydantic>=2.0.0
- langgraph>=0.0.3

## Usage Guide

### Basic Usage

```python
from langgraph.prebuilt import ValidationNode
from pydantic import BaseModel

# Define a schema
class NumberSelection(BaseModel):
    number: int
    reason: str

    class Config:
        extra = "forbid"

# Create validation node
validator = ValidationNode(
    schemas=[NumberSelection],
    name="number_validator"
)
```

### Integration with StateGraph

```python
from langgraph.graph import StateGraph
from typing import TypedDict, Annotated
from langgraph.graph.message import add_messages

class State(TypedDict):
    messages: Annotated[list, add_messages]

# Create graph
graph = StateGraph(State)
graph.add_node("validation", ValidationNode([NumberSelection]))
```

## Testing Guide

### Test Cases

Here's a comprehensive test suite for the ValidationNode module:

```python
# test_validation_node.py
from __future__ import annotations

import pytest
from typing import Generator
from pydantic import BaseModel, validator
from langchain_core.messages import AIMessage, ToolMessage
from langgraph.prebuilt import ValidationNode

class TestSchema(BaseModel):
    value: int

    @validator("value")
    def validate_value(cls, v: int) -> int:
        if v < 0:
            raise ValueError("Value must be positive")
        return v

@pytest.fixture
def basic_schema() -> type[BaseModel]:
    """Provide test schema."""
    return TestSchema

@pytest.fixture
def valid_message() -> Generator[AIMessage, None, None]:
    """Provide valid test message."""
    message = AIMessage(
        content="",
        tool_calls=[{
            "id": "test_id",
            "name": "TestSchema",
            "type": "tool_use",
            "args": {"value": 42}
        }]
    )
    yield message

@pytest.fixture
def invalid_message() -> Generator[AIMessage, None, None]:
    """Provide invalid test message."""
    message = AIMessage(
        content="",
        tool_calls=[{
            "id": "test_id",
            "name": "TestSchema",
            "type": "tool_use",
            "args": {"value": -1}
        }]
    )
    yield message

def test_validation_success(
    basic_schema: type[BaseModel],
    valid_message: AIMessage
) -> None:
    """Test successful validation."""
    validator = ValidationNode([basic_schema])
    result = validator.invoke([valid_message])

    assert isinstance(result, list)
    assert len(result) == 1
    assert isinstance(result[0], ToolMessage)
    assert not result[0].additional_kwargs.get("is_error")
    assert "42" in result[0].content

def test_validation_failure(
    basic_schema: type[BaseModel],
    invalid_message: AIMessage
) -> None:
    """Test validation failure."""
    validator = ValidationNode([basic_schema])
    result = validator.invoke([invalid_message])

    assert isinstance(result, list)
    assert len(result) == 1
    assert isinstance(result[0], ToolMessage)
    assert result[0].additional_kwargs.get("is_error")
    assert "Value must be positive" in result[0].content

@pytest.mark.asyncio
async def test_async_validation(
    basic_schema: type[BaseModel],
    valid_message: AIMessage
) -> None:
    """Test async validation."""
    validator = ValidationNode([basic_schema])
    result = await validator.ainvoke([valid_message])

    assert isinstance(result, list)
    assert len(result) == 1
    assert isinstance(result[0], ToolMessage)

def test_multiple_tool_calls(
    basic_schema: type[BaseModel]
) -> None:
    """Test handling multiple tool calls."""
    message = AIMessage(
        content="",
        tool_calls=[
            {
                "id": "test_1",
                "name": "TestSchema",
                "type": "tool_use",
                "args": {"value": 1}
            },
            {
                "id": "test_2",
                "name": "TestSchema",
                "type": "tool_use",
                "args": {"value": 2}
            }
        ]
    )
    validator = ValidationNode([basic_schema])
    result = validator.invoke([message])

    assert isinstance(result, list)
    assert len(result) == 2
    assert all(isinstance(r, ToolMessage) for r in result)

def test_custom_error_formatting(
    basic_schema: type[BaseModel],
    invalid_message: AIMessage
) -> None:
    """Test custom error formatting."""
    def custom_format(error: BaseException, call: dict, schema: type[BaseModel]) -> str:
        return "Custom error: " + str(error)

    validator = ValidationNode(
        [basic_schema],
        format_error=custom_format
    )
    result = validator.invoke([invalid_message])

    assert "Custom error" in result[0].content

```

### Test Categories

1. Basic Validation
   - Success cases
   - Failure cases
   - Schema conformance

2. Error Handling
   - Custom error formatting
   - Invalid schema types
   - Missing schemas

3. Integration Tests
   - StateGraph integration
   - MessageGraph integration
   - Multi-tool validation

4. Performance Tests
   - Multiple parallel validations
   - Large payload handling

## Best Practices

1. Schema Definition
```python
class ValidSchema(BaseModel):
    """Define schemas with clear validation rules."""
    field: int

    @validator("field")
    def validate_field(cls, v: int) -> int:
        if not (0 <= v <= 100):
            raise ValueError("Value must be between 0 and 100")
        return v
```

2. Error Handling
```python
def custom_error_formatter(
    error: BaseException,
    call: dict,
    schema: type[BaseModel]
) -> str:
    """Implement custom error formatting for clear feedback."""
    return f"Validation failed for {call['name']}: {str(error)}"
```

## Debugging and Troubleshooting

Common issues and solutions:

1. Schema Mismatch
```python
# Problem: Schema doesn't match tool call args
# Solution: Print schema and incoming data
print(f"Schema: {schema.schema()}")
print(f"Input data: {call['args']}")
```

2. Invalid Tool Names
```python
# Problem: Tool name not found in schemas
# Solution: Verify schema registration
print(f"Available schemas: {validator.schemas_by_name.keys()}")
```

3. Performance Issues
```python
# Problem: Slow validation for many tool calls
# Solution: Use async validation with proper executor configuration
config = {"executor": "thread_pool"}
await validator.ainvoke(messages, config=config)
```
