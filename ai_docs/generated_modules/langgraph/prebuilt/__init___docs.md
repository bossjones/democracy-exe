
> [!NOTE]
> Documentation auto-generated by [ai-docs.](https://github.com/connor-john/ai-docs)

I'll create comprehensive documentation and testing examples for the langgraph.prebuilt module.

# langgraph.prebuilt Documentation

## Module Overview

The `langgraph.prebuilt` module provides a high-level API for creating and managing AI agents and tools in a workflow system. It simplifies the implementation of ReAct (Reasoning and Acting) agents, tool execution, and validation workflows.

Key Features:
- ReAct agent creation and management
- Tool execution framework
- State injection and management
- Tool validation and verification
- Conditional tool execution flows

Dependencies:
- Python 3.8+
- langchain
- pydantic
- typing-extensions

## Installation and Setup

```bash
pip install langgraph
```

Required dependencies:
```
langchain>=0.0.300
pydantic>=2.0.0
typing-extensions>=4.5.0
```

## Usage Guide

### 1. Creating a ReAct Agent

```python
from langgraph.prebuilt.chat_agent_executor import create_react_agent
from langchain_core.language_models import ChatOpenAI

# Initialize the language model
llm = ChatOpenAI(temperature=0)

# Define tools
tools = [
    {
        "name": "calculator",
        "description": "Useful for performing calculations",
        "func": lambda x: eval(x)
    }
]

# Create the agent
agent = create_react_agent(llm, tools)
```

### 2. Tool Execution

```python
from langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation

# Define a tool executor
tools = {
    "calculator": lambda x: eval(x)
}
executor = ToolExecutor(tools)

# Create a tool invocation
invocation = ToolInvocation(
    tool_name="calculator",
    tool_input="2 + 2"
)

# Execute the tool
result = executor.execute(invocation)
```

### 3. Tool Node Implementation

```python
from langgraph.prebuilt.tool_node import ToolNode, InjectedState

# Define a tool node
class CalculatorNode(ToolNode):
    def __init__(self):
        super().__init__()
        self.state = InjectedState()

    async def execute(self, input_data: dict) -> dict:
        result = eval(input_data["expression"])
        return {"result": result}
```

## Testing Guide

### 1. Basic ReAct Agent Tests

```python
# test_react_agent.py
from __future__ import annotations

import pytest
from langchain_core.language_models import BaseChatModel
from pytest_mock import MockerFixture

from langgraph.prebuilt.chat_agent_executor import create_react_agent

@pytest.fixture
def mock_llm(mocker: MockerFixture) -> BaseChatModel:
    """Create a mock language model."""
    mock = mocker.Mock(spec=BaseChatModel)
    mock.predict.return_value = "I'll use the calculator tool: 2 + 2"
    return mock

@pytest.mark.asyncio
async def test_react_agent_creation(mock_llm: BaseChatModel) -> None:
    """Test creating a ReAct agent."""
    tools = [
        {
            "name": "calculator",
            "description": "Performs calculations",
            "func": lambda x: eval(x)
        }
    ]

    agent = create_react_agent(mock_llm, tools)
    assert agent is not None
```

### 2. Tool Executor Tests

```python
# test_tool_executor.py
from __future__ import annotations

import pytest
from pytest_mock import MockerFixture

from langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation

@pytest.fixture
def calculator_executor() -> ToolExecutor:
    """Create a calculator tool executor."""
    tools = {
        "calculator": lambda x: eval(x)
    }
    return ToolExecutor(tools)

def test_tool_execution(calculator_executor: ToolExecutor) -> None:
    """Test basic tool execution."""
    invocation = ToolInvocation(
        tool_name="calculator",
        tool_input="2 + 2"
    )

    result = calculator_executor.execute(invocation)
    assert result == 4

def test_invalid_tool_execution(calculator_executor: ToolExecutor) -> None:
    """Test execution with invalid tool name."""
    invocation = ToolInvocation(
        tool_name="invalid_tool",
        tool_input="2 + 2"
    )

    with pytest.raises(KeyError):
        calculator_executor.execute(invocation)
```

### 3. Tool Node Tests

```python
# test_tool_node.py
from __future__ import annotations

import pytest
from pytest_mock import MockerFixture

from langgraph.prebuilt.tool_node import ToolNode, InjectedState

class TestCalculatorNode(ToolNode):
    def __init__(self):
        super().__init__()
        self.state = InjectedState()

    async def execute(self, input_data: dict) -> dict:
        result = eval(input_data["expression"])
        return {"result": result}

@pytest.mark.asyncio
async def test_calculator_node() -> None:
    """Test calculator node execution."""
    node = TestCalculatorNode()
    result = await node.execute({"expression": "2 + 2"})
    assert result["result"] == 4

@pytest.mark.asyncio
async def test_calculator_node_error() -> None:
    """Test calculator node with invalid expression."""
    node = TestCalculatorNode()
    with pytest.raises(SyntaxError):
        await node.execute({"expression": "invalid"})
```

### 4. Validation Node Tests

```python
# test_validation.py
from __future__ import annotations

import pytest
from pydantic import BaseModel

from langgraph.prebuilt.tool_validator import ValidationNode

class CalculationInput(BaseModel):
    expression: str

class ValidationCalculatorNode(ValidationNode):
    input_schema = CalculationInput

@pytest.mark.asyncio
async def test_validation_node() -> None:
    """Test validation node with valid input."""
    node = ValidationCalculatorNode()
    validated = await node.validate({"expression": "2 + 2"})
    assert validated["expression"] == "2 + 2"

@pytest.mark.asyncio
async def test_validation_node_error() -> None:
    """Test validation node with invalid input."""
    node = ValidationCalculatorNode()
    with pytest.raises(ValueError):
        await node.validate({"invalid_field": "value"})
```

## Testing Best Practices

1. Use Type Annotations
- Always include proper type hints
- Use mypy for static type checking

2. Fixture Management
- Create reusable fixtures for common test scenarios
- Use appropriate fixture scopes

3. Async Testing
- Use pytest.mark.asyncio for async tests
- Handle coroutines properly

4. Error Handling
- Test both success and error cases
- Verify proper exception raising
- Test edge cases

5. Mocking
- Use pytest-mock for mocking dependencies
- Create appropriate mock responses

6. Test Coverage
- Aim for high test coverage (>90%)
- Include integration tests
- Test all public interfaces

## Common Test Fixtures

```python
# conftest.py
import pytest
from typing import Generator
from pytest_mock import MockerFixture

@pytest.fixture
def mock_tools() -> Generator[dict, None, None]:
    """Provide standard test tools."""
    tools = {
        "calculator": lambda x: eval(x),
        "uppercase": lambda x: x.upper()
    }
    yield tools

@pytest.fixture
def mock_state() -> Generator[dict, None, None]:
    """Provide test state data."""
    state = {
        "history": [],
        "variables": {}
    }
    yield state
```

This documentation provides a comprehensive overview of the langgraph.prebuilt module and its testing approach. The test examples cover the main components and demonstrate best practices for testing async code, validation, and error handling.
