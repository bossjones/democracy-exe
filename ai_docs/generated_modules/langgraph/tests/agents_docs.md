
> [!NOTE]
> Documentation auto-generated by [ai-docs.](https://github.com/connor-john/ai-docs)

I'll create comprehensive documentation and testing examples for this module, which defines agent-related data models.

# Module Documentation

## Module Overview

This module defines core data models for representing agent actions and completion states in an agent-based system. It provides two main classes:
- `AgentAction`: Represents a request for an agent to execute a specific tool with given inputs
- `AgentFinish`: Represents the final state/output when an agent completes its task

### Key Features
- Type-safe models using Pydantic
- Structured representation of agent operations
- JSON schema support
- Clear distinction between action requests and completion states

### Dependencies
- `pydantic`: For data validation and settings management
- `typing`: For type hints and annotations

## Installation and Setup

```bash
pip install pydantic
```

Required Python version: 3.7+

## Usage Guide

### Basic Usage

```python
# Creating an AgentAction
action = AgentAction(
    tool="search",
    tool_input="What is the weather in Paris?",
    log="Executing weather search for Paris"
)

# Creating an AgentFinish
finish = AgentFinish(
    return_values={"answer": "The weather is sunny", "confidence": 0.9},
    log="Task completed successfully"
)
```

### Advanced Usage

```python
# Using dictionary input for tool_input
action = AgentAction(
    tool="database_query",
    tool_input={
        "query": "SELECT * FROM users",
        "params": {"active": True}
    },
    log="Executing database query"
)

# Accessing model fields
print(action.tool)  # "database_query"
print(action.type)  # "AgentAction"

# JSON serialization
action_json = action.model_dump_json()
```

# Testing Guide

Here's a comprehensive test suite for the module:

```python
# test_agent_models.py
from typing import Generator
import pytest
from pydantic import ValidationError

@pytest.fixture
def sample_action_data() -> Generator[dict, None, None]:
    """Fixture providing sample data for AgentAction tests."""
    data = {
        "tool": "search",
        "tool_input": "test query",
        "log": "test log"
    }
    yield data

@pytest.fixture
def sample_finish_data() -> Generator[dict, None, None]:
    """Fixture providing sample data for AgentFinish tests."""
    data = {
        "return_values": {"result": "test result"},
        "log": "completion log"
    }
    yield data

class TestAgentAction:
    def test_create_valid_action(self, sample_action_data: dict) -> None:
        """Test creating a valid AgentAction instance."""
        action = AgentAction(**sample_action_data)
        assert action.tool == sample_action_data["tool"]
        assert action.tool_input == sample_action_data["tool_input"]
        assert action.log == sample_action_data["log"]
        assert action.type == "AgentAction"

    def test_create_action_with_dict_input(self) -> None:
        """Test creating AgentAction with dictionary tool_input."""
        action = AgentAction(
            tool="test_tool",
            tool_input={"key": "value"},
            log="test log"
        )
        assert isinstance(action.tool_input, dict)
        assert action.tool_input["key"] == "value"

    def test_action_type_immutable(self, sample_action_data: dict) -> None:
        """Test that action type cannot be changed."""
        action = AgentAction(**sample_action_data)
        with pytest.raises(ValidationError):
            action.type = "InvalidType"  # type: ignore

    @pytest.mark.parametrize("invalid_input", [
        {"tool": "", "tool_input": "test", "log": "test"},  # empty tool
        {"tool": "test", "tool_input": "", "log": "test"},  # empty tool_input
        {"tool": "test", "tool_input": None, "log": "test"},  # None tool_input
    ])
    def test_invalid_action_inputs(self, invalid_input: dict) -> None:
        """Test validation of invalid inputs."""
        with pytest.raises(ValidationError):
            AgentAction(**invalid_input)

class TestAgentFinish:
    def test_create_valid_finish(self, sample_finish_data: dict) -> None:
        """Test creating a valid AgentFinish instance."""
        finish = AgentFinish(**sample_finish_data)
        assert finish.return_values == sample_finish_data["return_values"]
        assert finish.log == sample_finish_data["log"]
        assert finish.type == "AgentFinish"

    def test_finish_json_serialization(self, sample_finish_data: dict) -> None:
        """Test JSON serialization of AgentFinish."""
        finish = AgentFinish(**sample_finish_data)
        json_data = finish.model_dump_json()
        assert isinstance(json_data, str)
        assert "return_values" in json_data
        assert "log" in json_data
        assert "type" in json_data

    def test_finish_with_complex_return_values(self) -> None:
        """Test AgentFinish with nested return values."""
        complex_data = {
            "return_values": {
                "results": ["item1", "item2"],
                "metadata": {"source": "test", "confidence": 0.9}
            },
            "log": "test log"
        }
        finish = AgentFinish(**complex_data)
        assert isinstance(finish.return_values["results"], list)
        assert isinstance(finish.return_values["metadata"], dict)

    def test_invalid_finish_creation(self) -> None:
        """Test validation of invalid AgentFinish creation."""
        with pytest.raises(ValidationError):
            AgentFinish(
                return_values=None,  # type: ignore
                log="test"
            )
```

## Testing Best Practices

1. **Test Coverage**
   - Aim for 100% code coverage
   - Test both successful and error cases
   - Include edge cases and boundary conditions

2. **Fixture Usage**
   - Use fixtures for common test data
   - Keep fixtures focused and minimal
   - Use appropriate scope for fixtures

3. **Validation Testing**
   - Test all validation rules
   - Verify type constraints
   - Check required fields

4. **JSON Schema Testing**
   - Verify JSON serialization/deserialization
   - Test schema compliance
   - Validate custom schema extras

5. **Type Safety**
   - Use type annotations in tests
   - Verify type constraints are enforced
   - Test type conversion cases

## Error Handling and Edge Cases

```python
def test_edge_cases() -> None:
    """Test various edge cases."""
    # Empty strings in log
    action = AgentAction(tool="test", tool_input="input", log="")
    assert action.log == ""

    # Unicode characters
    action = AgentAction(tool="test", tool_input="input", log="测试")
    assert len(action.log) == 2

    # Very large inputs
    large_input = "x" * 1000000
    action = AgentAction(tool="test", tool_input=large_input, log="test")
    assert len(action.tool_input) == 1000000
```

Remember to run tests with coverage:
```bash
pytest --cov=your_module tests/ --cov-report=term-missing
```

This documentation provides a solid foundation for understanding and testing the agent models module. The test suite covers all major functionality and edge cases while following best practices for Python testing.
