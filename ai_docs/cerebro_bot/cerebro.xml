<documents>
<document index="1">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/bot.py</source>
<document_content>
#!/usr/bin/env python
"""cerebro_bot.bot"""

# SOURCE: https://realpython.com/how-to-make-a-discord-bot-python/#responding-to-messages

import asyncio
import datetime
import logging
import os
import os.path
import pathlib
import re
import sys
import time
import traceback
from typing import List, NoReturn

from aiodebug import log_slow_callbacks as aiodebug_log_slow_callbacks
import aiomonitor
from codetiming import Timer
import discord
from discord.ext import commands
from fuzzywuzzy import fuzz
import torch

import cerebro_bot
from cerebro_bot import db, helpers, shell, utils
from cerebro_bot.aio_settings import aiosettings
from cerebro_bot.bot_logger import get_logger, intercept_all_loggers
from cerebro_bot.factories import guild_factory

# from cerebro_bot.web import CerebroMetricsApi

HERE = os.path.dirname(__file__)

LOGGER = get_logger(__name__, provider="Bot", level=logging.DEBUG)
intercept_all_loggers()

ROOTLOGGER = logging.getLogger()
HANDLER_LOGGER = logging.getLogger("handler")

NAME_LOGGER = logging.getLogger(__name__)
logging.getLogger("asyncio").setLevel(logging.DEBUG)
logging.getLogger("aiomonitor").setLevel(logging.DEBUG)

INVITE_LINK = "https://discordapp.com/api/oauth2/authorize?client_id={}&scope=bot&permissions=0"

# DISCORD_TOKEN = os.environ.get("DISCORD_TOKEN")
# DISCORD_ADMIN = os.environ.get("DISCORD_ADMIN_USER_ID")
# DISCORD_GUILD = os.environ.get("DISCORD_SERVER_ID")
# DISCORD_GENERAL_CHANNEL = 908894727779258390

DESCRIPTION = """An example bot to showcase the discord.ext.commands extension
module.

There are a number of utility commands being showcased here."""

# DL_THUMB_COMMAND = """
# youtube-dl -v -f best -n --ignore-errors --restrict-filenames --write-thumbnail --no-mtime --embed-thumbnail --recode-video mp4 --cookies=~/Downloads/yt-cookies.txt {dl_uri}
# """
# ECHO_DL_THUMB_COMMAND = "echo 'youtube-dl -v -f best -n --ignore-errors --restrict-filenames --write-thumbnail --no-mtime --embed-thumbnail --recode-video mp4 --cookies=~/Downloads/yt-cookies.txt {dl_uri}'"

# DL_SAFE_COMMAND = """

# youtube-dl -v -f best -n --ignore-errors --restrict-filenames --write-thumbnail --no-mtime --embed-thumbnail --recode-video mp4 --cookies=~/Downloads/yt-cookies.txt {dl_uri}

# _RETVAL=$?

# if [[ "${_RETVAL}" != "0" ]]; then
#         echo \"Trying yt-best instead\"

#         youtube-dl -v -f "bestvideo[ext=mp4]+bestaudio[ext=m4a]/bestvideo+bestaudio" -n --ignore-errors --restrict-filenames --write-thumbnail --no-mtime --embed-thumbnail --recode-video mp4 --cookies=~/Downloads/yt-cookies.txt --write-info-json {dl_uri}

#         _RETVAL=$?

#         if [[ "${_RETVAL}" != "0" ]]; then
#                 echo "Trying youtube-dl instead"
#                 youtube-dl {dl_uri}
#         fi
# fi
# """

HOME_PATH = os.environ.get("HOME")

COMMAND_RUNNER = {"dl_thumb": shell.run_coroutine_subprocess}


def filter_empty_string(a_list: List[str]) -> List[str]:
    """_summary_

    Args:
        a_list (List[str]): _description_

    Returns:
        List[str]: _description_
    """
    # filter out empty strings
    filter_object = filter(lambda x: x != "", a_list)

    return list(filter_object)


# SOURCE: https://docs.python.org/3/library/asyncio-queue.html
async def worker(name: str, queue: asyncio.Queue) -> NoReturn:
    """_summary_

    Args:
        name (str): _description_
        queue (asyncio.Queue): _description_

    Returns:
        NoReturn: _description_
    """
    LOGGER.info(f"starting working ... {name}")

    while True:
        # Get a "work item" out of the queue.
        co_cmd_task = await queue.get()
        print(f"co_cmd_task = {co_cmd_task}")

        # Sleep for the "co_cmd_task" seconds.
        # await asyncio.sleep(co_cmd_task)
        await COMMAND_RUNNER[co_cmd_task.name](cmd=co_cmd_task.cmd, uri=co_cmd_task.uri)

        # Notify the queue that the "work item" has been processed.
        queue.task_done()

        print(f"{name} ran {co_cmd_task.name} with arguments {co_cmd_task}")


# SOURCE: https://realpython.com/python-async-features/#building-a-synchronous-web-server
async def co_task(name: str, queue: asyncio.Queue):
    LOGGER.info(f"starting working ... {name}")

    timer = Timer(text=f"Task {name} elapsed time: {{:.1f}}")
    while not queue.empty():
        co_cmd_task = await queue.get()
        print(f"Task {name} running")
        timer.start()
        await COMMAND_RUNNER[co_cmd_task.name](cmd=co_cmd_task.cmd, uri=co_cmd_task.uri)
        timer.stop()
        yield


# # SOURCE: https://github.com/CarlGroth/Carl-Bot/blob/master/bot.py
# def _prefix_callable(bot, msg):
#     user_id = bot.user.id
#     base = ["<@!{}> ".format(user_id), "<@{}> ".format(user_id)]
#     if msg.guild is None:
#         base.append("!")
#         base.append("?")
#     else:
#         base.extend(bot.prefixes.get(msg.guild.id, ["?", "!"]))
#     return base


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/master/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/__init__.py
async def get_prefix(_bot: "Cerebro", message: discord.message.Message):
    """_summary_

    Args:
        _bot (Cerebro): _description_
        message (discord.message.Message): _description_

    Returns:
        _type_: _description_
    """
    LOGGER.info(f"inside get_prefix(_bot, message) - > get_prefix({_bot}, {message})")
    LOGGER.info(f"inside get_prefix(_bot, message) - > get_prefix({_bot}, {message})")
    LOGGER.info(f"inside get_prefix(_bot, message) - > get_prefix({type(_bot)}, {type(message)})")
    prefix = (
        [aiosettings.prefix]
        if isinstance(message.channel, discord.DMChannel)
        else [utils.get_guild_prefix(_bot, message.guild.id)]
    )
    LOGGER.info(f"prefix -> {prefix}")
    return commands.when_mentioned_or(*prefix)(_bot, message)


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/master/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/__init__.py#L28
# async def preload_guild_data():
#     LOGGER.info(f"preload_guild_data ... ")
#     d = dict()
#     d[DISCORD_GUILD] = {"prefix": constants.PREFIX}
#     LOGGER.info(f"preload_guild_data d = {d}")
#     print(f"preload_guild_data d = {d}\n")
#     return d


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/master/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/__init__.py#L28
async def preload_guild_data():
    """_summary_

    Returns:
        _type_: _description_
    """
    LOGGER.info("preload_guild_data ... ")
    guilds = [guild_factory.Guild()]
    return {guild.id: {"prefix": guild.prefix} for guild in guilds}


class Cerebro(commands.AutoShardedBot):
    """_summary_

    Args:
        commands (_type_): _description_
    """

    def __init__(
        self,
        *args,
        # command_prefix=get_prefix,
        intents: discord.flags.Intents = discord.Intents.default(),
        # TEMPCHANGE: # command_prefix=commands.when_mentioned_or(constants.PREFIX),
        command_prefix=commands.when_mentioned_or(aiosettings.prefix),
        description="Better than the last one",
        **kwargs,
    ):
        """_summary_

        Args:
            intents (discord.flags.Intents, optional): _description_. Defaults to discord.Intents.default().
            command_prefix (_type_, optional): _description_. Defaults to commands.when_mentioned_or(constants.PREFIX).
            description (str, optional): _description_. Defaults to "Better than the last one".
        """
        # super().__init__(
        #     *args, command_prefix=command_prefix, description=description, **kwargs
        # )
        # super(Cerebro, self).__init__(length, length)
        # https://realpython.com/python-super/#a-super-deep-dive
        super(Cerebro, self).__init__(
            *args,
            intents=intents,
            command_prefix=command_prefix,
            description=description,
            **kwargs,
        )

        # self.session = aiohttp.ClientSession(loop=self.loop)

        # Create a queue that we will use to store our "workload".
        self.queue = asyncio.Queue()

        self.tasks = []

        self.num_workers = 3

        self.total_sleep_time = 0

        self.start_time = datetime.datetime.now()

        # self.metrics_api = CerebroMetricsApi(metrics_host="0.0.0.0")

        # DISABLED: 3/25/2023 temporary to figure some stuff out # self.loop.run_until_complete(self.metrics_api.start())

        self.typerCtx = None

        #### For upscaler

        self.job_queue = {}

        # This group of variables are used in the upscaling process
        self.last_model = None
        self.last_in_nc = None
        self.last_out_nc = None
        self.last_nf = None
        self.last_nb = None
        self.last_scale = None
        self.last_kind = None
        self.model = None
        self.autocrop_model = None
        self.db = None
        # self.device = torch.device("cpu")
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        if torch.cuda.is_available():
            torch.set_default_tensor_type(torch.cuda.HalfTensor)
        # TEMPCHANGE: # self.ml_models_path = f"{helpers.ML_MODEL_PATH}/"
        # TEMPCHANGE: # self.my_custom_ml_models_path = f"{helpers.MY_CUSTOM_ML_MODELS_PATH}/"
        self.ml_models_path = f"{aiosettings.esgran_dir}"
        self.my_custom_ml_models_path = f"{aiosettings.screencropnet_dir}/"

        self.current_task = None

        # tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
        # This group of variables pertain to the models list
        self.models = []
        pth_list_only = helpers.walk_ml_model_dir()
        self.models.extend(f"{m.name}" for m in pth_list_only)
        self.fuzzymodels, self.aliases = self.build_aliases()

    async def setup_hook(self) -> None:
        """_summary_"""

        self.version = cerebro_bot.__version__
        self.guild_data = {}
        self.intents.members = True
        self.intents.message_content = True

        self.db = db.init_worker_redis()

        # import bpdb

        # bpdb.set_trace()

        # here, we are loading extensions prior to sync to ensure we are syncing interactions defined in those extensions.

        for ext in extensions():
            try:
                await self.load_extension(ext)
            except Exception as ex:
                print(f"Failed to load extension {ext} - exception: {ex}")
                exc_type, exc_value, exc_traceback = sys.exc_info()
                LOGGER.error(f"Error Class: {str(ex.__class__)}")
                output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                LOGGER.warning(output)
                LOGGER.error(f"exc_type: {exc_type}")
                LOGGER.error(f"exc_value: {exc_value}")
                traceback.print_tb(exc_traceback)
                raise

        # for extension in self.initial_extensions:
        #     await self.load_extension(extension)

        # # In overriding setup hook,
        # # we can do things that require a bot prior to starting to process events from the websocket.
        # # In this case, we are using this to ensure that once we are connected, we sync for the testing guild.
        # # You should not do this for every guild or for global sync, those should only be synced when changes happen.
        # if self.testing_guild_id:
        #     guild = discord.Object(self.testing_guild_id)
        #     # We'll copy in the global commands to test with:
        #     self.tree.copy_global_to(guild=guild)
        #     # followed by syncing to the testing guild.
        #     await self.tree.sync(guild=guild)

        # # This would also be a good place to connect to our database and
        # # load anything that should be in memory prior to handling events.

    # Method translated to python from BlueAmulet's original alias PR
    # Basically this allows the fuzzy matching to look at individual phrases present in the model name
    # This way, if you had two models, e.g 4xBox and 4x_sponge_bob, you could type 'bob' and it will choose the correct model
    # This method just builds the alias dictionary and list for that functionality
    def build_aliases(self):
        """Builds aliases for fuzzy string matching the model name input"""
        aliases = {}

        # Create aliases for models based on unique parts
        for model in self.models:
            name = os.path.splitext(os.path.basename(model))[0]
            parts = re.findall(r"([0-9]+x?|[A-Z]+(?![a-z])|[A-Z][^A-Z0-9_-]*)", name)
            for i in range(len(parts)):
                for j in range(i + 1, len(parts) + 1):
                    alias = "".join(parts[i:j])
                    if alias in aliases:
                        if fuzz.ratio(alias, model) > fuzz.ratio(alias, aliases[alias]):
                            aliases[alias] = model
                    else:
                        aliases[alias] = model

        # Ensure exact names are usable
        for model in self.models:
            name = os.path.splitext(os.path.basename(model))[0]
            aliases[name] = model

        fuzzylist = [alias for alias, value in aliases.items() if value]
        print(f"Made {len(fuzzylist)} aliases for {len(self.models)} models.")
        LOGGER.debug(f"Made {fuzzylist} aliases for {self.models} models.")
        return fuzzylist, aliases

    # SOURCE: https://discordpy.readthedocs.io/en/stable/api.html?highlight=event#discord.on_ready
    async def on_ready(self) -> None:
        """Event is called when the bot has finished logging in and setting things up"""
        print(f"Logged in as {self.user} (ID: {self.user.id})")
        print("------")
        self.invite = INVITE_LINK.format(self.user.id)
        self.guild_data = await preload_guild_data()
        print(
            f"""Logged in as {self.user}..
            Serving {len(self.users)} users in {len(self.guilds)} guilds
            Invite: {INVITE_LINK.format(self.user.id)}
        """
        )
        await self.change_presence(status=discord.Status.online, activity=discord.Game("CEREBRO"))

    async def my_background_task(self) -> None:
        """_summary_"""
        await self.wait_until_ready()
        counter = 0
        # TEMPCHANGE: # channel = self.get_channel(DISCORD_GENERAL_CHANNEL)  # channel ID goes here
        channel = self.get_channel(aiosettings.discord_general_channel)  # channel ID goes here
        while not self.is_closed():
            counter += 1
            await channel.send(counter)
            await asyncio.sleep(60)  # task runs every 60 seconds

    async def on_worker_monitor(self) -> None:
        await self.wait_until_ready()
        counter = 0
        # channel = self.get_channel(DISCORD_GENERAL_CHANNEL)  # channel ID goes here
        while not self.is_closed():
            counter += 1
            # await channel.send(counter)
            print(f" self.tasks = {self.tasks}")
            print(f" len(self.tasks) = {len(self.tasks)}")
            await asyncio.sleep(10)  # task runs every 60 seconds

    async def setup_workers(self) -> None:
        await self.wait_until_ready()

        # Create three worker tasks to process the queue concurrently.

        for i in range(self.num_workers):
            task = asyncio.create_task(worker(f"worker-{i}", self.queue))
            self.tasks.append(task)

        # Wait until the queue is fully processed.
        started_at = time.monotonic()
        await self.queue.join()
        total_slept_for = time.monotonic() - started_at

        # Cancel our worker tasks.
        for task in self.tasks:
            task.cancel()
        # Wait until all worker tasks are cancelled.
        await asyncio.gather(*self.tasks, return_exceptions=True)

        print("====")
        print(f"3 workers slept in parallel for {total_slept_for:.2f} seconds")
        # print(f'total expected sleep time: {total_sleep_time:.2f} seconds')

        # counter = 0
        # channel = self.get_channel(DISCORD_GENERAL_CHANNEL)  # channel ID goes here
        # while not self.is_closed():
        #     counter += 1
        #     await channel.send(counter)
        #     await asyncio.sleep(60)  # task runs every 60 seconds

    async def setup_co_tasks(self) -> None:
        await self.wait_until_ready()

        # Create three worker tasks to process the queue concurrently.

        for i in range(self.num_workers):
            task = asyncio.create_task(co_task(f"worker-{i}", self.queue))
            self.tasks.append(task)

        # Wait until the queue is fully processed.
        started_at = time.monotonic()
        await self.queue.join()
        total_slept_for = time.monotonic() - started_at

        # Cancel our worker tasks.
        for task in self.tasks:
            task.cancel()
        # Wait until all worker tasks are cancelled.
        await asyncio.gather(*self.tasks, return_exceptions=True)

        print("====")
        print(f"3 workers slept in parallel for {total_slept_for:.2f} seconds")


def extensions():
    """_summary_

    Yields:
        _type_: _description_
    """
    module_dir = pathlib.Path(HERE)
    files = pathlib.Path(module_dir.stem, "cogs").rglob("*.py")
    for file in files:
        LOGGER.debug(f"exension = {file.as_posix()[:-3].replace('/', '.')}")
        yield file.as_posix()[:-3].replace("/", ".")


# _bot: "Cerebro", message: discord.message.Message


# def load_extensions(_bot: "Cerebro") -> None:
#     """_summary_

#     Args:
#         _bot (Cerebro): _description_
#     """
#     for ext in extensions():
#         try:
#             _bot.load_extension(ext)
#         except Exception as ex:
#             print(f"Failed to load extension {ext} - exception: {ex}")
#             exc_type, exc_value, exc_traceback = sys.exc_info()
#             LOGGER.error(f"Error Class: {str(ex.__class__)}")
#             output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
#             LOGGER.warning(output)
#             LOGGER.error(f"exc_type: {exc_type}")
#             LOGGER.error(f"exc_value: {exc_value}")
#             traceback.print_tb(exc_traceback)
#             raise


if __name__ == "__main__":
    # cerebro = Cerebro()
    # # cerebro_bot/bot.py:528:4: E0237: Assigning to attribute 'members' not defined in class slots (assigning-non-slot)
    # cerebro.intents.members = True  # pylint: disable=assigning-non-slot
    # # NOTE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/master/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/__init__.py
    # cerebro.version = cerebro_bot.__version__
    # cerebro.guild_data = {}
    # # load_extensions(cerebro)
    # # cerebro.add_command(echo)
    # # import bpdb; bpdb.set_trace()
    # _cog = cerebro.get_cog("Utility")
    # utility_commands = _cog.get_commands()
    # print([c.name for c in utility_commands])
    # # print([c.name for c in commands])

    # # it is possible to pass a dictionary with local variables
    # # to the python console environment
    # host, port = "localhost", 50101
    # locals_ = {"port": port, "host": host}
    # # init monitor just before run_app

    # # intents = discord.Intents.default()
    # # intents.members = True
    # # DiscordBackend.client = discord.Client(intents=intents)

    # # import rich
    # # # cli.CLI()
    # # temp_runner = CliRunner()
    # # result: ClickResult
    # # result = temp_runner.invoke(cli.CLI, ["dump-context"])
    # # rich.print("Lets see if that populated the CTX cached value we need")
    # # rich.print(cli.CACHE_CTX)
    # # # rich.print(result)
    # # import bpdb
    # # bpdb.set_trace()

    # aiodebug_log_slow_callbacks.enable(0.05)

    # with aiomonitor.start_monitor(loop=cerebro.loop, locals=locals_):
    #     # TEMPCHANGE: cerebro.run(DISCORD_TOKEN)
    #     # TEMPCHANGE: replacing DISCORD_TOKEN with aiosettings.discord_token
    #     cerebro.run(aiosettings.discord_token)

    intents = discord.Intents.default()
    intents.message_content = True

    async def aio_smoke_test() -> None:
        async with Cerebro(intents=intents) as cerebro:
            await cerebro.start(aiosettings.discord_token)

    # For most use cases, after defining what needs to run, we can just tell asyncio to run it:
    asyncio.run(aio_smoke_test())

</document_content>
</document>
<document index="2">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/cogs/autocrop.py</source>
<document_content>
# pylint: disable=no-member
"""cerebro_bot.cogs.autocrop"""
from __future__ import annotations

import asyncio
import concurrent.futures
from enum import IntEnum
import functools
import logging
import os
import os.path
import pathlib
import sys
import tempfile
from timeit import default_timer as timer
import traceback
import typing
from typing import Dict, List, NewType, Optional

from PIL import Image
from codetiming import Timer
import cv2
import discord
from discord.ext import commands
from discord.message import Message
from discord.user import User
import numpy as np
import rich
import torch
from torch import nn
import torchvision.transforms as transforms
import torchvision.transforms.functional as FT
import torchvision.transforms.functional as pytorch_transforms_functional
from tqdm.auto import tqdm

from cerebro_bot.bot_logger import get_logger
from cerebro_bot.factories import guild_factory
from cerebro_bot.utils import file_functions
from cerebro_bot.utils.arch.ScreenCropNet import (
    ObjLocModel as ScreenCropNet_ObjLocModel,
)

if typing.TYPE_CHECKING:
    from cerebro_bot.bot import Cerebro

DISCORD_GUILD = os.environ.get("DISCORD_SERVER_ID")

LOGGER = get_logger(__name__, provider="AutoCrop", level=logging.DEBUG)

IMG_SIZE_CUTOFF = 1080

TYPE_IMAGE_ARRAY = typing.Union[np.ndarray, typing.Any]

TYPE_SCALE = typing.Union[str, int]

CUDA_AVAILABLE = torch.cuda.is_available()  # True


class Dimensions(IntEnum):
    HEIGHT = 224
    WIDTH = 224


ImageNdarrayBGR = NewType("ImageBGR", np.ndarray)
ImageNdarrayHWC = NewType("ImageHWC", np.ndarray)
TensorCHW = NewType("TensorCHW", torch.Tensor)

OPENCV_GREEN = (0, 255, 0)
OPENCV_RED = (255, 0, 0)


def unlink_orig_image(images_filepath: str):
    # for orig_to_rm in images_filepaths:
    rich.print(f"deleting ... {images_filepath}")
    os.unlink(f"{images_filepath}")
    return images_filepath


def resize_image_and_bbox(
    image: torch.Tensor,
    boxes: torch.Tensor,
    dims=(300, 300),
    return_percent_coords=False,
    device: torch.device = None,
):
    """
    Resize image. For the SSD300, resize to (300, 300).
    Since percent/fractional coordinates are calculated for the bounding boxes (w.r.t image dimensions) in this process,
    you may choose to retain them.
    :param image: image, a PIL Image
    :param boxes: bounding boxes in boundary coordinates, a tensor of dimensions (n_objects, 4)
    :return: resized image, updated bounding box coordinates (or fractional coordinates, in which case they remain the same)
    """

    image_tensor_to_resize_height = image.shape[1]
    image_tensor_to_resize_width = image.shape[2]

    # Resize image
    new_image = FT.resize(image, dims)

    # Resize bounding boxes
    old_dims = (
        torch.FloatTensor(
            [
                image_tensor_to_resize_width,
                image_tensor_to_resize_height,
                image_tensor_to_resize_width,
                image_tensor_to_resize_height,
            ]
        )
        .unsqueeze(0)
        .to(device)
    )
    new_boxes = boxes / old_dims  # percent coordinates

    if not return_percent_coords:
        new_dims = torch.FloatTensor([dims[1], dims[0], dims[1], dims[0]]).unsqueeze(0).to(device)
        new_boxes = new_boxes * new_dims

    return new_image, new_boxes


# SOURCE: https://www.learnpytorch.io/09_pytorch_model_deployment/
# 1. Create a function to return a list of dictionaries with sample, truth label, prediction, prediction probability and prediction time
def pred_and_store(
    paths: List[pathlib.Path],
    model: torch.nn.Module,
    # transform: torchvision.transforms,
    # class_names: List[str],
    device: torch.device = "",
) -> List[Dict]:
    # 3. Loop through target paths
    for path in tqdm(paths):
        # 4. Create empty dictionary to store prediction information for each sample
        pred_dict = {"image_path": path}

        # 6. Start the prediction timer
        timer()

        targetSize = Dimensions.HEIGHT
        # 7. Open image path

        img: ImageNdarrayBGR

        img_channel: int
        img_height: int
        img_width: int

        # import bpdb
        # bpdb.set_trace()

        img, img_channel, img_height, img_width = read_image_to_bgr(f"{paths[0]}")

        resized = cv2.resize(img, (targetSize, targetSize), interpolation=cv2.INTER_AREA)
        print(resized.shape)

        # normalize and change output to (c, h, w)
        resized_tensor: torch.Tensor = torch.from_numpy(resized).permute(2, 0, 1) / 255.0

        # 9. Prepare model for inference by sending it to target device and turning on eval() mode
        model.to(device)
        model.eval()

        with torch.inference_mode():
            # Convert to (bs, c, h, w)
            unsqueezed_tensor = resized_tensor.unsqueeze(0).to(device)

            # predict
            out_bbox: torch.Tensor = model(unsqueezed_tensor)

            # ic(out_bbox)

            xmin, ymin, xmax, ymax = out_bbox[0]
            pt1 = (int(xmin), int(ymin))
            pt2 = (int(xmax), int(ymax))

            starting_point = pt1
            end_point = pt2
            color = (255, 0, 0)
            thickness = 2

            # import bpdb
            # bpdb.set_trace()

            # img = image.astype("uint8")
            # generate the image with bounding box on it
            out_img = cv2.rectangle(
                unsqueezed_tensor.squeeze().permute(1, 2, 0).cpu().numpy().astype("uint8"),
                starting_point,
                end_point,
                color,
                thickness,
            )

            # TODO: Enable this?
            # if --display
            # plt.imshow(out_img)

            # NOTE: At this point we have our bounding box for the smaller image, lets figure out what the values would be for a larger image.
            # First setup variables we need
            # -------------------------------------------------------
            image_tensor_to_resize = resized_tensor
            resized_bboxes_tensor = out_bbox[0]
            resized_height = img_height
            resized_width = img_width
            resized_dims = (resized_height, resized_width)

            image_tensor_to_resize.shape[0]
            image_tensor_to_resize.shape[1]
            image_tensor_to_resize.shape[2]

            # perform fullsize transformation
            fullsize_image, fullsize_bboxes = resize_image_and_bbox(
                image_tensor_to_resize,
                resized_bboxes_tensor,
                dims=resized_dims,
                return_percent_coords=False,
                device=device,
            )

            # get fullsize bboxes
            (
                xmin_fullsize,
                ymin_fullsize,
                xmax_fullsize,
                ymax_fullsize,
            ) = fullsize_bboxes[0]

            (int(xmin_fullsize), int(ymin_fullsize))
            (int(xmax_fullsize), int(ymax_fullsize))

            color = OPENCV_RED
            thickness = 1

    print(fullsize_bboxes)

    return fullsize_bboxes


def get_pil_image_channels(image_path: str) -> int:
    """Open an image and get the number of channels it has.

    Args:
        image_path (str): _description_

    Returns:
        int: _description_
    """
    # load pillow image
    pil_img = Image.open(image_path)

    # Converts a PIL Image (H x W x C) to a Tensor of shape (C x H x W).
    pil_img_tensor = transforms.PILToTensor()(pil_img)

    return pil_img_tensor.shape[0]


def convert_pil_image_to_rgb_channels(image_path: str):
    """Convert Pil image to have the appropriate number of color channels

    Args:
        image_path (str): _description_

    Returns:
        _type_: _description_
    """
    return Image.open(image_path).convert("RGB") if get_pil_image_channels(image_path) != 4 else Image.open(image_path)


def read_image_to_bgr(image_path: str) -> ImageNdarrayBGR:
    """Read the image from image id.

    returns ImageNdarrayBGR.

    Opencv returns ndarry in format = row (height) x column (width) x color (3)
    """

    # image = cv2.imread(image_path, cv2.IMREAD_COLOR)
    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)
    # image /= 255.0  # Normalize

    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    # import bpdb
    # bpdb.set_trace()
    # img_shape = image.shape
    img_channel = image.shape[2]
    img_height = image.shape[0]
    img_width = image.shape[1]
    return image, img_channel, img_height, img_width


def convert_image_from_hwc_to_chw(img: ImageNdarrayBGR) -> torch.Tensor:
    img: torch.Tensor = torch.from_numpy(img).permute(2, 0, 1) / 255.0  # (h,w,c) -> (c,h,w)
    return img


# convert image back and forth if needed: https://stackoverflow.com/questions/68207510/how-to-use-torchvision-io-read-image-with-image-as-variable-not-stored-file
def convert_pil_image_to_torch_tensor(pil_image: Image) -> torch.Tensor:
    """Convert PIL image to pytorch tensor

    Args:
        pil_image (PIL.Image): _description_

    Returns:
        torch.Tensor: _description_
    """
    return pytorch_transforms_functional.to_tensor(pil_image)


# convert image back and forth if needed: https://stackoverflow.com/questions/68207510/how-to-use-torchvision-io-read-image-with-image-as-variable-not-stored-file
def convert_tensor_to_pil_image(tensor_image: torch.Tensor) -> Image:
    """Convert tensor image to Pillow object

    Args:
        tensor_image (torch.Tensor): _description_

    Returns:
        PIL.Image: _description_
    """
    return pytorch_transforms_functional.to_pil_image(tensor_image)


def predict_from_file(path_to_image_from_cli: str, model: torch.nn.Module, device: torch.device):
    """wrapper function to perform predictions on individual files

    Args:
        path_to_image_from_cli (str): eg.  "/Users/malcolm/Downloads/2020-11-25_10-47-32_867.jpeg
        model (torch.nn.Module): _description_
        transform (torchvision.transforms): _description_
        class_names (List[str]): _description_
        device (torch.device): _description_
        args (argparse.Namespace): _description_
    """
    # ic(f"Predict | individual file {path_to_image_from_cli} ...")
    image_path_api = pathlib.Path(path_to_image_from_cli).resolve()
    # ic(image_path_api)

    paths = [image_path_api]
    img = convert_pil_image_to_rgb_channels(f"{paths[0]}")

    bboxes = pred_and_store(paths, model, device=device)

    return img, bboxes


def get_pixel_rgb(image_pil: Image):
    """Get first pixel in image and return a humanreadable name of what color is represented

    Args:
        image_pil (Image): _description_

    Returns:
        _type_: _description_
    """
    r, g, b = image_pil.getpixel((1, 1))
    # ic(r,g,b)

    color = "white" if (r, g, b) == (255, 255, 255) else "darkmode"
    print(f"GOT COLOR {color} -- {r},{g},{b}")
    return color


def resize_and_pillarbox(image_pil: Image, width: int, height: int, background="white"):
    """
    Resize PIL image keeping ratio and using white background.
    """
    autodetect_background = get_pixel_rgb(image_pil)

    ratio_w = width / image_pil.width
    ratio_h = height / image_pil.height
    if ratio_w < ratio_h:
        # It must be fixed by width
        resize_width = width
        resize_height = round(ratio_w * image_pil.height)
    else:
        # Fixed by height
        resize_width = round(ratio_h * image_pil.width)
        resize_height = height
    image_resize = image_pil.resize((resize_width, resize_height), Image.Resampling.LANCZOS)
    if background and autodetect_background == "white":
        background = Image.new("RGBA", (width, height), (255, 255, 255, 255))
    elif background and autodetect_background == "darkmode":
        background = Image.new("RGBA", (width, height), (22, 32, 42, 1))
    offset = (round((width - resize_width) / 2), round((height - resize_height) / 2))
    background.paste(image_resize, offset)
    return background.convert("RGB")


def handle_autocrop(
    images_filepaths: List[str],
    cols=5,
    model=None,
    device=None,
    args=None,
    resize=False,
    predict_results=None,
):
    cropped_image_file_paths = []
    for i, image_filepath in enumerate(images_filepaths):
        image, bboxes = predict_results[i]
        # image, bboxes = predict_from_file(image_filepath, model, device)
        img_as_array = np.asarray(image)
        img_as_array = cv2.cvtColor(img_as_array, cv2.COLOR_RGB2BGR)

        # get fullsize bboxes
        xmin_fullsize, ymin_fullsize, xmax_fullsize, ymax_fullsize = bboxes[0]

        startY = int(ymin_fullsize)
        endY = int(ymax_fullsize)
        startX = int(xmin_fullsize)
        endX = int(xmax_fullsize)

        # roi = image[startY:endY, startX:endX]
        cropped_image = img_as_array[startY:endY, startX:endX]

        # import bpdb
        # bpdb.set_trace()

        image_path_api = pathlib.Path(image_filepath).resolve()
        fname = f"{image_path_api.parent}/cropped-{model.name}-{image_path_api.stem}{image_path_api.suffix}"

        # if f"{image_path_api.suffix}".lower() == ".png":
        #     cv2.imwrite(fname, cropped_image, [int(cv2.IMWRITE_PNG_COMPRESSION),5])
        # elif f"{image_path_api.suffix}".lower() == (".jpg" or ".jpeg"):
        #     cv2.imwrite(fname, cropped_image, [cv2.IMWRITE_JPEG_QUALITY , 80])
        cv2.imwrite(fname, cropped_image)

        cropped_full_path = file_functions.fix_path(fname)

        cropped_image_file_paths.append(cropped_full_path)

    return cropped_image_file_paths


def handle_autocrop_one(
    images_filepath: str,
    cols=5,
    model=None,
    device=None,
    args=None,
    resize=False,
    predict_results=None,
):
    # cropped_image_file_paths = []
    # for i, image_filepath in enumerate(images_filepaths):

    # import bpdb
    # bpdb.set_trace()

    image, bboxes = predict_results
    temp = image.copy()
    # image, bboxes = predict_from_file(image_filepath, model, device)
    img_as_array = np.asarray(temp)
    img_as_array = cv2.cvtColor(img_as_array, cv2.COLOR_RGB2BGR)

    # get fullsize bboxes
    xmin_fullsize, ymin_fullsize, xmax_fullsize, ymax_fullsize = bboxes[0]

    # if we have a negative point to make a rectange with, set it to 0
    startY = max(int(ymin_fullsize), 0)
    endY = max(int(ymax_fullsize), 0)
    startX = max(int(xmin_fullsize), 0)
    endX = max(int(xmax_fullsize), 0)

    rich.print(startY, endY, startX, endX)

    cropped_image = img_as_array[startY:endY, startX:endX]

    image_path_api = pathlib.Path(images_filepath).resolve()
    fname = f"{image_path_api.parent}/cropped-{model.name}-{image_path_api.stem}{image_path_api.suffix}"

    cv2.imwrite(fname, cropped_image)

    return file_functions.fix_path(fname)


def handle_resize(
    images_filepaths: List[str],
    cols=5,
    model=None,
    device=None,
    args=None,
    resize=False,
):
    resized_image_file_paths = []
    for i, image_filepath in enumerate(images_filepaths):
        image_path_api = pathlib.Path(image_filepath).resolve()
        fname = f"{image_path_api.parent}/cropped-{model.name}-{image_path_api.stem}{image_path_api.suffix}"

        cropped_full_path = file_functions.fix_path(fname)

        if resize:
            to_resize = Image.open(cropped_full_path).convert("RGB")
            resized_pil_image = resize_and_pillarbox(to_resize, 1080, 1350, background=resize)
            if f"{image_path_api.suffix}".lower() == ".png":
                # https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html
                resized_pil_image.save(fname, optimize=True, compress_level=9)
            elif f"{image_path_api.suffix}".lower() == (".jpg" or ".jpeg"):
                resized_pil_image.save(fname, quality="web_medium")

        resized_image_file_paths.append(cropped_full_path)

    return resized_image_file_paths


def handle_resize_one(
    images_filepath: str,
    cols=5,
    model=None,
    device=None,
    args=None,
    resize=False,
):
    image_path_api = pathlib.Path(images_filepath).resolve()
    fname = f"{image_path_api.parent}/cropped-{model.name}-{image_path_api.stem}{image_path_api.suffix}"

    cropped_full_path = file_functions.fix_path(fname)

    if resize:
        to_resize = Image.open(cropped_full_path).convert("RGB")
        resized_pil_image = resize_and_pillarbox(to_resize, 1080, 1350, background=resize)
        if f"{image_path_api.suffix}".lower() == ".png":
            # https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html
            resized_pil_image.save(fname, optimize=True, compress_level=9)
        elif f"{image_path_api.suffix}".lower() == (".jpg" or ".jpeg"):
            resized_pil_image.save(fname, quality="web_medium")

    return cropped_full_path


def handle_predict(
    images_filepaths: List[str],
    cols=5,
    model=None,
    device=None,
    args=None,
    resize=False,
):
    image_and_bboxes_list = []
    for image_filepath in images_filepaths:
        image, bboxes = predict_from_file(image_filepath, model, device)
        image_and_bboxes_list.append([image, bboxes])
    return image_and_bboxes_list


def handle_predict_one(
    images_filepath: str,
    cols=5,
    model=None,
    device=None,
    args=None,
    resize=False,
):
    assert cols
    # image_and_bboxes_list = []
    # for i, image_filepath in enumerate(images_filepaths):
    image, bboxes = predict_from_file(images_filepath, model, device)
    # image_and_bboxes_list.append()
    return image, bboxes


# NOTE: https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference
def load_model_for_inference(save_path: str, device: str) -> nn.Module:
    model = ScreenCropNet_ObjLocModel()
    model.name = "ObjLocModelV1"
    model.load_state_dict(torch.load(save_path, map_location=device))
    model.eval()
    print(f"Model loaded from path {save_path} successfully.")
    # Get the model size in bytes then convert to megabytes
    model_size = pathlib.Path(save_path).stat().st_size // (1024 * 1024)
    print(f"{save_path} | feature extractor model size: {model_size} MB")
    return model


# wrapper function of common code
def run_get_model_for_inference(
    model: torch.nn.Module,
    device: torch.device,
    path_to_model: pathlib.PosixPath,
) -> torch.nn.Module:
    """wrapper function to load model .pth file from disk

    Args:
        model (torch.nn.Module): _description_
        device (torch.device): _description_
        class_names (List[str]): _description_

    Returns:
        Tuple[pathlib.PosixPath, torch.nn.Module]: _description_
    """
    return load_model_for_inference(path_to_model, device)


def unique_list(
    list1: typing.Union[typing.List[str], typing.List[bytes]]
) -> typing.Union[typing.List[str], typing.List[bytes]]:
    # insert the list to the set
    list_set = set(list1)
    return list(list_set)


# https://github.com/discord-math/bot/blob/babb41b71a68b4b099684b3e1ed583f84083f971/plugins/log.py#L63
def path_for(attm: discord.Attachment, basedir: str = "./") -> pathlib.Path:
    p = pathlib.Path(basedir, str(attm.filename))
    LOGGER.debug(f"path_for: p -> {p}")
    return p


# https://github.com/discord-math/bot/blob/babb41b71a68b4b099684b3e1ed583f84083f971/plugins/log.py#L63
async def save_attachment(attm: discord.Attachment, basedir: str = "./") -> None:
    path = path_for(attm, basedir=basedir)
    LOGGER.debug(f"save_attachment: path -> {path}")
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        ret_code = await attm.save(path, use_cached=True)
        await asyncio.sleep(5)
    except discord.HTTPException:
        await attm.save(path)


# TODO: Remove this when we eventually upgrade to 2.0 discord.py
def attachment_to_dict(attm: discord.Attachment):
    result = {
        "filename": attm.filename,
        "id": attm.id,
        "proxy_url": attm.proxy_url,
        "size": attm.size,
        "url": attm.url,
        "spoiler": attm.is_spoiler(),
    }
    if attm.height:
        result["height"] = attm.height
    if attm.width:
        result["width"] = attm.width
    if attm.content_type:
        result["content_type"] = attm.content_type

    result["attachment_obj"] = attm

    return result


def file_to_local_data_dict(fname: str, dir_root: str):
    file_api = pathlib.Path(fname)
    return {
        "filename": f"{dir_root}/{file_api.stem}{file_api.suffix}",
        "size": file_api.stat().st_size,
        "ext": f"{file_api.suffix}",
        "api": file_api,
    }


async def handle_save_attachment_locally(attm_data_dict, dir_root):
    # attm_data_dict_copy = copy.copy(attm_data_dict)
    fname = f"{dir_root}/orig_{attm_data_dict['id']}_{attm_data_dict['filename']}"
    rich.print(f"Saving to ... {fname}")
    await attm_data_dict["attachment_obj"].save(fname, use_cached=True)
    await asyncio.sleep(1)
    # attm_data_dict["local_file"] = fname
    return fname


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/133702ceb8682ec3927530ac35ad28d47a42802e/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/cogs/settings.py
class AutoCrop(commands.Cog):
    def __init__(self, cerebro: Cerebro):
        self.bot = cerebro

    @commands.Cog.listener()
    async def on_ready(self) -> None:
        print(f"{type(self).__name__} Cog ready.")

    @commands.Cog.listener()
    async def on_guild_join(self, guild: guild_factory.Guild) -> None:
        """Add new guilds to the database"""
        _ = await guild_factory.Guild(id=guild.id)

    @commands.command(aliases=["ac", "auto"])
    async def autocrop(self, ctx: commands.context.Context, *args) -> None:  # type:ignore
        """`$autocrop [model]` // AutoCrops attached image using specified model. Model name input will be automatically matched with the closest model name.

        `$autocrop [url] [model]` // AutoCrops linked image using specified model. Model name input will be automatically matched with the closest model name.

        Optional `$autocrop` args:

        `$downscale [amount]` // Downscales the image by the amount listed. For example, `$downscale 4` will make the image 25% of its original size.

        `$filter [filter]` // Filter to be used for downscaling. Must be a valid OpenCV image interpolation filter, with ImageMagick aliases supported as well. Defaults to box/area.

        `$blur [type] [amount]` // Blurs the image before upscaling using the specified blur type and the amount specified. Only Gaussian and median blur are currently supported.

        `$montage` // Creates aside by side comparison of the LR and result after upscaling.

        `$seamless` // Duplicates the image around the edges to make a seamless texture retain its seamlessness

        Example: `$autocrop www.imageurl.com/image.png 4xBox.pth $downscale 4 $filter point $montage`
        """

        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, args = {args}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user: Optional[User]
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        message = ctx.message
        args = list(args)

        attachment_data_list_dicts = []
        local_attachment_file_list = []
        local_attachment_data_list_dicts = []
        images_filepaths = []

        await self.load_model()

        await ctx.send(
            embed=discord.Embed(description="Loading Autocrop Model ...."),
            delete_after=30.0,
        )

        for attm in message.attachments:
            data = attachment_to_dict(attm)
            attachment_data_list_dicts.append(data)

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                # return a list of strings pointing to the downloaded files
                for an_attachment_dict in attachment_data_list_dicts:
                    local_attachment_path = await handle_save_attachment_locally(an_attachment_dict, tmpdirname)
                    local_attachment_file_list.append(local_attachment_path)

                # create new list of dicts including info about the local files
                for some_file in local_attachment_file_list:
                    local_data_dict = file_to_local_data_dict(some_file, tmpdirname)
                    local_attachment_data_list_dicts.append(local_data_dict)
                    path_to_image = file_functions.fix_path(local_data_dict["filename"])
                    images_filepaths.append(path_to_image)

                print("hello")

                # import bpdb
                # bpdb.set_trace()
                rich.print("images_filepaths -> ")
                rich.print(images_filepaths)

                print("standy")

                # now it is time to autocrop everything

                await ctx.send(
                    embed=discord.Embed(description=f"Autocropping {images_filepaths}...."),
                    delete_after=30.0,
                )

                try:
                    # upscale = functools.partial(
                    #     ops.auto_split_upscale, img, self.esrgan, scale
                    # )
                    # rlt, _ = await self.bot.loop.run_in_executor(
                    #     None, upscale
                    # )

                    for count, img_fpaths in enumerate(images_filepaths):
                        # compute all predictions first
                        handle_predict_func = functools.partial(
                            handle_predict_one,
                            img_fpaths,
                            cols=5,
                            model=self.bot.autocrop_model,
                            device=self.bot.device,
                            resize=True,
                        )

                        # 2. Run in a custom thread pool:
                        with concurrent.futures.ThreadPoolExecutor() as pool:
                            (
                                image_results,
                                bboxes_results,
                            ) = await self.bot.loop.run_in_executor(pool, handle_predict_func)
                            rich.print(
                                f"count: {count} - predict threadpool",
                                image_results,
                                bboxes_results,
                            )
                        await asyncio.sleep(2)

                        # perform crop and save to disk
                        handle_autocrop_func = functools.partial(
                            handle_autocrop_one,
                            img_fpaths,
                            cols=5,
                            model=self.bot.autocrop_model,
                            device=self.bot.device,
                            resize=True,
                            predict_results=[image_results, bboxes_results],
                        )

                        # 2. Run in a custom thread pool:
                        with concurrent.futures.ThreadPoolExecutor() as pool:
                            cropped_result = await self.bot.loop.run_in_executor(pool, handle_autocrop_func)
                            rich.print(f"count: {count} - autocrop threadpool", cropped_result)
                        await asyncio.sleep(2)

                        # if count == 1:
                        # import bpdb
                        # bpdb.set_trace()

                        # perform resize
                        handle_resize_func = functools.partial(
                            handle_resize_one,
                            img_fpaths,
                            cols=5,
                            model=self.bot.autocrop_model,
                            device=self.bot.device,
                            resize=True,
                        )

                        # 2. Run in a custom thread pool:
                        with concurrent.futures.ThreadPoolExecutor() as pool:
                            resized_result = await self.bot.loop.run_in_executor(pool, handle_resize_func)
                            rich.print(f"count: {count} - Resized threadpool", resized_result)
                        await asyncio.sleep(2)

                        # nuke the originals
                        unlink_func = functools.partial(unlink_orig_image, img_fpaths)

                        # 2. Run in a custom thread pool:
                        with concurrent.futures.ThreadPoolExecutor() as pool:
                            unlink_result = await self.bot.loop.run_in_executor(pool, unlink_func)
                            rich.print(f"count: {count} - Unlink", unlink_result)
                        await asyncio.sleep(1)

                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not download story...."))
                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    LOGGER.warning(output)
                    await ctx.send(embed=discord.Embed(description=output))
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                # await asyncio.sleep(2)
                # unlink_func = functools.partial(unlink_orig_images, images_filepaths)

                # # 2. Run in a custom thread pool:
                # with concurrent.futures.ThreadPoolExecutor() as pool:
                #     unlink_result = await self.bot.loop.run_in_executor(
                #         pool, unlink_func)
                #     rich.print('Unlink', unlink_result)

                # for orig_to_rm in images_filepaths:
                #     print(f"deleting ... {orig_to_rm}")
                #     os.unlink(f"{orig_to_rm}")

                # now it is time to upload everything

                tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
                rich.print("tree_list ->")
                rich.print(tree_list)

                file_to_upload_list = [f"{p}" for p in tree_list]
                LOGGER.debug(f"{type(self).__name__} -> file_to_upload_list = {file_to_upload_list}")
                rich.print(file_to_upload_list)

                file_to_upload = file_functions.filter_media(file_to_upload_list)

                # ---------------------------------------------------------
                # chunked_lists = list(misc.divide_chunks(file_to_upload, n=10))
                # discord has a limit of 10 media uploads per api call. break them up.
                # SOURCE: https://www.geeksforgeeks.org/break-list-chunks-size-n-python/
                n = 2
                final = [file_to_upload[i * n : (i + 1) * n] for i in range((len(file_to_upload) + n - 1) // n)]

                for count, chunk in enumerate(final):
                    await ctx.send(
                        embed=discord.Embed(description=f"Uploading batch {count}...."),
                        delete_after=30.0,
                    )

                    my_files = []

                    for f in chunk:
                        rich.print(f)
                        my_files.append(discord.File(f"{f}"))

                    LOGGER.debug(f"{type(self).__name__} -> my_files = {my_files}")
                    rich.print(my_files)

                    try:
                        msg: Message
                        msg = await ctx.send(files=my_files)
                    except Exception as ex:
                        await ctx.send(embed=discord.Embed(description="Could not upload story to discord...."))
                        print(ex)
                        exc_type, exc_value, exc_traceback = sys.exc_info()
                        LOGGER.error(f"Error Class: {str(ex.__class__)}")
                        output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                        LOGGER.warning(output)
                        await ctx.send(embed=discord.Embed(description=output))
                        LOGGER.error(f"exc_type: {exc_type}")
                        LOGGER.error(f"exc_value: {exc_value}")
                        traceback.print_tb(exc_traceback)

        await message.delete(delay=10)

        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, args = {args}")

    async def load_model(self, model_name: str = "ScreenCropNetV1_378_epochs.pth"):
        model = ScreenCropNet_ObjLocModel()
        model.name = "ObjLocModelV1"
        model.to(self.bot.device)
        weights = f"{self.bot.my_custom_ml_models_path}{model_name}"
        model = run_get_model_for_inference(model, self.bot.device, weights)
        self.bot.autocrop_model = model
        LOGGER.info(f"Loaded model: {weights} ...")


async def setup(cerebro: Cerebro) -> None:
    await cerebro.add_cog(AutoCrop(cerebro))

</document_content>
</document>
<document index="3">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/cogs/autoresize.py</source>
<document_content>
# pylint: disable=no-member
"""cerebro_bot.cogs.autoresize"""
from __future__ import annotations

import asyncio
import concurrent.futures
from enum import IntEnum
import functools
import logging
import os
import os.path
import pathlib
import sys
import tempfile
import time
from timeit import default_timer as timer
import traceback
import typing
from typing import Dict, List, NewType, Optional

from PIL import Image
from codetiming import Timer
import cv2
import discord
from discord.ext import commands
from discord.message import Message
from discord.user import User
import numpy as np
import rich
import torch
from torch import nn
import torchvision.transforms as transforms
import torchvision.transforms.functional as FT
import torchvision.transforms.functional as pytorch_transforms_functional
from tqdm.auto import tqdm

from cerebro_bot import shell
from cerebro_bot.bot_logger import get_logger
from cerebro_bot.factories import guild_factory
from cerebro_bot.utils import file_functions
from cerebro_bot.utils.arch.ScreenCropNet import (
    ObjLocModel as ScreenCropNet_ObjLocModel,
)

if typing.TYPE_CHECKING:
    from cerebro_bot.bot import Cerebro

DISCORD_GUILD = os.environ.get("DISCORD_SERVER_ID")

LOGGER = get_logger(__name__, provider="AutoResize", level=logging.DEBUG)

IMG_SIZE_CUTOFF = 1080

TYPE_IMAGE_ARRAY = typing.Union[np.ndarray, typing.Any]

TYPE_SCALE = typing.Union[str, int]

CUDA_AVAILABLE = torch.cuda.is_available()  # True


# os.environ['TZ'] = 'US/Eastern'
# time.tzset()
# time.tzname


async def details_from_file(path_to_media_from_cli: str, cwd: typing.Union[str, None] = None):
    """Take a file path and return the input and output file paths and the timestamp of the input file.

    Args:
        path_to_media_from_cli (str): _description_

    Returns:
        _type_: _description_
    """
    p = pathlib.Path(path_to_media_from_cli)
    full_path_input_file = f"{p.stem}{p.suffix}"
    full_path_output_file = f"{p.stem}_smaller.mp4"
    rich.print(full_path_input_file)
    rich.print(full_path_output_file)
    if sys.platform == "darwin":
        get_timestamp = await shell._aio_run_process_and_communicate(
            ["gstat", "-c", "%y", f"{p.stem}{p.suffix}"], cwd=cwd
        )
    elif sys.platform == "linux":
        get_timestamp = await shell._aio_run_process_and_communicate(
            ["stat", "-c", "%y", f"{p.stem}{p.suffix}"], cwd=cwd
        )

    return full_path_input_file, full_path_output_file, get_timestamp


def unlink_orig_file(a_filepath: str):
    """_summary_

    Args:
        a_filepath (str): _description_

    Returns:
        _type_: _description_
    """
    # for orig_to_rm in media_filepaths:
    rich.print(f"deleting ... {a_filepath}")
    os.unlink(f"{a_filepath}")
    return a_filepath


# https://github.com/discord-math/bot/blob/babb41b71a68b4b099684b3e1ed583f84083f971/plugins/log.py#L63
def path_for(attm: discord.Attachment, basedir: str = "./") -> pathlib.Path:
    p = pathlib.Path(basedir, str(attm.filename))
    LOGGER.debug(f"path_for: p -> {p}")
    return p


# https://github.com/discord-math/bot/blob/babb41b71a68b4b099684b3e1ed583f84083f971/plugins/log.py#L63
async def save_attachment(attm: discord.Attachment, basedir: str = "./") -> None:
    path = path_for(attm, basedir=basedir)
    LOGGER.debug(f"save_attachment: path -> {path}")
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        ret_code = await attm.save(path, use_cached=True)
        await asyncio.sleep(5)
    except discord.HTTPException:
        await attm.save(path)


# TODO: Remove this when we eventually upgrade to 2.0 discord.py
def attachment_to_dict(attm: discord.Attachment):
    """Converts a discord.Attachment object to a dictionary.

    Args:
        attm (discord.Attachment): _description_

    Returns:
        _type_: _description_
    """
    result = {
        "filename": attm.filename,
        "id": attm.id,
        "proxy_url": attm.proxy_url,
        "size": attm.size,
        "url": attm.url,
        "spoiler": attm.is_spoiler(),
    }
    if attm.height:
        result["height"] = attm.height
    if attm.width:
        result["width"] = attm.width
    if attm.content_type:
        result["content_type"] = attm.content_type

    result["attachment_obj"] = attm

    return result


def file_to_local_data_dict(fname: str, dir_root: str):
    """Convert a file to a dictionary.

    Args:
        fname (str): _description_
        dir_root (str): _description_

    Returns:
        _type_: _description_
    """
    file_api = pathlib.Path(fname)
    return {
        "filename": f"{dir_root}/{file_api.stem}{file_api.suffix}",
        "size": file_api.stat().st_size,
        "ext": f"{file_api.suffix}",
        "api": file_api,
    }


async def handle_save_attachment_locally(attm_data_dict, dir_root):
    """Save an attachment locally.

    Args:
        attm_data_dict (_type_): _description_
        dir_root (_type_): _description_

    Returns:
        _type_: _description_
    """
    fname = f"{dir_root}/orig_{attm_data_dict['id']}_{attm_data_dict['filename']}"
    rich.print(f"Saving to ... {fname}")
    await attm_data_dict["attachment_obj"].save(fname, use_cached=True)
    await asyncio.sleep(1)
    return fname


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/133702ceb8682ec3927530ac35ad28d47a42802e/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/cogs/settings.py
class AutoResize(commands.Cog):
    def __init__(self, cerebro: Cerebro):
        self.bot = cerebro

    @commands.Cog.listener()
    async def on_ready(self) -> None:
        print(f"{type(self).__name__} Cog ready.")

    @commands.Cog.listener()
    async def on_guild_join(self, guild: guild_factory.Guild) -> None:
        """Add new guilds to the database"""
        _ = await guild_factory.Guild(id=guild.id)

    @commands.command(aliases=["ars"])
    async def autoresizesmall(self, ctx: commands.context.Context, *args) -> None:  # type:ignore
        """Autoresize videos to 1080x1080.

        Args:
            ctx (commands.context.Context): _description_
        """

        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, args = {args}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user: Optional[User]
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        message = ctx.message
        args = list(args)

        attachment_data_list_dicts = []
        local_attachment_file_list = []
        local_attachment_data_list_dicts = []
        media_filepaths = []

        for attm in message.attachments:
            data = attachment_to_dict(attm)
            attachment_data_list_dicts.append(data)

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                # return a list of strings pointing to the downloaded files
                for an_attachment_dict in attachment_data_list_dicts:
                    local_attachment_path = await handle_save_attachment_locally(an_attachment_dict, tmpdirname)
                    local_attachment_file_list.append(local_attachment_path)

                # create new list of dicts including info about the local files
                for some_file in local_attachment_file_list:
                    local_data_dict = file_to_local_data_dict(some_file, tmpdirname)
                    local_attachment_data_list_dicts.append(local_data_dict)
                    path_to_image = file_functions.fix_path(local_data_dict["filename"])
                    media_filepaths.append(path_to_image)

                print("hello")

                rich.print("media_filepaths -> ")
                rich.print(media_filepaths)

                print("standy")

                await ctx.send(
                    embed=discord.Embed(description=f"AutoResizing {media_filepaths}...."),
                    delete_after=30.0,
                )

                try:

                    for count, media_fpaths in enumerate(media_filepaths):
                        # compute all predictions first
                        full_path_input_file, full_path_output_file, get_timestamp = await details_from_file(
                            media_fpaths, cwd=f"{tmpdirname}"
                        )

                        ffmpeg_command = [
                            "ffmpeg",
                            "-y",
                            "-hide_banner",
                            "-loglevel",
                            "warning",
                            "-i",
                            f"{tmpdirname}/{full_path_input_file}",
                            "-c:v",
                            # "h264_videotoolbox",
                            "libx264",
                            "-bufsize",
                            "5200K",
                            "-b:v",
                            "5200K",
                            "-maxrate",
                            "5200K",
                            "-level",
                            "42",
                            "-bf",
                            "2",
                            "-g",
                            "63",
                            "-refs",
                            "4",
                            "-threads",
                            "16",
                            "-preset:v",
                            "fast",
                            "-vf",
                            "scale=1080:1080:force_original_aspect_ratio=decrease,pad=width=1080:height=1080:x=-1:y=-1:color=0x16202A",
                            "-c:a",
                            "aac",
                            "-ar",
                            "44100",
                            "-ac",
                            "2",
                            f"{tmpdirname}/{full_path_output_file}",
                        ]

                        _ = await shell._aio_run_process_and_communicate(ffmpeg_command, cwd=f"{tmpdirname}")

                        # nuke the originals
                        unlink_func = functools.partial(unlink_orig_file, media_fpaths)

                        # 2. Run in a custom thread pool:
                        with concurrent.futures.ThreadPoolExecutor() as pool:
                            unlink_result = await self.bot.loop.run_in_executor(pool, unlink_func)
                            rich.print(f"count: {count} - Unlink", unlink_result)
                        # await asyncio.sleep(1)

                        ######################################################
                        # compress the file if it is too large
                        ######################################################
                        compress_command = [
                            "compress-discord.sh",
                            f"{tmpdirname}/{full_path_output_file}",
                        ]

                        _ = await shell._aio_run_process_and_communicate(compress_command, cwd=f"{tmpdirname}")

                        ######################################################
                        # nuke the uncompressed version
                        ######################################################

                        LOGGER.info(f"nuking uncompressed: {tmpdirname}/{full_path_output_file}")

                        # nuke the originals
                        unlink_func = functools.partial(unlink_orig_file, f"{tmpdirname}/{full_path_output_file}")

                        # 2. Run in a custom thread pool:
                        with concurrent.futures.ThreadPoolExecutor() as pool:
                            unlink_result = await self.bot.loop.run_in_executor(pool, unlink_func)
                            rich.print(f"count: {count} - Unlink", unlink_result)

                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not download story...."))
                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    LOGGER.warning(output)
                    await ctx.send(embed=discord.Embed(description=output))
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                # Now that we are finished processing, we can upload the files to discord

                tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
                rich.print("tree_list ->")
                rich.print(tree_list)

                file_to_upload_list = [f"{p}" for p in tree_list]
                LOGGER.debug(f"{type(self).__name__} -> file_to_upload_list = {file_to_upload_list}")
                rich.print(file_to_upload_list)

                file_to_upload = file_functions.filter_media(file_to_upload_list)

                # ---------------------------------------------------------
                # chunked_lists = list(misc.divide_chunks(file_to_upload, n=10))
                # discord has a limit of 10 media uploads per api call. break them up.
                # SOURCE: https://www.geeksforgeeks.org/break-list-chunks-size-n-python/
                n = 2
                final = [file_to_upload[i * n : (i + 1) * n] for i in range((len(file_to_upload) + n - 1) // n)]

                for count, chunk in enumerate(final):
                    await ctx.send(
                        embed=discord.Embed(description=f"Uploading batch {count}...."),
                        delete_after=30.0,
                    )

                    my_files = []

                    for f in chunk:
                        rich.print(f)
                        my_files.append(discord.File(f"{f}"))

                    LOGGER.debug(f"{type(self).__name__} -> my_files = {my_files}")
                    rich.print(my_files)

                    try:
                        # msg: Message
                        _ = await ctx.send(files=my_files)
                    except Exception as ex:
                        await ctx.send(embed=discord.Embed(description="Could not upload story to discord...."))
                        print(ex)
                        exc_type, exc_value, exc_traceback = sys.exc_info()
                        LOGGER.error(f"Error Class: {str(ex.__class__)}")
                        output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                        LOGGER.warning(output)
                        await ctx.send(embed=discord.Embed(description=output))
                        LOGGER.error(f"exc_type: {exc_type}")
                        LOGGER.error(f"exc_value: {exc_value}")
                        traceback.print_tb(exc_traceback)

        await message.delete(delay=10)

        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, args = {args}")

    @commands.command(aliases=["arl"])
    async def autoresizelarge(self, ctx: commands.context.Context, *args) -> None:  # type:ignore
        """Autoresize videos to 1080x1080.

        Args:
            ctx (commands.context.Context): _description_
        """

        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, args = {args}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user: Optional[User]
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        message = ctx.message
        args = list(args)

        attachment_data_list_dicts = []
        local_attachment_file_list = []
        local_attachment_data_list_dicts = []
        media_filepaths = []

        for attm in message.attachments:
            data = attachment_to_dict(attm)
            attachment_data_list_dicts.append(data)

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                # return a list of strings pointing to the downloaded files
                for an_attachment_dict in attachment_data_list_dicts:
                    local_attachment_path = await handle_save_attachment_locally(an_attachment_dict, tmpdirname)
                    local_attachment_file_list.append(local_attachment_path)

                # create new list of dicts including info about the local files
                for some_file in local_attachment_file_list:
                    local_data_dict = file_to_local_data_dict(some_file, tmpdirname)
                    local_attachment_data_list_dicts.append(local_data_dict)
                    path_to_image = file_functions.fix_path(local_data_dict["filename"])
                    media_filepaths.append(path_to_image)

                print("hello")

                rich.print("media_filepaths -> ")
                rich.print(media_filepaths)

                print("standy")

                await ctx.send(
                    embed=discord.Embed(description=f"AutoResizing {media_filepaths}...."),
                    delete_after=30.0,
                )

                try:

                    for count, media_fpaths in enumerate(media_filepaths):
                        # compute all predictions first
                        full_path_input_file, full_path_output_file, get_timestamp = await details_from_file(
                            media_fpaths, cwd=f"{tmpdirname}"
                        )

                        ffmpeg_command = [
                            "ffmpeg",
                            "-y",
                            "-hide_banner",
                            "-loglevel",
                            "warning",
                            "-i",
                            f"{tmpdirname}/{full_path_input_file}",
                            "-c:v",
                            # "h264_videotoolbox",
                            "libx264",
                            "-bufsize",
                            "5200K",
                            "-b:v",
                            "5200K",
                            "-maxrate",
                            "5200K",
                            "-level",
                            "42",
                            "-bf",
                            "2",
                            "-g",
                            "63",
                            "-refs",
                            "4",
                            "-threads",
                            "16",
                            "-preset:v",
                            "fast",
                            "-vf",
                            "scale=1080:1350:force_original_aspect_ratio=decrease,pad=width=1080:height=1350:x=-1:y=-1:color=0x16202A",
                            "-c:a",
                            "aac",
                            "-ar",
                            "44100",
                            "-ac",
                            "2",
                            f"{tmpdirname}/{full_path_output_file}",
                        ]

                        _ = await shell._aio_run_process_and_communicate(ffmpeg_command, cwd=f"{tmpdirname}")

                        # nuke the originals
                        unlink_func = functools.partial(unlink_orig_file, media_fpaths)

                        # 2. Run in a custom thread pool:
                        with concurrent.futures.ThreadPoolExecutor() as pool:
                            unlink_result = await self.bot.loop.run_in_executor(pool, unlink_func)
                            rich.print(f"count: {count} - Unlink", unlink_result)
                        # await asyncio.sleep(1)

                        ######################################################
                        # compress the file if it is too large
                        ######################################################
                        compress_command = [
                            "compress-discord.sh",
                            f"{tmpdirname}/{full_path_output_file}",
                        ]

                        _ = await shell._aio_run_process_and_communicate(compress_command, cwd=f"{tmpdirname}")

                        ######################################################
                        # nuke the uncompressed version
                        ######################################################

                        LOGGER.info(f"nuking uncompressed: {tmpdirname}/{full_path_output_file}")

                        # nuke the originals
                        unlink_func = functools.partial(unlink_orig_file, f"{tmpdirname}/{full_path_output_file}")

                        # 2. Run in a custom thread pool:
                        with concurrent.futures.ThreadPoolExecutor() as pool:
                            unlink_result = await self.bot.loop.run_in_executor(pool, unlink_func)
                            rich.print(f"count: {count} - Unlink", unlink_result)

                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not download story...."))
                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    LOGGER.warning(output)
                    await ctx.send(embed=discord.Embed(description=output))
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                # Now that we are finished processing, we can upload the files to discord

                tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
                rich.print("tree_list ->")
                rich.print(tree_list)

                file_to_upload_list = [f"{p}" for p in tree_list]
                LOGGER.debug(f"{type(self).__name__} -> file_to_upload_list = {file_to_upload_list}")
                rich.print(file_to_upload_list)

                file_to_upload = file_functions.filter_media(file_to_upload_list)

                # ---------------------------------------------------------
                # chunked_lists = list(misc.divide_chunks(file_to_upload, n=10))
                # discord has a limit of 10 media uploads per api call. break them up.
                # SOURCE: https://www.geeksforgeeks.org/break-list-chunks-size-n-python/
                n = 2
                final = [file_to_upload[i * n : (i + 1) * n] for i in range((len(file_to_upload) + n - 1) // n)]

                for count, chunk in enumerate(final):
                    await ctx.send(
                        embed=discord.Embed(description=f"Uploading batch {count}...."),
                        delete_after=30.0,
                    )

                    my_files = []

                    for f in chunk:
                        rich.print(f)
                        my_files.append(discord.File(f"{f}"))

                    LOGGER.debug(f"{type(self).__name__} -> my_files = {my_files}")
                    rich.print(my_files)

                    try:
                        # msg: Message
                        _ = await ctx.send(files=my_files)
                    except Exception as ex:
                        await ctx.send(embed=discord.Embed(description="Could not upload story to discord...."))
                        print(ex)
                        exc_type, exc_value, exc_traceback = sys.exc_info()
                        LOGGER.error(f"Error Class: {str(ex.__class__)}")
                        output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                        LOGGER.warning(output)
                        await ctx.send(embed=discord.Embed(description=output))
                        LOGGER.error(f"exc_type: {exc_type}")
                        LOGGER.error(f"exc_value: {exc_value}")
                        traceback.print_tb(exc_traceback)

        await message.delete(delay=10)

        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, args = {args}")


async def setup(cerebro: Cerebro) -> None:
    await cerebro.add_cog(AutoResize(cerebro))

</document_content>
</document>
<document index="4">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/cogs/cog.template</source>
<document_content>
import discord
from discord.ext import commands


class Name(commands.Cog):
    def __init__(self, bot):
        self.bot = bot

    @commands.Cog.listener()
    async def on_ready(self):
        print(f'{type(self).__name__} Cog ready.')


def setup(bot):
    bot.add_cog(Name(bot))
</document_content>
</document>
<document index="5">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/cogs/cookies.py</source>
<document_content>
"""cerebro_bot.cogs.cookies"""
import asyncio
import logging
import os
import sys
import tempfile
import traceback

from codetiming import Timer
import discord
from discord.ext import commands
from redis.asyncio import ConnectionPool, Redis

from cerebro_bot import db, shell
from cerebro_bot.bot_logger import get_logger
from cerebro_bot.constants import CURRENT_USER
from cerebro_bot.factories import cmd_factory, guild_factory

# DISCORD_GUILD = os.environ.get("DISCORD_SERVER_ID")

LOGGER = get_logger(__name__, provider="Cookies", level=logging.DEBUG)

UNI_USER_COMMAND = """
cp -av ~/.config/gallery-dl/universityofprofessorex-cookies-instagram.txt ~/.config/gallery-dl/cookies-instagram.txt
"""

REACT_USER_COMMAND = """
cp -av ~/.config/gallery-dl/reactionmemestv-cookies-instagram.txt ~/.config/gallery-dl/cookies-instagram.txt
"""

HLM_USER_COMMAND = """
cp -av ~/.config/gallery-dl/hlm-cookies-instagram.txt ~/.config/gallery-dl/cookies-instagram.txt
"""

WAVY_USER_COMMAND = """
cp -av ~/.config/gallery-dl/wavy-cookies-instagram.txt ~/.config/gallery-dl/cookies-instagram.txt
"""


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/133702ceb8682ec3927530ac35ad28d47a42802e/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/cogs/settings.py
class Cookies(commands.Cog):
    def __init__(self, cerebro):
        self.bot = cerebro
        self.current_user = None

    @commands.Cog.listener()
    async def on_ready(self):
        # global CURRENT_USER
        print(f"{type(self).__name__} Cog ready.")

        ret = await db.get_redis_value("cerebro_cookies", self.bot.db)

        self.current_user = f"{ret.value}" if ret else "n/a"

    @commands.Cog.listener()
    async def on_guild_join(self, guild):
        """Add new guilds to the database"""
        _ = await guild_factory.Guild(id=guild.id)

    # $dl_metadata https://www.instagram.com/p/CUiQyYcFGsb/
    # gallery-dl --user-agent Wget/1.21.1 -v -u professorex.university@gmail.com https://www.instagram.com/p/CUiQyYcFGsb/
    @commands.command()
    async def cookies(self, ctx, uri: str = None):
        """*Use cookies to change gallery_dl cookies*
        **Example**: `{cookies}cookies !`
        """
        # global CURRENT_USER

        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, uri = {uri}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        # DMChannel
        # ---------------------------------------------------------------

        if "uni" in uri:
            print("GOT uni")
            cmd_args = ["cookies"]
            cmd_kargs = {
                "cmd": UNI_USER_COMMAND,
                "uri": f"{uri}",
            }
            self.current_user = "professorex.university@gmail.com"
        elif "react" in uri:
            print("GOT react")
            cmd_args = ["cookies"]
            cmd_kargs = {
                "cmd": REACT_USER_COMMAND,
                "uri": f"{uri}",
            }
            self.current_user = "reactionmemestv@gmail.com"
        elif "wavy" in uri:
            print("GOT wavy")
            cmd_args = ["cookies"]
            cmd_kargs = {
                "cmd": WAVY_USER_COMMAND,
                "uri": f"{uri}",
            }
            self.current_user = "iam.wavy.memes@gmail.com"
        elif "hlm" in uri:
            print("GOT hlm")
            cmd_args = ["cookies"]
            cmd_kargs = {
                "cmd": HLM_USER_COMMAND,
                "uri": f"{uri}",
            }
            self.current_user = "iamhoeslikememes@gmail.com"

        cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

        LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                await ctx.send(
                    embed=discord.Embed(description="Running ...."),
                    delete_after=25.0,
                )

                try:
                    dbg = await asyncio.gather(
                        asyncio.create_task(
                            shell.run_coroutine_subprocess(
                                cmd=cmd_metadata.cmd,
                                uri=cmd_metadata.uri,
                                working_dir=f"{tmpdirname}",
                            )
                        ),
                    )

                    await ctx.send(embed=discord.Embed(description=f"Cookies switched to {self.current_user} | {dbg}"))

                    persist_data = db.RedisValueDTO(key="cerebro_cookies", value=f"{self.current_user}")

                    await db.set_redis_value(persist_data, self.bot.db)

                except Exception as ex:
                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    tb_str = "".join(traceback.format_exception(etype=type(ex), value=ex, tb=ex.__traceback__))
                    await ctx.send(embed=discord.Embed(description=f"{tb_str}"))
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    await ctx.send(embed=discord.Embed(description=f"{output}"))
                    LOGGER.warning(output)
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

    @cookies.error
    async def cookies_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(
                    description="Sorry, you need `MANAGE SERVER` permissions to change the dl_metadata!"
                )
            )

    # $dl_metadata https://www.instagram.com/p/CUiQyYcFGsb/
    # gallery-dl --user-agent Wget/1.21.1 -v -u professorex.university@gmail.com https://www.instagram.com/p/CUiQyYcFGsb/
    @commands.command()
    async def cookies_user(self, ctx):
        """*Use cookies to change gallery_dl cookies*
        **Example**: `{cookies}cookies !`
        """

        await ctx.send(embed=discord.Embed(description=f"Cookies user {self.current_user}"))

    @cookies_user.error
    async def cookies_user_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(
                    description="Sorry, you need `MANAGE SERVER` permissions to change the dl_metadata!"
                )
            )


async def setup(cerebro):
    await cerebro.add_cog(Cookies(cerebro))

</document_content>
</document>
<document index="6">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/cogs/facebook.py</source>
<document_content>
"""cerebro_bot.cogs.facebook"""
import asyncio
import logging
import pathlib
import sys
import tempfile
import traceback
from typing import Optional

import aiohttp
from codetiming import Timer
import discord
from discord.ext import commands
from discord.message import Message
from discord.user import User
import uritools

from cerebro_bot import constants, shell
from cerebro_bot.bot_logger import get_logger
from cerebro_bot.factories import cmd_factory, guild_factory
from cerebro_bot.utils import aiodbx
from cerebro_bot.utils.file_functions import glob_file_by_extension

# DISCORD_GUILD = os.environ.get("DISCORD_SERVER_ID")

LOGGER = get_logger(__name__, provider="Facebook", level=logging.DEBUG)

# SOURCE: https://github.com/yt-dlp/yt-dlp/issues/4101
FB_SAFE_COMMAND = """

yt-dlp -v -f best --ignore-errors --restrict-filenames --write-thumbnail --embed-thumbnail --no-mtime --recode-video mp4 --cookies-from-browser firefox --write-info-json {dl_uri}

if [ "$?" != "0" ]; then
        echo \"Trying yt-best instead\"

        yt-dlp -v -f best --ignore-errors --restrict-filenames --no-mtime --recode-video mp4 --cookies-from-browser firefox --write-info-json {dl_uri}
fi
"""

# python3


async def expandURL(link: str):
    async with aiohttp.ClientSession() as session:
        async with session.head(link) as response:
            expanded = await response.getheader("location")
    # conn = http.client.HTTPSConnection('bit.ly')  # use HTTPS !
    # conn.request('HEAD', '/foobar')
    # response = conn.getresponse()
    return expanded


# SOURCE: https://www.programcreek.com/python/?project_name=athphane%2Fuserbot#
async def expand_url(url: str):
    async with aiohttp.ClientSession() as session:
        async with session.get(f"http://expandurl.com/api/v1/?url={url}") as resp:
            expanded = await resp.text()

        return expanded if expanded != "false" and expanded[:-1] != url else None


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/133702ceb8682ec3927530ac35ad28d47a42802e/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/cogs/settings.py
class Facebook(commands.Cog):
    def __init__(self, cerebro):
        self.bot = cerebro

    @commands.Cog.listener()
    async def on_ready(self):
        print(f"{type(self).__name__} Cog ready.")

    @commands.Cog.listener()
    async def on_guild_join(self, guild):
        """Add new guilds to the database"""
        _ = await guild_factory.Guild(id=guild.id)

    # $facebook https://www.reddit.com/r/TikTok_Ass/comments/r352rg/hit_it_for_me_one_time/
    # @commands.command()
    @commands.command(aliases=["fb", "face"])
    async def facebook(self, ctx, uri: str = None):
        """*Use youtube_dl to download video with thumbnail facebook*
        **Example**: `{facebook}facebook !`
        """
        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, uri = {uri}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user: Optional[User]
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        # DMChannel
        # ---------------------------------------------------------------
        dl_uri = uritools.urisplit(uri)

        expanded = False

        if dl_uri.authority == "fb.watch":
            expanded = await expand_url(f"{dl_uri.geturi()}")
            LOGGER.error(f"EXPANDED {expanded}")

        if expanded:
            dl_uri = uritools.urisplit(expanded)

        cmd_args = ["facebook"]
        cmd_kargs = {
            "cmd": FB_SAFE_COMMAND.format(dl_uri=dl_uri.geturi()),
            "uri": f"{dl_uri.geturi()}",
        }

        # If downloading facebook, we use it without the login flags, cause it makes FB act funny
        if dl_uri.authority in ["fb.watch", "facebook"]:
            cmd_kargs = {
                "cmd": FB_SAFE_COMMAND.format(dl_uri=dl_uri.geturi()),
                "uri": f"{dl_uri.geturi()}",
            }

        cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

        LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

        await ctx.send(
            embed=discord.Embed(description=f"Downloading {cmd_metadata.uri} ...."),
            delete_after=25.0,
        )

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                try:
                    await asyncio.gather(
                        asyncio.create_task(
                            shell.run_coroutine_subprocess(
                                cmd=cmd_metadata.cmd,
                                uri=cmd_metadata.uri,
                                working_dir=f"{tmpdirname}",
                            )
                        ),
                    )

                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not upload story to discord...."))
                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    await ctx.send(embed=discord.Embed(description=f"{output}"))
                    LOGGER.warning(output)
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                await ctx.send(
                    embed=discord.Embed(description=f"Success, downloaded {cmd_metadata.uri}"),
                    delete_after=25.0,
                )

                file_to_upload_list = glob_file_by_extension(f"{tmpdirname}", extension="*.mp4")

                file_to_upload = f"{file_to_upload_list[0]}"

                if pathlib.Path(file_to_upload).stat().st_size > constants.MAX_BYTES_UPLOAD_DISCORD:
                    msg_upload = await ctx.send(
                        embed=discord.Embed(
                            description=f"File is over 8MB... Uploading to dropbox -> {file_to_upload}...."
                        )
                    )
                    await msg_upload.delete()

                    await aiodbx.dropbox_upload(file_to_upload_list)

                    await ctx.send(
                        embed=discord.Embed(
                            description=f"File successfully uploaded to dropbox! -> {file_to_upload}...."
                        )
                    )

                else:
                    msg_upload = await ctx.send(
                        embed=discord.Embed(description=f"Uploading to discord -> {file_to_upload}....")
                    )

                    msg: Message
                    await ctx.send(file=discord.File(f"{file_to_upload}"))
                    await msg_upload.delete()
                    # await msg.pin()

    @facebook.error
    async def facebook_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(description="Sorry, you need `MANAGE SERVER` permissions to change the facebook!")
            )


async def setup(cerebro):
    await cerebro.add_cog(Facebook(cerebro))

</document_content>
</document>
<document index="7">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/cogs/imagemagick.py</source>
<document_content>
"""cerebro_bot.cogs.imagemagick"""
from __future__ import annotations

import asyncio
import concurrent.futures
import functools

# pylint: disable=no-member
import logging
import os
import os.path
import pathlib
import sys
import tempfile
import traceback
import typing
from typing import Optional

from codetiming import Timer
import discord
from discord.ext import commands
from discord.message import Message
from discord.user import User
import rich

from cerebro_bot import shell
from cerebro_bot.bot_logger import get_logger
from cerebro_bot.factories import cmd_factory, guild_factory
from cerebro_bot.utils import file_functions
from cerebro_bot.utils.imgops import handle_get_dominant_color

if typing.TYPE_CHECKING:
    from cerebro_bot.bot import Cerebro

# DISCORD_GUILD = os.environ.get("DISCORD_SERVER_ID")

LOGGER = get_logger(__name__, provider="Imagemagick", level=logging.DEBUG)

IMAGEMAGICK_RESIZE_SQUARE_LARGE_CUSTOM_COLOR = """
convert -size 1080x1350 canvas:{color_name} \"{white_background_output_file_str}\"
magick \"{full_path_input_file}\" -resize 1080x1350 -background {color_name} -compose Copy -gravity center -extent 1080x1350 -quality 92 \"{full_path_output_file}\"
"""


def unlink_orig_image(images_filepath: str):
    # for orig_to_rm in images_filepaths:
    rich.print(f"deleting ... {images_filepath}")
    os.unlink(f"{images_filepath}")
    return images_filepath


def unique_list(
    list1: typing.Union[typing.List[str], typing.List[bytes]]
) -> typing.Union[typing.List[str], typing.List[bytes]]:
    # insert the list to the set
    list_set = set(list1)
    return list(list_set)


# https://github.com/discord-math/bot/blob/babb41b71a68b4b099684b3e1ed583f84083f971/plugins/log.py#L63
def path_for(attm: discord.Attachment, basedir: str = "./") -> pathlib.Path:
    p = pathlib.Path(basedir, str(attm.filename))
    LOGGER.debug(f"path_for: p -> {p}")
    return p


# https://github.com/discord-math/bot/blob/babb41b71a68b4b099684b3e1ed583f84083f971/plugins/log.py#L63
async def save_attachment(attm: discord.Attachment, basedir: str = "./") -> None:
    path = path_for(attm, basedir=basedir)
    LOGGER.debug(f"save_attachment: path -> {path}")
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        ret_code = await attm.save(path, use_cached=True)
        await asyncio.sleep(5)
    except discord.HTTPException:
        await attm.save(path)


# TODO: Remove this when we eventually upgrade to 2.0 discord.py
def attachment_to_dict(attm: discord.Attachment):
    result = {
        "filename": attm.filename,
        "id": attm.id,
        "proxy_url": attm.proxy_url,
        "size": attm.size,
        "url": attm.url,
        "spoiler": attm.is_spoiler(),
    }
    if attm.height:
        result["height"] = attm.height
    if attm.width:
        result["width"] = attm.width
    if attm.content_type:
        result["content_type"] = attm.content_type

    result["attachment_obj"] = attm

    return result


def file_to_local_data_dict(fname: str, dir_root: str):
    file_api = pathlib.Path(fname)
    return {
        "filename": f"{dir_root}/{file_api.stem}{file_api.suffix}",
        "size": file_api.stat().st_size,
        "ext": f"{file_api.suffix}",
        "api": file_api,
    }


async def handle_save_attachment_locally(attm_data_dict, dir_root):
    # attm_data_dict_copy = copy.copy(attm_data_dict)
    fname = f"{dir_root}/orig_{attm_data_dict['id']}_{attm_data_dict['filename']}"
    rich.print(f"Saving to ... {fname}")
    await attm_data_dict["attachment_obj"].save(fname, use_cached=True)
    await asyncio.sleep(1)
    # attm_data_dict["local_file"] = fname
    return fname


def get_imagemagick_resize_square_filename(p: pathlib.Path):
    """programatically create square up file name outputs.
    Args:
        fileinfo (fileobject.FileInfo): [description]
    Returns:
        [type]: [description]
    """
    # eg. data/fixtures/ig-square-1080x1080-00000-gif1-farming.mp4

    output_file_str = f"{p.parent}/{p.stem}_out{p.suffix}"

    # eg. <fileobject.FileInfo(00000-gif1-farming.jpeg)>
    output_file = pathlib.Path(output_file_str)

    # eg. /Users/malcolm/dev/universityofprofessorex/ffmpeg-tools/data/fixtures/00000-gif1-farming.jpeg
    full_path_output_file = f"{output_file.absolute()}"

    white_background_output_file_str = f"{p.parent}/white.jpg"

    return (
        output_file_str,
        output_file,
        full_path_output_file,
        white_background_output_file_str,
    )


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/133702ceb8682ec3927530ac35ad28d47a42802e/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/cogs/settings.py
class Imagemagick(commands.Cog):
    def __init__(self, cerebro: Cerebro):
        self.bot = cerebro

    @commands.Cog.listener()
    async def on_ready(self) -> None:
        print(f"{type(self).__name__} Cog ready.")

    @commands.Cog.listener()
    async def on_guild_join(self, guild: guild_factory.Guild) -> None:
        """Add new guilds to the database"""
        _ = await guild_factory.Guild(id=guild.id)

    @commands.command(aliases=["cr"])
    async def color_resize(self, ctx: commands.context.Context, *args) -> None:  # type:ignore
        """`$autocrop [model]` // Imagemagicks attached image using specified model. Model name input will be automatically matched with the closest model name.

        `$autocrop [url] [model]` // Imagemagicks linked image using specified model. Model name input will be automatically matched with the closest model name.

        Optional `$autocrop` args:

        `$downscale [amount]` // Downscales the image by the amount listed. For example, `$downscale 4` will make the image 25% of its original size.

        `$filter [filter]` // Filter to be used for downscaling. Must be a valid OpenCV image interpolation filter, with ImageMagick aliases supported as well. Defaults to box/area.

        `$blur [type] [amount]` // Blurs the image before upscaling using the specified blur type and the amount specified. Only Gaussian and median blur are currently supported.

        `$montage` // Creates aside by side comparison of the LR and result after upscaling.

        `$seamless` // Duplicates the image around the edges to make a seamless texture retain its seamlessness

        Example: `$autocrop www.imageurl.com/image.png 4xBox.pth $downscale 4 $filter point $montage`
        """

        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, args = {args}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user: Optional[User]
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        message = ctx.message
        args = list(args)

        attachment_data_list_dicts = []
        local_attachment_file_list = []
        local_attachment_data_list_dicts = []
        images_filepaths = []

        for attm in message.attachments:
            data = attachment_to_dict(attm)
            attachment_data_list_dicts.append(data)

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                # return a list of strings pointing to the downloaded files
                for an_attachment_dict in attachment_data_list_dicts:
                    local_attachment_path = await handle_save_attachment_locally(an_attachment_dict, tmpdirname)
                    local_attachment_file_list.append(local_attachment_path)

                # create new list of dicts including info about the local files
                for some_file in local_attachment_file_list:
                    local_data_dict = file_to_local_data_dict(some_file, tmpdirname)
                    local_attachment_data_list_dicts.append(local_data_dict)
                    path_to_image = file_functions.fix_path(local_data_dict["filename"])
                    images_filepaths.append(path_to_image)

                print("hello")

                # import bpdb
                # bpdb.set_trace()
                rich.print("images_filepaths -> ")
                rich.print(images_filepaths)

                print("standy")

                # now it is time to autocrop everything

                await ctx.send(
                    embed=discord.Embed(description=f"Resizing {images_filepaths}...."),
                    delete_after=30.0,
                )

                try:
                    for count, img_fpaths in enumerate(images_filepaths):
                        cmd_args = ["color_resize"]

                        full_path_input_file = f"{img_fpaths}"
                        full_path_input_file_api = pathlib.Path(full_path_input_file)

                        color_name = handle_get_dominant_color([full_path_input_file], return_type="hex")

                        (
                            output_file_str,
                            output_file,
                            full_path_output_file,
                            white_background_output_file_str,
                        ) = get_imagemagick_resize_square_filename(full_path_input_file_api)

                        cmd_kargs = {
                            "cmd": IMAGEMAGICK_RESIZE_SQUARE_LARGE_CUSTOM_COLOR.format(
                                full_path_input_file=full_path_input_file,
                                full_path_output_file=full_path_output_file,
                                white_background_output_file_str=white_background_output_file_str,
                                color_name=f"'{color_name}'",
                            ),
                            "uri": "",
                        }

                        cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

                        LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

                        dbg = await asyncio.gather(
                            asyncio.create_task(
                                shell.run_coroutine_subprocess(
                                    cmd=cmd_metadata.cmd,
                                    uri=cmd_metadata.uri,
                                    working_dir=f"{tmpdirname}",
                                )
                            ),
                        )
                        await ctx.send(
                            embed=discord.Embed(description=f"Success, resized {full_path_input_file}"),
                            delete_after=25.0,
                        )

                        # nuke the originals
                        unlink_func = functools.partial(unlink_orig_image, img_fpaths)

                        # 2. Run in a custom thread pool:
                        with concurrent.futures.ThreadPoolExecutor() as pool:
                            unlink_result = await self.bot.loop.run_in_executor(pool, unlink_func)
                            rich.print(f"count: {count} - Unlink", unlink_result)
                        await asyncio.sleep(1)

                        # nuke the background image
                        unlink_func = functools.partial(unlink_orig_image, white_background_output_file_str)

                        # 2. Run in a custom thread pool:
                        with concurrent.futures.ThreadPoolExecutor() as pool:
                            unlink_result = await self.bot.loop.run_in_executor(pool, unlink_func)
                            rich.print(f"count: {count} - Unlink", unlink_result)
                        await asyncio.sleep(1)

                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not download story...."))
                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    LOGGER.warning(output)
                    await ctx.send(embed=discord.Embed(description=output))
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
                rich.print("tree_list ->")
                rich.print(tree_list)

                file_to_upload_list = [f"{p}" for p in tree_list]
                LOGGER.debug(f"{type(self).__name__} -> file_to_upload_list = {file_to_upload_list}")
                rich.print(file_to_upload_list)

                file_to_upload = file_functions.filter_media(file_to_upload_list)

                # ---------------------------------------------------------
                # chunked_lists = list(misc.divide_chunks(file_to_upload, n=10))
                # discord has a limit of 10 media uploads per api call. break them up.
                # SOURCE: https://www.geeksforgeeks.org/break-list-chunks-size-n-python/
                n = 2
                final = [file_to_upload[i * n : (i + 1) * n] for i in range((len(file_to_upload) + n - 1) // n)]

                for count, chunk in enumerate(final):
                    await ctx.send(
                        embed=discord.Embed(description=f"Uploading batch {count}...."),
                        delete_after=30.0,
                    )

                    my_files = []

                    for f in chunk:
                        rich.print(f)
                        my_files.append(discord.File(f"{f}"))

                    LOGGER.debug(f"{type(self).__name__} -> my_files = {my_files}")
                    rich.print(my_files)

                    try:
                        msg: Message
                        msg = await ctx.send(files=my_files)
                    except Exception as ex:
                        await ctx.send(embed=discord.Embed(description="Could not upload story to discord...."))
                        print(ex)
                        exc_type, exc_value, exc_traceback = sys.exc_info()
                        LOGGER.error(f"Error Class: {str(ex.__class__)}")
                        output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                        LOGGER.warning(output)
                        await ctx.send(embed=discord.Embed(description=output))
                        LOGGER.error(f"exc_type: {exc_type}")
                        LOGGER.error(f"exc_value: {exc_value}")
                        traceback.print_tb(exc_traceback)

        await message.delete(delay=10)

        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, args = {args}")


async def setup(cerebro: Cerebro) -> None:
    await cerebro.add_cog(Imagemagick(cerebro))

</document_content>
</document>
<document index="8">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/cogs/instagram.py</source>
<document_content>
"""cerebro_bot.cogs.instagram"""
import asyncio
import json
import logging
import pathlib
import subprocess
import sys
import tempfile
import traceback
from typing import Optional

from codetiming import Timer
import discord
from discord.ext import commands
from discord.message import Message
from discord.user import User
import rich
import uritools

from cerebro_bot import constants, shell
from cerebro_bot.bot_logger import get_logger
from cerebro_bot.factories import cmd_factory, guild_factory
from cerebro_bot.types import JSONType
from cerebro_bot.utils import aiodbx, events, file_functions

# DISCORD_GUILD = os.environ.get("DISCORD_SERVER_ID")

LOGGER = get_logger(__name__, provider="Instagram", level=logging.DEBUG)

GET_METADATA_JSON_COMMAND = """
gallery-dl --no-mtime --user-agent Wget/1.21.1 -u {constants.CURRENT_USER} -j {dl_uri}
"""

# depricated for IG
DL_DOWNLOAD_COMMAND = """
gallery-dl --no-mtime --user-agent Wget/1.21.1 -v --write-info-json --write-metadata {dl_uri}

if [ "$?" != "0" ]; then
    echo \"Trying with netrc instead instead\"
    gallery-dl --clear-cache instagram
    gallery-dl --no-mtime --netrc --user-agent Wget/1.21.1 -v --write-info-json --write-metadata {dl_uri}
fi
"""

# cookies only method specifically for instagram
DL_DOWNLOAD_COMMAND_SAFE = """
gallery-dl --no-mtime --cookies ~/.config/gallery-dl/cookies-instagram.txt --user-agent Wget/1.21.1 -v --write-info-json --write-metadata {dl_uri}

if [ "$?" != "0" ]; then
    echo \"Trying with clear cache first instead instead\"
    gallery-dl --clear-cache instagram
    gallery-dl --no-mtime --cookies ~/.config/gallery-dl/cookies-instagram.txt --user-agent Wget/1.21.1 -v --write-info-json --write-metadata {dl_uri}
fi
"""

TWITTER_DL_DOWNLOAD_COMMAND_SAFE = """
gallery-dl --no-mtime --cookies ~/.config/gallery-dl/cookies-twitter.txt --user-agent Wget/1.21.1 -v --write-info-json --write-metadata {dl_uri}

if [ "$?" != "0" ]; then
    gallery-dl --no-mtime --cookies ~/.config/gallery-dl/cookies-twitter.txt --user-agent Wget/1.21.1 -v --write-info-json --write-metadata {dl_uri}
fi
"""

REDDIT_DL_DOWNLOAD_COMMAND_SAFE = """
gallery-dl --no-mtime --cookies ~/.config/gallery-dl/cookies-reddit.txt --user-agent Wget/1.21.1 -v --write-info-json --write-metadata {dl_uri}

if [ "$?" != "0" ]; then
    gallery-dl --no-mtime --cookies ~/.config/gallery-dl/cookies-reddit.txt --user-agent Wget/1.21.1 -v --write-info-json --write-metadata {dl_uri}
fi
"""

# depricated for IG
DL_STORY_COMMAND = """
gallery-dl --user-agent Wget/1.21.1 -v -u {constants.CURRENT_USER} --write-info-json --write-metadata {dl_uri}

# We use single brackets since this is using /bin/sh
if [ "$?" != "0" ]; then
    echo \"Trying with netrc instead instead\"
    gallery-dl --clear-cache instagram

    gallery-dl --no-mtime --netrc --user-agent Wget/1.21.1 -v -u {constants.CURRENT_USER} --write-info-json --write-metadata {dl_uri}
fi
"""

# cookies only method specifically for instagram
DL_STORY_COMMAND_SAFE = """
gallery-dl --user-agent Wget/1.21.1 -v --write-info-json --write-metadata {dl_uri}

# We use single brackets since this is using /bin/sh
if [ "$?" != "0" ]; then
    echo \"Trying with clear cache first instead instead\"
    gallery-dl --clear-cache instagram

    gallery-dl --no-mtime --user-agent Wget/1.21.1 -v --write-info-json --write-metadata {dl_uri}
fi
"""


def run_get_metadata_json(uri: str) -> Optional[JSONType]:
    dl_uri = uritools.urisplit(uri)
    dl_uri = f"{dl_uri.geturi()}"
    cmd = GET_METADATA_JSON_COMMAND.format(dl_uri=dl_uri)
    jsonstr = subprocess.check_output(cmd, shell=True, encoding="utf-8")
    return json.loads(jsonstr)


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/133702ceb8682ec3927530ac35ad28d47a42802e/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/cogs/settings.py
class Instagram(commands.Cog):
    def __init__(self, cerebro):
        self.bot = cerebro

    @commands.Cog.listener()
    async def on_ready(self):
        print(f"{type(self).__name__} Cog ready.")

    @commands.Cog.listener()
    async def on_guild_join(self, guild):
        """Add new guilds to the database"""
        _ = await guild_factory.Guild(id=guild.id)

    # $dl_download https://www.instagram.com/p/CUiQyYcFGsb/
    # $dl_download https://www.instagram.com/p/CUiVmWflehZ/
    # gallery-dl --user-agent Wget/1.21.1 -v -u {constants.CURRENT_USER} https://www.instagram.com/p/CUiQyYcFGsb/
    # @commands.command()
    @commands.command(aliases=["dl", "ig", "instagram", "i"])
    async def dl_download(self, ctx, uri: str = None):
        """*Use dl_download to download video with thumbnail dl_download*
        **Example**: `{dl_download}dl_download !`
        """
        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, uri = {uri}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user: Optional[User]
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        # DMChannel
        # ---------------------------------------------------------------
        dl_uri = uritools.urisplit(uri)
        cmd_args = ["dl_download"]
        cmd_kargs = {
            "cmd": DL_DOWNLOAD_COMMAND.format(dl_uri=dl_uri.geturi()),
            "uri": f"{dl_uri.geturi()}",
        }

        # If downloading from instagram itself, we use it without the login flags, cause it makes IG act funny
        if dl_uri.authority == "instagram":
            cmd_kargs = {
                "cmd": DL_DOWNLOAD_COMMAND_SAFE.format(dl_uri=dl_uri.geturi()),
                "uri": f"{dl_uri.geturi()}",
            }

        if dl_uri.authority in ["twitter", "t.co"]:
            cmd_kargs = {
                "cmd": TWITTER_DL_DOWNLOAD_COMMAND_SAFE.format(dl_uri=dl_uri.geturi()),
                "uri": f"{dl_uri.geturi()}",
            }

        if dl_uri.authority in ["reddit", "redd.it"]:
            cmd_kargs = {
                "cmd": REDDIT_DL_DOWNLOAD_COMMAND_SAFE.format(dl_uri=dl_uri.geturi()),
                "uri": f"{dl_uri.geturi()}",
            }

        cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

        LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                await ctx.send(
                    embed=discord.Embed(description="Beginning download ...."),
                    delete_after=25.0,
                )

                try:
                    dbg = await asyncio.gather(
                        asyncio.create_task(
                            shell.run_coroutine_subprocess(
                                cmd=cmd_metadata.cmd,
                                uri=cmd_metadata.uri,
                                working_dir=f"{tmpdirname}",
                            )
                        ),
                    )
                    await ctx.send(
                        embed=discord.Embed(description=f"Success, downloaded {cmd_metadata.uri}"),
                        delete_after=25.0,
                    )

                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not upload story to discord...."))

                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    tb_str = "".join(traceback.format_exception(etype=type(ex), value=ex, tb=ex.__traceback__))
                    await ctx.send(embed=discord.Embed(description=f"{tb_str}"))
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    await ctx.send(embed=discord.Embed(description=f"{output}"))
                    LOGGER.warning(output)
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
                rich.print(tree_list)

                file_to_upload_list = [f"{p}" for p in tree_list]
                LOGGER.debug(f"{type(self).__name__} -> file_to_upload_list = {file_to_upload_list}")
                rich.print(file_to_upload_list)

                file_to_upload = file_functions.filter_media(file_to_upload_list)

                LOGGER.debug(f"{type(self).__name__} -> file_to_upload = {file_to_upload}")

                await ctx.send(
                    f"{type(self).__name__} -> file_to_upload = {file_to_upload}",
                    delete_after=25.0,
                )

                rich.print(file_to_upload)

                await ctx.send(
                    embed=discord.Embed(description=f"Uploading to discord -> {file_to_upload}...."),
                    delete_after=25.0,
                )

                my_files = []

                is_dropbox_upload = False

                for f in file_to_upload:
                    rich.print(f)

                    if pathlib.Path(f).stat().st_size > constants.MAX_BYTES_UPLOAD_DISCORD:
                        await ctx.send(
                            embed=discord.Embed(
                                description=f"File is over 8MB... Uploading to dropbox -> {file_to_upload}...."
                            ),
                            delete_after=25.0,
                        )

                        to_upload_list = [f]
                        await aiodbx.dropbox_upload(to_upload_list)

                        is_dropbox_upload = True

                        await ctx.send(
                            embed=discord.Embed(description=f"File successfully uploaded to dropbox! -> {f}....")
                        )
                    else:
                        my_files.append(discord.File(f"{f}"))

                LOGGER.debug(f"{type(self).__name__} -> my_files = {my_files}")
                rich.print(my_files)

                try:
                    # bugfix?
                    # recipient_user: Optional[User]
                    # recipient_user = ctx.channel.recipient
                    if isinstance(ctx.channel, discord.DMChannel):
                        LOGGER.warning("This is a DM channel")
                        msg: Message
                        msg = await recipient_user.send(files=my_files)
                        # await msg.pin()
                    elif isinstance(ctx.channel, discord.TextChannel):
                        msg: Message
                        msg = await ctx.message.channel.send(
                            f"{ctx.message.author.mention}, Here are your images.",
                            files=my_files,
                        )
                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not upload to discord...."))
                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    LOGGER.warning(output)
                    await ctx.send(embed=discord.Embed(description=output))
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                await ctx.send(
                    embed=discord.Embed(description=f"File successfully uploaded -> {my_files}...."),
                    delete_after=25.0,
                )

                await events.aio_download_event(
                    ctx,
                    f"{tmpdirname}",
                    cmd_metadata,
                    is_dropbox_upload,
                    recursive=True,
                )

    @dl_download.error
    async def dl_download_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(
                    description="Sorry, you need `MANAGE SERVER` permissions to change the dl_download!"
                )
            )

    # $dl_metadata https://www.instagram.com/p/CUiQyYcFGsb/
    # gallery-dl --user-agent Wget/1.21.1 -v -u professorex.university@gmail.com https://www.instagram.com/p/CUiQyYcFGsb/
    @commands.command()
    async def dl_metadata(self, ctx, uri: str = None):
        """*Use dl_metadata to download video with thumbnail dl_metadata*
        **Example**: `{dl_metadata}dl_metadata !`
        """
        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, uri = {uri}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        # DMChannel
        # ---------------------------------------------------------------
        dl_uri = uritools.urisplit(uri)
        cmd_args = ["dl_metadata"]
        cmd_kargs = {
            "cmd": DL_DOWNLOAD_COMMAND.format(dl_uri=dl_uri.geturi()),
            "uri": f"{dl_uri.geturi()}",
        }

        cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

        LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

        json_ret = run_get_metadata_json(dl_uri.geturi())

        await ctx.send(embed=discord.Embed(description=json.dumps(json_ret)))

    @dl_metadata.error
    async def dl_metadata_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(
                    description="Sorry, you need `MANAGE SERVER` permissions to change the dl_metadata!"
                )
            )

    # $dl_story gastonlefrenchie
    # @commands.command()
    @commands.command(aliases=["dls", "story"])
    async def dl_story(self, ctx, user: str):
        """*Use dl_story to download video with thumbnail dl_story*
        **Example**: `{dl_story}dl_story !`
        """
        message: Message
        message = ctx.message

        sent_message: Message
        sent_message = await message.channel.send(f"Downloading story for user -> {user} ...")

        await sent_message.edit(content=f"{sent_message.content} | ")

        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, user = {user}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user: Optional[User]
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        # DMChannel
        # ---------------------------------------------------------------
        if "https://" in f"{user}":
            # use full URL if contains https in it
            uri = f"{user}"
        else:
            uri = f"https://www.instagram.com/stories/{user}/"

        dl_uri = uritools.urisplit(uri)
        LOGGER.warning(f"dl_uri -> {dl_uri}")

        cmd_kargs = {
            "cmd": f"""gallery-dl --user-agent Wget/1.21.1 -v --cookies ~/.config/gallery-dl/cookies-instagram.txt --write-info-json --write-metadata {dl_uri.geturi()}""",
            "uri": f"{dl_uri.geturi()}",
        }

        cmd_args = ["dl_story"]
        cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

        LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

        await sent_message.edit(
            content=f"{sent_message.content} {type(self).__name__} -> cmd_metadata = {cmd_metadata}..."
        )

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                try:
                    await sent_message.edit(
                        content=f"{sent_message.content} Processing...",
                        delete_after=60.0,
                    )
                    await asyncio.gather(
                        asyncio.create_task(
                            shell.run_coroutine_subprocess(
                                cmd=cmd_metadata.cmd,
                                uri=cmd_metadata.uri,
                                working_dir=f"{tmpdirname}",
                            )
                        ),
                    )
                    await ctx.send(
                        embed=discord.Embed(description=f"Success, downloaded {cmd_metadata.uri}"),
                        delete_after=25.0,
                    )
                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not download story...."))
                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    LOGGER.warning(output)
                    await ctx.send(embed=discord.Embed(description=output))
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
                rich.print(tree_list)

                file_to_upload_list = [f"{p}" for p in tree_list]
                LOGGER.debug(f"{type(self).__name__} -> file_to_upload_list = {file_to_upload_list}")
                rich.print(file_to_upload_list)

                file_to_upload = file_functions.filter_media(file_to_upload_list)

                LOGGER.debug(f"{type(self).__name__} -> file_to_upload = {file_to_upload}")

                rich.print(file_to_upload)

                await ctx.send(
                    embed=discord.Embed(description=f"Uploading to discord -> {file_to_upload}...."),
                    delete_after=25.0,
                )

                # chunked_lists = list(misc.divide_chunks(file_to_upload, n=10))
                # discord has a limit of 10 media uploads per api call. break them up.
                # SOURCE: https://www.geeksforgeeks.org/break-list-chunks-size-n-python/
                n = 10
                final = [file_to_upload[i * n : (i + 1) * n] for i in range((len(file_to_upload) + n - 1) // n)]

                for count, chunk in enumerate(final):
                    await ctx.send(
                        embed=discord.Embed(description=f"Uploading batch {count}...."),
                        delete_after=30.0,
                    )

                    my_files = []

                    for f in chunk:
                        rich.print(f)
                        my_files.append(discord.File(f"{f}"))

                    LOGGER.debug(f"{type(self).__name__} -> my_files = {my_files}")
                    rich.print(my_files)

                    try:
                        msg: Message
                        msg = await ctx.send(files=my_files)
                    except Exception as ex:
                        await ctx.send(embed=discord.Embed(description="Could not upload story to discord...."))
                        print(ex)
                        exc_type, exc_value, exc_traceback = sys.exc_info()
                        LOGGER.error(f"Error Class: {str(ex.__class__)}")
                        output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                        LOGGER.warning(output)
                        await ctx.send(embed=discord.Embed(description=output))
                        LOGGER.error(f"exc_type: {exc_type}")
                        LOGGER.error(f"exc_value: {exc_value}")
                        traceback.print_tb(exc_traceback)

                is_dropbox_upload = False  # all clips are 15 seconds max each
                await events.aio_download_event(
                    ctx,
                    f"{tmpdirname}",
                    cmd_metadata,
                    is_dropbox_upload,
                    recursive=True,
                )

    @dl_story.error
    async def dl_story_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(description="Sorry, you need `MANAGE SERVER` permissions to change the dl_story!")
            )


async def setup(cerebro):
    await cerebro.add_cog(Instagram(cerebro))

</document_content>
</document>
<document index="9">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/cogs/mlmodels.py</source>
<document_content>
"""cerebro_bot.cogs.mlmodels"""
import asyncio
import logging
import pathlib
import sys
import tempfile
import traceback
from typing import Optional

from codetiming import Timer
import discord
from discord.ext import commands
from discord.message import Message
from discord.user import User
import rich
import uritools

from cerebro_bot import constants, shell
from cerebro_bot.bot_logger import get_logger
from cerebro_bot.factories import cmd_factory, guild_factory
from cerebro_bot.utils import aiodbx, file_functions
from cerebro_bot.utils.aiomodels import upscale_model_markdown
from cerebro_bot.utils.file_functions import aiowrite_file

# DISCORD_GUILD = os.environ.get("DISCORD_SERVER_ID")

LOGGER = get_logger(__name__, provider="MLModels", level=logging.DEBUG)

MD_TO_PDF_COMMAND = """
md2pdf table.md table.pdf
"""

# async def _aimages(tweet_url: str):
#     client = MLModelsHTTPClient()
#     res = await client.aimages(tweet_url)
#     return res


# async def _write_files_to_disk(data: dict, dl_dir: str = "./") -> None:
#     await async_download_file(data, dl_dir)


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/133702ceb8682ec3927530ac35ad28d47a42802e/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/cogs/settings.py
class MLModels(commands.Cog):
    def __init__(self, cerebro):
        self.bot = cerebro

    @commands.Cog.listener()
    async def on_ready(self):
        print(f"{type(self).__name__} Cog ready.")

    @commands.Cog.listener()
    async def on_guild_join(self, guild):
        """Add new guilds to the database"""
        _ = await guild_factory.Guild(id=guild.id)

    # $ml_show anime
    @commands.command(aliases=["mls", "ms"])
    async def ml_show(self, ctx, fuzzy_search_str: str = None):
        """*Use beautifulsoup to look up the current list of models on the wiki and download info about them*
        **Example**: `{ml_show}ml_show !`
        """

        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, urifuzzy_search_str= {fuzzy_search_str}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user: Optional[User]
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        fname = "table"
        ext = "md"
        uri = "https://upscale.wiki/wiki/Model_Database"
        dl_uri = uritools.urisplit(uri)
        cmd_args = ["ml_show"]
        cmd_kargs = {
            "cmd": MD_TO_PDF_COMMAND.format(dl_uri=dl_uri.geturi()),
            "uri": f"{dl_uri.geturi()}",
        }

        cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

        LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                await ctx.send(
                    embed=discord.Embed(description="Beginning Upscale lookup ...."),
                    delete_after=25.0,
                )

                try:
                    res = await upscale_model_markdown(fuzzy_search_str)
                except Exception as ex:
                    await ctx.send(
                        embed=discord.Embed(description="Could not lookup ML Model information on discord....")
                    )

                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    tb_str = "".join(traceback.format_exception(etype=type(ex), value=ex, tb=ex.__traceback__))
                    await ctx.send(embed=discord.Embed(description=f"{tb_str}"))
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    await ctx.send(embed=discord.Embed(description=f"{output}"))
                    LOGGER.warning(output)
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                # write markdown file to disk
                try:
                    # content = BytesIO((f"{res}").encode("utf8"))
                    await aiowrite_file(f"{res}", dl_dir=f"{tmpdirname}", fname=fname, ext=ext)
                except Exception as ex:
                    await ctx.send(
                        embed=discord.Embed(description=f"Could not write file to disk.... {tmpdirname}/{fname}.{ext}"),
                        delete_after=65.0,
                    )

                    debug_md_file_p = pathlib.Path(f"{tmpdirname}/{fname}.{ext}")

                    await ctx.send(
                        embed=discord.Embed(description=f"Does file exist {debug_md_file_p.exists()}"),
                        delete_after=65.0,
                    )

                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    tb_str = "".join(traceback.format_exception(etype=type(ex), value=ex, tb=ex.__traceback__))
                    await ctx.send(embed=discord.Embed(description=f"{tb_str}"))
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    await ctx.send(embed=discord.Embed(description=f"{output}"))
                    LOGGER.warning(output)
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)
                    return

                try:
                    dbg = await asyncio.gather(
                        asyncio.create_task(
                            shell.run_coroutine_subprocess(
                                # cmd=f"md2pdf {tmpdirname}/{fname}.{ext} {tmpdirname}/{fname}.pdf",
                                # uri=f"{tmpdirname}/{fname}.{ext}",
                                cmd=cmd_metadata.cmd,
                                uri=cmd_metadata.uri,
                                working_dir=f"{tmpdirname}",
                            )
                        ),
                    )
                    await ctx.send(
                        embed=discord.Embed(description=f"Success, created {tmpdirname}/{fname}.pdf"),
                        delete_after=25.0,
                    )

                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not upload story to discord...."))

                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    tb_str = "".join(traceback.format_exception(etype=type(ex), value=ex, tb=ex.__traceback__))
                    await ctx.send(embed=discord.Embed(description=f"{tb_str}"))
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    await ctx.send(embed=discord.Embed(description=f"{output}"))
                    LOGGER.warning(output)
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                # try:
                #     # convert to html first
                #     output = markdown.markdown(f"{res}")

                #     # aiowrite_file(data: str, dl_dir: str="./", fname: str="", ext: str=""):
                #     await ctx.send(
                #         "",
                #         file=discord.File(
                #             BytesIO((f"{output}").encode("utf8")), "table.html"
                #         ),
                #     )
                #     # write markdown to string
                #     # message = f"```md\n{res}```"
                #     # await ctx.author.send(message)
                # except Exception as ex:
                #     await ctx.send(
                #         embed=discord.Embed(
                #             description=f"Could not render Model markdown table"
                #         )
                #     )

                #     print(str(ex))
                #     exc_type, exc_value, exc_traceback = sys.exc_info()
                #     tb_str = ''.join(traceback.format_exception(etype=type(ex), value=ex, tb=ex.__traceback__))
                #     await ctx.send(embed=discord.Embed(description=f"{tb_str}"))
                #     LOGGER.error("Error Class: {}".format(str(ex.__class__)))
                #     output = "[{}] {}: {}".format("UNEXPECTED", type(ex).__name__, ex)
                #     await ctx.send(embed=discord.Embed(description=f"{output}"))
                #     LOGGER.warning(output)
                #     LOGGER.error("exc_type: {}".format(exc_type))
                #     LOGGER.error("exc_value: {}".format(exc_value))
                #     traceback.print_tb(exc_traceback)
                tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
                rich.print(tree_list)

                file_to_upload_list = [f"{p}" for p in tree_list]
                LOGGER.debug(f"{type(self).__name__} -> file_to_upload_list = {file_to_upload_list}")
                rich.print(file_to_upload_list)

                file_to_upload = file_functions.filter_pdf(file_to_upload_list)

                LOGGER.debug(f"{type(self).__name__} -> file_to_upload = {file_to_upload}")

                await ctx.send(
                    f"{type(self).__name__} -> file_to_upload = {file_to_upload}",
                    delete_after=25.0,
                )

                rich.print(file_to_upload)

                await ctx.send(
                    embed=discord.Embed(description=f"Uploading to discord -> {file_to_upload}...."),
                    delete_after=25.0,
                )

                my_files = []

                for f in file_to_upload:
                    rich.print(f)

                    if pathlib.Path(f).stat().st_size > constants.MAX_BYTES_UPLOAD_DISCORD:
                        await ctx.send(
                            embed=discord.Embed(
                                description=f"File is over 8MB... Uploading to dropbox -> {file_to_upload}...."
                            ),
                            delete_after=25.0,
                        )

                        to_upload_list = [f]
                        await aiodbx.dropbox_upload(to_upload_list)

                        await ctx.send(
                            embed=discord.Embed(description=f"File successfully uploaded to dropbox! -> {f}....")
                        )
                    else:
                        my_files.append(discord.File(f"{f}"))

                LOGGER.debug(f"{type(self).__name__} -> my_files = {my_files}")
                rich.print(my_files)

                try:
                    # bugfix?
                    # recipient_user: Optional[User]
                    # recipient_user = ctx.channel.recipient
                    if isinstance(ctx.channel, discord.DMChannel):
                        LOGGER.warning("This is a DM channel")
                        msg: Message
                        msg = await recipient_user.send(files=my_files)
                        # await msg.pin()
                    elif isinstance(ctx.channel, discord.TextChannel):
                        msg: Message
                        msg = await ctx.message.channel.send(
                            f"{ctx.message.author.mention}, Here are your images.",
                            files=my_files,
                        )
                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not upload to discord...."))
                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    LOGGER.warning(output)
                    await ctx.send(embed=discord.Embed(description=output))
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                await ctx.send(
                    embed=discord.Embed(description=f"File successfully uploaded -> {my_files}...."),
                    delete_after=25.0,
                )

    @ml_show.error
    async def ml_show_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(description="Sorry, you need `MANAGE SERVER` permissions to change the ml_show!")
            )


async def setup(cerebro):
    await cerebro.add_cog(MLModels(cerebro))

</document_content>
</document>
<document index="10">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/cogs/settings.py</source>
<document_content>
"""cerebro_bot.cogs.settings"""
# import os

import discord
from discord.ext import commands

from cerebro_bot.factories import guild_factory
from cerebro_bot.utils import get_guild_prefix

# from cerebro_bot.db import

# DISCORD_GUILD = os.environ.get("DISCORD_SERVER_ID")


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/133702ceb8682ec3927530ac35ad28d47a42802e/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/cogs/settings.py
class Settings(commands.Cog):
    def __init__(self, cerebro):
        self.bot = cerebro

    @commands.Cog.listener()
    async def on_ready(self):
        print(f"{type(self).__name__} Cog ready.")

    @commands.Cog.listener()
    async def on_guild_join(self, guild):
        """Add new guilds to the database"""
        _ = await guild_factory.Guild(id=guild.id)

    @commands.has_permissions(manage_guild=True)
    @commands.command()
    async def prefix(self, ctx, new_prefix: str = None):
        """*Change your servers prefix*
        **Example**: `{prefix}prefix !`
        **Requires permission**: `MANAGER SERVER`
        """
        if not new_prefix:
            prefix = get_guild_prefix(self.bot, ctx.guild.id)
            embed = discord.Embed(description=f"Prefix currently set to `{prefix}`")
            await ctx.send(embed=embed)
            return
        # embed = discord.Embed(description="Prefix changed")
        # # guild = await Guild.get(ctx.guild.id)
        # guild = guild_factory.Guild()
        # # if guild is None:
        # #     # await Guild.create(id=ctx.guild.id, prefix=new_prefix)
        # #     self.bot.guild_data[ctx.guild.id] = {"prefix": new_prefix}
        # # else:
        # embed.add_field(name="From", value=guild.prefix)
        # await guild.update(prefix=new_prefix).apply()
        # self.bot.guild_data[ctx.guild.id].update({"prefix": new_prefix})

        # embed.add_field(name="To", value=new_prefix)
        # await ctx.channel.send(embed=embed)

    @prefix.error
    async def prefix_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(description="Sorry, you need `MANAGE SERVER` permissions to change the prefix!")
            )


async def setup(cerebro):
    await cerebro.add_cog(Settings(cerebro))

</document_content>
</document>
<document index="11">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/cogs/soundeffects.py</source>
<document_content>
"""cerebro_bot.cogs.soundeffects"""
import asyncio
import logging
import pathlib
import sys
import tempfile
import traceback
from typing import Optional

from codetiming import Timer
import discord
from discord.ext import commands
from discord.message import Message
from discord.user import User
import uritools

from cerebro_bot import constants, shell
from cerebro_bot.bot_logger import get_logger
from cerebro_bot.factories import cmd_factory, guild_factory
from cerebro_bot.utils import aiodbx
from cerebro_bot.utils.file_functions import glob_file_by_extension

# DISCORD_GUILD = os.environ.get("DISCORD_SERVER_ID")

LOGGER = get_logger(__name__, provider="Soundeffects", level=logging.DEBUG)

# NOTE: https://github.com/xxcodianxx/youtube-dl-web/blob/master/server/src/util/stream.py#L59-L68
# NOTE: https://github.com/xxcodianxx/youtube-dl-web/blob/master/server/src/util/stream.py#L59-L68
# NOTE: https://github.com/xxcodianxx/youtube-dl-web/blob/master/server/src/util/stream.py#L59-L68
# NOTE: https://github.com/xxcodianxx/youtube-dl-web/blob/master/server/src/util/stream.py#L59-L68
# NOTE: https://github.com/xxcodianxx/youtube-dl-web/blob/master/server/src/util/stream.py#L59-L68
# NOTE: https://github.com/xxcodianxx/youtube-dl-web/blob/master/server/src/util/stream.py#L59-L68
# NOTE: https://github.com/xxcodianxx/youtube-dl-web/blob/master/server/src/util/stream.py#L59-L68
# NOTE: https://github.com/xxcodianxx/youtube-dl-web/blob/master/server/src/util/stream.py#L59-L68
# NOTE: https://github.com/xxcodianxx/youtube-dl-web/blob/master/server/src/util/stream.py#L59-L68
# NOTE: https://github.com/xxcodianxx/youtube-dl-web/blob/master/server/src/util/stream.py#L59-L68
# NOTE: https://github.com/xxcodianxx/youtube-dl-web/blob/master/server/src/util/stream.py#L59-L68
# DEBUG: https://www.reddit.com/r/youtubedl/comments/t044pt/can_i_pipe_the_output_of_ytdlp_directly_into/
# DEBUG: https://www.reddit.com/r/youtubedl/comments/t044pt/can_i_pipe_the_output_of_ytdlp_directly_into/
# DEBUG: https://www.reddit.com/r/youtubedl/comments/t044pt/can_i_pipe_the_output_of_ytdlp_directly_into/
# DEBUG: https://www.reddit.com/r/youtubedl/comments/t044pt/can_i_pipe_the_output_of_ytdlp_directly_into/
# DEBUG: https://www.reddit.com/r/youtubedl/comments/t044pt/can_i_pipe_the_output_of_ytdlp_directly_into/
# DEBUG: https://www.reddit.com/r/youtubedl/comments/t044pt/can_i_pipe_the_output_of_ytdlp_directly_into/
# DEBUG: https://www.reddit.com/r/youtubedl/comments/t044pt/can_i_pipe_the_output_of_ytdlp_directly_into/
# SEE: https://github.com/xxcodianxx/youtube-dl-web/blob/master/server/src/util/stream.py#L59-L68

SOUNDEFFECTS_WATERMARK = """
# export font_location='/Volumes/Macintosh HD/System/Library/Fonts/Helvetica.ttc'
# export font_location='/home/pi/.local/share/fonts/Noto Sans ExtraBold Nerd Font Complete.ttf'
ffmpeg -y -hide_banner -loglevel warning -i \"{full_path_input_file}\" -vf drawtext="text='\"{text_val}\"':fontcolor=white:fontsize=20:box=1:boxcolor=black@0.5:boxborderw=5:x=(w-text_w)/2:y=(h-text_h)/2" -c:a aac -q:a 128k \"{full_path_output_file}\"
"""

DL_SAFE_COMMAND = """

yt-dlp -v -f best -n --ignore-errors --restrict-filenames --write-thumbnail --embed-thumbnail --no-mtime --recode-video mp4 --cookies=~/Downloads/yt-cookies.txt {dl_uri}

# _RETVAL=$?

if [ "$?" != "0" ]; then
        echo \"Trying yt-best instead\"

        yt-dlp -v -f "bestvideo[ext=mp4]+bestaudio[ext=m4a]/bestvideo+bestaudio" -n --ignore-errors --restrict-filenames --write-thumbnail --embed-thumbnail --no-mtime --recode-video mp4 --cookies=~/Downloads/yt-cookies.txt --write-info-json {dl_uri}

        # _RETVAL=$?

        if [ "$?" != "0" ]; then
                echo "Trying yt-dlp instead"
                yt-dlp {dl_uri}
        fi
fi
"""


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/133702ceb8682ec3927530ac35ad28d47a42802e/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/cogs/settings.py
class Soundeffects(commands.Cog):
    def __init__(self, cerebro):
        self.bot = cerebro

    @commands.Cog.listener()
    async def on_ready(self):
        print(f"{type(self).__name__} Cog ready.")

    @commands.Cog.listener()
    async def on_guild_join(self, guild):
        """Add new guilds to the database"""
        _ = await guild_factory.Guild(id=guild.id)

    @commands.command(aliases=["se", "sound", "snd"])
    async def soundeffects(self, ctx, uri: str = None):
        """*Use youtube_dl to download video with thumbnail soundeffects*
        **Example**: `{soundeffects}soundeffects !`
        """
        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, uri = {uri}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user: Optional[User]
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        dl_uri = uritools.urisplit(uri)

        cmd_args = ["dl_safe"]
        cmd_kargs = {
            "cmd": DL_SAFE_COMMAND.format(dl_uri=dl_uri.geturi()),
            "uri": f"{dl_uri.geturi()}",
        }

        cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

        LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

        await ctx.send(
            embed=discord.Embed(description=f"Downloading {cmd_metadata.uri} ...."),
            delete_after=25.0,
        )

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                try:
                    await asyncio.gather(
                        asyncio.create_task(
                            shell.run_coroutine_subprocess(
                                cmd=cmd_metadata.cmd,
                                uri=cmd_metadata.uri,
                                working_dir=f"{tmpdirname}",
                            )
                        ),
                    )

                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not upload story to discord...."))
                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    await ctx.send(embed=discord.Embed(description=f"{output}"))
                    LOGGER.warning(output)
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                await ctx.send(
                    embed=discord.Embed(description=f"Success, downloaded {cmd_metadata.uri}"),
                    delete_after=25.0,
                )

                # After downloading file we need to then add the water mark to it

                file_to_upload_list = glob_file_by_extension(f"{tmpdirname}", extension="*.mp4")

                file_to_upload = f"{file_to_upload_list[0]}"

                ######################################################################
                # run watermark command
                ######################################################################
                file_api = pathlib.Path(file_to_upload)

                full_path_input_file = f"{file_api.absolute()}"
                current_dir = file_api.parents[0]
                full_path_output_file = f"{current_dir}/watermark_{file_api.stem}{file_api.suffix}"
                text_val = f"{file_api.name}"

                cmd_args = ["soundeffects_watermark"]
                cmd_kargs = {
                    "cmd": SOUNDEFFECTS_WATERMARK.format(
                        full_path_input_file=full_path_input_file,
                        text_val=text_val,
                        full_path_output_file=full_path_output_file,
                    ),
                    "uri": f"{dl_uri.geturi()}",
                }

                cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

                LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

                await ctx.send(
                    embed=discord.Embed(description=f"Watermarking {full_path_input_file} ...."),
                    delete_after=25.0,
                )

                try:
                    await asyncio.gather(
                        asyncio.create_task(
                            shell.run_coroutine_subprocess(
                                cmd=cmd_metadata.cmd,
                                uri=cmd_metadata.uri,
                                working_dir=f"{tmpdirname}",
                            )
                        ),
                    )

                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not upload story to discord...."))
                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    await ctx.send(embed=discord.Embed(description=f"{output}"))
                    LOGGER.warning(output)
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                # delete non watermarked
                file_api.unlink()

                file_to_upload_list = glob_file_by_extension(f"{tmpdirname}", extension="*.mp4")

                file_to_upload = f"{file_to_upload_list[0]}"

                if pathlib.Path(file_to_upload).stat().st_size > constants.MAX_BYTES_UPLOAD_DISCORD:
                    msg_upload = await ctx.send(
                        embed=discord.Embed(
                            description=f"File is over 8MB... Uploading to dropbox -> {file_to_upload}...."
                        )
                    )
                    await msg_upload.delete()

                    await aiodbx.dropbox_upload(file_to_upload_list)

                    await ctx.send(
                        embed=discord.Embed(
                            description=f"File successfully uploaded to dropbox! -> {file_to_upload}...."
                        )
                    )

                else:
                    msg_upload = await ctx.send(
                        embed=discord.Embed(description=f"Uploading to discord -> {file_to_upload}....")
                    )

                    msg: Message
                    msg = await ctx.send(file=discord.File(f"{file_to_upload}"))
                    await msg_upload.delete()

    @soundeffects.error
    async def soundeffects_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(
                    description="Sorry, you need `MANAGE SERVER` permissions to change the soundeffects!"
                )
            )


async def setup(cerebro):
    await cerebro.add_cog(Soundeffects(cerebro))

</document_content>
</document>
<document index="12">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/cogs/tasker.py</source>
<document_content>
"""cerebro_bot.cogs.tasker"""
import asyncio
import contextlib
import logging
import os
import random
import string
import subprocess
import sys
import tempfile
import time
import traceback
from typing import Optional

from codetiming import Timer
import discord
from discord.ext import commands
from discord.ext.commands import Context as DPYContext
from redis.asyncio import ConnectionPool, Redis

from cerebro_bot import db, shell
from cerebro_bot.bot_logger import get_logger
from cerebro_bot.constants import CURRENT_USER
from cerebro_bot.factories import cmd_factory, guild_factory

LOGGER = get_logger(__name__, provider="Tasker", level=logging.DEBUG)

AIO_QUEUE = asyncio.Queue(maxsize=3 - 1)  # Max 3 processes


# SOURCE: https://github.com/BobBuildTool/bob/blob/master/pym/bob/utils.py
async def aio_run(args, universal_newlines=False, errors=None, check=False, shell=False, **kwargs):
    """Provide the subprocess.run() function as asyncio corouting.
    This takes care of the missing 'universal_newlines' and 'check' options.
    Everything else is passed through. Will also raise the same exceptions as
    subprocess.run() to act as a drop-in replacement.
    """
    import asyncio
    import io
    import locale
    import subprocess

    if shell:
        proc = await asyncio.create_subprocess_shell(args, **kwargs)
    else:
        proc = await asyncio.create_subprocess_exec(*args, **kwargs)
    stdout, stderr = await proc.communicate()

    if universal_newlines and (stdout is not None):
        stdout = io.TextIOWrapper(io.BytesIO(stdout), errors=errors).read()
    if universal_newlines and (stderr is not None):
        stderr = io.TextIOWrapper(io.BytesIO(stderr), errors=errors).read()

    if check and (proc.returncode != 0):
        raise subprocess.CalledProcessError(proc.returncode, args, stdout, stderr)

    return subprocess.CompletedProcess(args, proc.returncode, stdout, stderr)


# SOURCE: https://github.com/BobBuildTool/bob/blob/master/pym/bob/utils.py
async def aio_check_output(args, **kwargs):
    """The subprocess.check_output() call as coroutine."""
    import subprocess

    return (await aio_run(args, check=True, stdout=subprocess.PIPE, **kwargs)).stdout


# async def aio_task_worker(id: int) -> None:
#     """
#     We could use more straightforward consumer-producer pattern:
#         * producer puts tasks into the queue
#         * worker waits for tasks in the queue

#     But for this tiny code sniped that would produce too much boilerplates.
#     """
#     delay = random.random()
#     print(">" * 5, f"task {id} starts with delay {delay:.1} seconds")
#     process = await asyncio.create_subprocess_exec(
#         "sleep",
#         str(delay),
#         stdout=subprocess.PIPE,
#         stderr=subprocess.PIPE,
#     )
#     (output, err) = await process.communicate()
#     status = await process.wait()

#     print("<" * 5, f"task {id} finished with status {status}")
#     print(f"Stdout: {output}, Stderr: {err}")
#     await AIO_QUEUE.get()


# async def dummy_worker(name: str, input_queue: asyncio.Queue, output_queue: asyncio.Queue):
#     """_summary_

#     Args:
#         name (str): _description_
#         input_queue (asyncio.Queue): _description_
#     """
#     while True:
#         # Get a "work item" out of the input_queue.
#         sleep_for = await input_queue.get()
#         environ = {"LC_ALL": "C.UTF-8", **os.environ}

#         delay = random.random()
#         print(">" * 5, f"task {id} starts with delay {sleep_for} seconds")
#         process = await asyncio.create_subprocess_exec(
#             "sleep",
#             str(sleep_for),
#             stdout=asyncio.subprocess.PIPE,
#             stderr=asyncio.subprocess.PIPE,
#             # close_fds=
#         )

#         # Read one line of output.
#         data = await process.stdout.readline()
#         line = data.decode("ascii").rstrip()

#         # (output, err) = await process.communicate()
#         status = await process.wait()
#         # output = output.strip().decode("utf-8")

#         # print(f"Subprocess output: {output}")
#         # print(f"Subprocess status: {status}")
#         # print(f"Subprocess finished with return code: {process.returncode}")

#         # add output to output_queue
#         await output_queue.put(output)

#         # Sleep for the "sleep_for" seconds.
#         await asyncio.sleep(sleep_for)

#         # Notify the input_queue that the "work item" has been processed.
#         input_queue.task_done()

#         print(f"{name} has slept for {sleep_for:.2f} seconds")


class Tasker(commands.Cog):
    def __init__(self, cerebro) -> None:
        self.bot = cerebro
        self._kw_chars = set(string.ascii_letters + string.digits + "-_")

        self._state = None
        self._exit_on_stdin_close = True
        # self.ready: asyncio.Event = asyncio.Event()
        # self._proc: Optional[asyncio.subprocess.Process] = None  # pylint:disable=no-member
        # self._shutdown: bool = False
        # self.start_monitor_task = None
        # self.timeout = 60
        self._stdin_close_timeout = 2
        self._terminate_timeout = 2
        self.input_queue = asyncio.Queue()
        self.output_queue = asyncio.Queue()

        # self._args = []
        # self._pipe_task = None
        self._pipe_tasks = []

        # SOURCE: https://github.com/twisteroidambassador/ptadapter/blob/master/ptadapter/adapters.py#L243
        self._process: asyncio.subprocess.Process = None
        self._stdout_task: asyncio.Task = None
        self._ready = asyncio.Future()
        self._stopping = False
        self._stack = contextlib.AsyncExitStack()

    def _build_env(self) -> dict:
        # env = os.environ.copy()
        return os.environ.copy()

    async def _process_stdout(self) -> None:
        while True:
            lines = []
            line = await self._process.stdout.readline()
            if not line:
                break
            print("Tasker stdout: %r", line)
            try:
                line = line.decode("utf-8").strip()
                self.output_queue.put_nowait(line)
                lines.append(line)
                # self._process_stdout_line(kw, optargs)
            except Exception as e:
                print("Error processing Tasker stdout line: %r", line, exc_info=True)
                if not self._ready.done():
                    self._ready.set_exception(e)
                continue
        print("Tasker stdout at EOF")
        assert not self._ready.done()
        self._ready.set_result(lines)

    async def _pre_start(self) -> None:
        if self._state is None:
            self._state = self._stack.enter_context(tempfile.TemporaryDirectory(prefix=__package__ + "_state_"))
            print("Created tempdir for state: %s", self._state)

    def _check_not_started(self) -> None:
        if self._process:
            raise asyncio.InvalidStateError("Tasker has already started")

    def _check_started(self) -> None:
        if not self._process:
            raise asyncio.InvalidStateError("Tasker has not yet started")

    def _check_running(self) -> None:
        self._check_started()
        if self._stopping:
            raise asyncio.InvalidStateError("Tasker is stopping or has stopped")

    # SOURCE: https://sorokin.engineer/posts/en/python_asyncio_multiprocessing.html
    # recreating this above code ^
    @commands.command()
    async def tasker(self, ctx: DPYContext, uri: str = None) -> None:
        """*Use tasker to change gallery_dl tasker*
        **Example**: `{tasker}tasker !`
        """

        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, uri = {uri}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        # realCommit = (await aio_check_output(["git", "version"],
        #         universal_newlines=True, errors='replace')).strip()

        # self.input_queue.put_nowait(uri)

        # # Create three worker tasks to process the queue concurrently.
        # for i in range(1):
        #     task = asyncio.create_task(dummy_worker(f"worker-{i}", self.input_queue))
        #     print(f"Created {task!r}")
        #     self._pipe_tasks.append(task)

        # # for task_id in range(uri):
        # #     await AIO_QUEUE.put(task_id)  # It does'n matter what we put in the queue. We use it as semaphore.
        # #     self.bot.loop.create_task(aio_task_worker(task_id))

        # # Wait until the queue is fully processed.
        # started_at = time.monotonic()
        # await self.input_queue.join()
        # total_slept_for = time.monotonic() - started_at

        self._check_not_started()
        await self._pre_start()
        env = self._build_env()
        # print('Tasker environment variables: %r', env)
        cmd = ["echo", uri]
        cmd = """echo {uri}
            # Check return code
            if [ $? -ne 0 ]; then
              echo "'better luck next time'
              sleep {uri}
              echo 'slept for {uri} seconds'
              sleep {uri}
            fi
        """.format(
            uri=uri
        )
        # self._process = await asyncio.create_subprocess_exec(
        #     *cmd,
        #     env=env,
        #     stdin=asyncio.subprocess.PIPE,
        #     stdout=asyncio.subprocess.PIPE,
        #     stderr=None,
        # )
        self._process = await asyncio.create_subprocess_exec(
            cmd,
            env=env,
            stdin=asyncio.subprocess.PIPE,
            stdout=asyncio.subprocess.PIPE,
            stderr=None,
        )
        print("Started Tasker subprocess: %r", self._process)
        self._stdout_task = asyncio.create_task(self._process_stdout())
        try:
            res = await self._ready
        except Exception:
            await self.stop_tasker()
            raise

        print(f"res: {res}")

    @tasker.error
    async def tasker_error_handler(self, ctx: DPYContext, error: commands.CommandError) -> None:
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(
                    description="Sorry, you need `MANAGE SERVER` permissions to change the dl_metadata!"
                )
            )

    # SOURCE: https://sorokin.engineer/posts/en/python_asyncio_multiprocessing.html
    # recreating this above code ^
    @commands.command()
    async def bob_tasker(self, ctx: DPYContext, uri: str = None):
        """*Use tasker to change gallery_dl tasker*
        **Example**: `{tasker}tasker !`
        """

        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, uri = {uri}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        env = self._build_env()
        cmd = """echo {uri}
# Check return code
if [ $? -ne 0 ]; then
  echo 'better luck next time'
  sleep {uri}
  echo 'slept for {uri} seconds'
  sleep {uri}
fi
        """.format(
            uri=uri
        )
        try:
            res = (
                await aio_check_output(
                    cmd,
                    universal_newlines=True,
                    errors="replace",
                    shell=True,
                    env=env,
                    # stdout=asyncio.subprocess.PIPE,
                    stderr=subprocess.PIPE,
                )
            ).strip()
        except Exception as ex:
            print(ex)
            exc_type, exc_value, exc_traceback = sys.exc_info()
            LOGGER.error(f"Error Class: {str(ex.__class__)}")
            output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
            LOGGER.warning(output)
            # await ctx.send(embed=discord.Embed(description=output))
            LOGGER.error(f"exc_type: {exc_type}")
            LOGGER.error(f"exc_value: {exc_value}")
            traceback.print_tb(exc_traceback)

        print(f"res: {res}")
        # import bpdb
        # bpdb.set_trace()

    @bob_tasker.error
    async def bob_tasker_error_handler(self, ctx: DPYContext, error: commands.CommandError) -> None:
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(
                    description="Sorry, you need `MANAGE SERVER` permissions to change the dl_metadata!"
                )
            )

    async def stop_tasker(self) -> None:
        """(async) Stop the Tasker executable.
        First try to signal a graceful exit by closing Tasker's STDIN (if
        enabled) and wait, then call
        :meth:`~asyncio.asyncio.subprocess.Process.terminate` and wait,
        then call
        :meth:`~asyncio.asyncio.subprocess.Process.kill`.
        """
        # Why does cross referencing asyncio.subprocess need
        # "asyncio.asyncio.subprocess"?
        self._check_running()
        self._stopping = True
        try:
            if self._exit_on_stdin_close:
                print("Closing Tasker stdin")
                self._process.stdin.close()
                try:
                    await asyncio.wait_for(self._process.wait(), self._stdin_close_timeout)
                    print("Tasker exited after closing stdin")
                    return
                except asyncio.TimeoutError:
                    pass
            try:
                print("Terminating Tasker")
                self._process.terminate()
                try:
                    await asyncio.wait_for(self._process.wait(), self._terminate_timeout)
                    print("Tasker exited after calling terminate()")
                    return
                except asyncio.TimeoutError:
                    pass
                print("Calling kill() on Tasker")
                self._process.kill()
                await self._process.wait()
            except ProcessLookupError:
                print("Tasker process already exited")
        finally:
            await self._stack.aclose()

    async def wait(self) -> None:
        """(async) Block until the Tasker process exit."""
        self._check_started()
        await self._process.wait()

    @commands.Cog.listener()
    async def on_ready(self) -> None:
        """Wait for the bot to be ready before starting the monitor"""
        print(f"{type(self).__name__} Cog ready.")

    @commands.Cog.listener()
    async def on_guild_join(self, guild) -> None:
        """Add new guilds to the database"""
        _ = await guild_factory.Guild(id=guild.id)

    # async def shutdown(self) -> None:
    #     """Shut down the monitor process and cancel the monitor task."""
    #     if self.start_monitor_task is not None:
    #         self.start_monitor_task.cancel()
    #     await self._partial_shutdown()

    # async def _partial_shutdown(self) -> None:
    #     """Shut down the monitor process."""
    #     self.ready.clear()
    #     if self._shutdown is True:
    #         # For convenience, calling this method more than once or calling it before starting it
    #         # does nothing.
    #         return
    #     if self._pipe_task:
    #         self._pipe_task.cancel()
    #     if self._proc is not None:
    #         self._proc.terminate()
    #         await self._proc.wait()
    #     self._proc = None
    #     self._shutdown = True

    @commands.command()
    async def tasker_worker(self, ctx):
        """*Use tasker to change gallery_dl tasker*
        **Example**: `{tasker}tasker !`
        """

        await ctx.send(embed=discord.Embed(description="tasker_worker"))

    @tasker_worker.error
    async def tasker_worker_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(
                    description="Sorry, you need `MANAGE SERVER` permissions to change the dl_metadata!"
                )
            )


async def setup(cerebro):
    await cerebro.add_cog(Tasker(cerebro))

</document_content>
</document>
<document index="13">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/cogs/tiktok.py</source>
<document_content>
"""cerebro_bot.cogs.tiktok"""
import asyncio
import logging
import sys
import tempfile
import traceback
from typing import Optional

import aiohttp
from codetiming import Timer
import discord
from discord.ext import commands
from discord.user import User
import uritools

from cerebro_bot import shell
from cerebro_bot.bot_logger import get_logger
from cerebro_bot.factories import cmd_factory, guild_factory
from cerebro_bot.utils import aiodbx, events
from cerebro_bot.utils.file_functions import glob_file_by_extension

# import os

# DISCORD_GUILD = os.environ.get("DISCORD_SERVER_ID")

LOGGER = get_logger(__name__, provider="TikTok", level=logging.DEBUG)

TT_ONE_COMMAND = """

yt-dlp -v -n --ignore-errors --restrict-filenames --write-thumbnail --embed-thumbnail --no-mtime --recode-video mp4 --cookies=~/Downloads/yt-cookies.txt --write-info-json --convert-thumbnails jpg {dl_uri}

"""

TT_TWO_COMMAND = (
    r"""yt-dlp -v --ignore-errors --restrict-filenames --no-mtime --cookies=~/Downloads/yt-cookies.txt {dl_uri}"""
)


async def expandURL(link: str):
    async with aiohttp.ClientSession() as session:
        async with session.head(link) as response:
            expanded = await response.getheader("location")
    return expanded


# SOURCE: https://www.programcreek.com/python/?project_name=athphane%2Fuserbot#
async def expand_url(url: str):
    async with aiohttp.ClientSession() as session:
        async with session.get(f"http://expandurl.com/api/v1/?url={url}") as resp:
            expanded = await resp.text()

        return expanded if expanded != "false" and expanded[:-1] != url else None


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/133702ceb8682ec3927530ac35ad28d47a42802e/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/cogs/settings.py
class TikTok(commands.Cog):
    def __init__(self, cerebro):
        self.bot = cerebro

    @commands.Cog.listener()
    async def on_ready(self):
        print(f"{type(self).__name__} Cog ready.")

    @commands.Cog.listener()
    async def on_guild_join(self, guild):
        """Add new guilds to the database"""
        _ = await guild_factory.Guild(id=guild.id)

    # $tiktok https://www.reddit.com/r/TikTok_Ass/comments/r352rg/hit_it_for_me_one_time/
    # @commands.command()
    @commands.command(aliases=["tt", "tok", "tk"])
    async def tiktok(self, ctx, uri: str = None):
        """*Use youtube_dl to download video with thumbnail tiktok*
        **Example**: `{tiktok}tiktok !`
        """
        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, uri = {uri}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user: Optional[User]
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        # DMChannel
        # ---------------------------------------------------------------
        dl_uri = uritools.urisplit(uri)

        expanded = False

        if dl_uri.authority == "fb.watch":
            expanded = await expand_url(f"{dl_uri.geturi()}")
            LOGGER.error(f"EXPANDED {expanded}")
            # pass

        if expanded:
            dl_uri = uritools.urisplit(expanded)

        cmd_args = ["tiktok"]
        cmd_kargs = {
            "cmd": TT_ONE_COMMAND.format(dl_uri=dl_uri.geturi()),
            "uri": f"{dl_uri.geturi()}",
        }

        cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

        LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

        await ctx.send(
            embed=discord.Embed(description=f"Downloading {cmd_metadata.uri} ...."),
            delete_after=25.0,
        )

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                try:
                    await asyncio.gather(
                        asyncio.create_task(
                            shell.run_coroutine_subprocess(
                                cmd=cmd_metadata.cmd,
                                uri=cmd_metadata.uri,
                                working_dir=f"{tmpdirname}",
                            )
                        ),
                    )

                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not upload story to discord...."))
                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    await ctx.send(embed=discord.Embed(description=f"{output}"))
                    LOGGER.warning(output)
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                await ctx.send(
                    embed=discord.Embed(description=f"Success, downloaded {cmd_metadata.uri} ..."),
                    delete_after=25.0,
                )

                file_to_upload_list = glob_file_by_extension(f"{tmpdirname}", extension="*.mp4")

                file_to_upload = f"{file_to_upload_list[0]}"

                await aiodbx.dropbox_upload(file_to_upload_list)

                await ctx.send(
                    embed=discord.Embed(
                        description=f"File successfully uploaded to dropbox! -> {file_to_upload}....",
                        delete_after=45.0,
                    )
                )

                is_dropbox_upload = True

                await events.aio_download_event(ctx, f"{tmpdirname}", cmd_metadata, is_dropbox_upload)

    @tiktok.error
    async def tiktok_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(description="Sorry, you need `MANAGE SERVER` permissions to change the tiktok!")
            )


async def setup(cerebro):
    await cerebro.add_cog(TikTok(cerebro))

</document_content>
</document>
<document index="14">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/cogs/tweetpik.py</source>
<document_content>
"""cerebro_bot.cogs.tweetpik"""
import json
import logging
import pathlib
import sys
import tempfile
import traceback
from typing import Optional

from codetiming import Timer
import discord
from discord.ext import commands
from discord.message import Message
from discord.user import User
import rich

from cerebro_bot import constants
from cerebro_bot.bot_logger import get_logger
from cerebro_bot.factories import guild_factory
from cerebro_bot.utils import aiodbx, file_functions
from cerebro_bot.utils.aiotweetpik import TweetpikHTTPClient, async_download_file

# import os
# DISCORD_GUILD = os.environ.get("DISCORD_SERVER_ID")

LOGGER = get_logger(__name__, provider="Tweetpik", level=logging.DEBUG)


async def _aimages(tweet_url: str):
    client = TweetpikHTTPClient()
    return await client.aimages(tweet_url)


async def _write_files_to_disk(data: dict, dl_dir: str = "./") -> None:
    await async_download_file(data, dl_dir)


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/133702ceb8682ec3927530ac35ad28d47a42802e/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/cogs/settings.py
class Tweetpik(commands.Cog):
    def __init__(self, cerebro):
        self.bot = cerebro

    @commands.Cog.listener()
    async def on_ready(self):
        print(f"{type(self).__name__} Cog ready.")

    @commands.Cog.listener()
    async def on_guild_join(self, guild):
        """Add new guilds to the database"""
        _ = await guild_factory.Guild(id=guild.id)

    # $tweetpik https://www.instagram.com/p/CUiQyYcFGsb/
    # $tweetpik https://www.instagram.com/p/CUiVmWflehZ/
    # gallery-dl -o downloader.http.headers.User-Agent=Wget/1.21.1 -v -u professorex.university@gmail.com https://www.instagram.com/p/CUiQyYcFGsb/
    # @commands.command()
    @commands.command(aliases=["tp", "screenshot", "ss"])
    async def tweetpik(self, ctx, uri: str = None):
        """*Use tweetpik to screenshot and download a twitter url*
        **Example**: `{tweetpik}tweetpik !`
        """

        tweet_url = uri

        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, uri = {tweet_url}")
        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user: Optional[User]
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                await ctx.send(
                    embed=discord.Embed(description="Beginning download ...."),
                    delete_after=25.0,
                )

                try:
                    res = await _aimages(tweet_url)
                    rich.print(res)
                    data = json.loads(res)
                    await _write_files_to_disk(data, f"{tmpdirname}")
                    await ctx.send(
                        embed=discord.Embed(description=f"Success, downloaded {tweet_url}"),
                        delete_after=25.0,
                    )
                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not upload tweetpik to discord...."))

                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    tb_str = "".join(traceback.format_exception(etype=type(ex), value=ex, tb=ex.__traceback__))
                    await ctx.send(embed=discord.Embed(description=f"{tb_str}"))
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    await ctx.send(embed=discord.Embed(description=f"{output}"))
                    LOGGER.warning(output)
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
                rich.print(tree_list)

                to_rename = False

                file_to_upload_list = []

                for p in tree_list:
                    if "?updatedAt" in f"{p}":
                        to_rename = True
                    file_to_upload_list.append(f"{p}")

                LOGGER.debug(f"{type(self).__name__} -> file_to_upload_list = {file_to_upload_list}")
                rich.print(file_to_upload_list)

                if to_rename:
                    _ = file_functions.rename_without_cachebuster(file_to_upload_list)

                    # Now redo the tree command

                    tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
                    rich.print(tree_list)

                    to_rename = False

                    file_to_upload_list = []

                    for p in tree_list:
                        if "?updatedAt" in f"{p}":
                            to_rename = True
                        file_to_upload_list.append(f"{p}")

                    LOGGER.debug(f"{type(self).__name__} -> file_to_upload_list = {file_to_upload_list}")
                    rich.print(file_to_upload_list)

                # finally we should be ready to upload
                file_to_upload = file_functions.filter_media(file_to_upload_list)

                LOGGER.debug(f"{type(self).__name__} -> file_to_upload = {file_to_upload}")

                await ctx.send(
                    f"{type(self).__name__} -> file_to_upload = {file_to_upload}",
                    delete_after=25.0,
                )

                rich.print(file_to_upload)

                await ctx.send(
                    embed=discord.Embed(description=f"Uploading to discord -> {file_to_upload}...."),
                    delete_after=25.0,
                )

                my_files = []

                for f in file_to_upload:
                    rich.print(f)

                    if pathlib.Path(f).stat().st_size > constants.MAX_BYTES_UPLOAD_DISCORD:
                        await ctx.send(
                            embed=discord.Embed(
                                description=f"File is over 8MB... Uploading to dropbox -> {file_to_upload}...."
                            ),
                            delete_after=25.0,
                        )

                        to_upload_list = [f]
                        await aiodbx.dropbox_upload(to_upload_list)

                        await ctx.send(
                            embed=discord.Embed(description=f"File successfully uploaded to dropbox! -> {f}....")
                        )
                    else:
                        my_files.append(discord.File(f"{f}"))

                LOGGER.debug(f"{type(self).__name__} -> my_files = {my_files}")
                rich.print(my_files)

                try:
                    # bugfix?
                    # recipient_user: Optional[User]
                    # recipient_user = ctx.channel.recipient
                    if isinstance(ctx.channel, discord.DMChannel):
                        LOGGER.warning("This is a DM channel")
                        msg: Message
                        msg = await recipient_user.send(files=my_files)
                        # await msg.pin()
                    elif isinstance(ctx.channel, discord.TextChannel):
                        msg: Message
                        msg = await ctx.message.channel.send(
                            f"{ctx.message.author.mention}, Here are your images.",
                            files=my_files,
                        )
                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not upload to discord...."))
                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    LOGGER.warning(output)
                    await ctx.send(embed=discord.Embed(description=output))
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                await ctx.send(
                    embed=discord.Embed(description=f"File successfully uploaded -> {my_files}...."),
                    delete_after=25.0,
                )

    @tweetpik.error
    async def tweetpik_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(description="Sorry, you need `MANAGE SERVER` permissions to change the tweetpik!")
            )


async def setup(cerebro):
    await cerebro.add_cog(Tweetpik(cerebro))

</document_content>
</document>
<document index="15">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/cogs/twitter.py</source>
<document_content>
"""cerebro_bot.cogs.twitter"""

from __future__ import annotations

import asyncio
import concurrent.futures
from enum import IntEnum
import functools
import logging
import os
import os.path
import pathlib
import sys
import tempfile
import time
from timeit import default_timer as timer
import traceback
import typing
from typing import Any, Dict, List, NewType, Optional

from codetiming import Timer
import discord
from discord.ext import commands
from discord.message import Message
from discord.user import User
import rich
import uritools

from cerebro_bot import constants, shell
from cerebro_bot.bot_logger import get_logger
from cerebro_bot.factories import cmd_factory, guild_factory
from cerebro_bot.utils import aiodbx, file_functions

LOGGER = get_logger(__name__, provider="Twitter", level=logging.DEBUG)

DL_SAFE_TWITTER_COMMAND = """
gallery-dl --no-mtime --user-agent Wget/1.21.1 -v --netrc --cookies ~/.config/gallery-dl/cookies-twitter.txt --write-info-json {dl_uri}
"""

DL_TWITTER_CARD_COMMAND = """
gallery-dl --no-mtime -o cards=true --user-agent Wget/1.21.1 -v --netrc --write-info-json {dl_uri}
"""

DL_TWITTER_THREAD_COMMAND = """
gallery-dl --no-mtime --user-agent Wget/1.21.1 --netrc --cookies ~/.config/gallery-dl/cookies-twitter.txt -v -c ~/dev/universityofprofessorex/cerebro-bot/thread.conf {dl_uri}
"""


def unlink_orig_file(a_filepath: str):
    """_summary_

    Args:
        a_filepath (str): _description_

    Returns:
        _type_: _description_
    """
    # for orig_to_rm in media_filepaths:
    rich.print(f"deleting ... {a_filepath}")
    os.unlink(f"{a_filepath}")
    return a_filepath


def get_files_to_upload(tmpdirname: str) -> List[str]:
    """Get directory and iterate over files to upload

    Args:
        tmpdirname (str): _description_

    Returns:
        _type_: _description_
    """
    tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
    rich.print(tree_list)

    file_to_upload_list = [f"{p}" for p in tree_list]
    LOGGER.debug(f"get_files_to_upload -> file_to_upload_list = {file_to_upload_list}")
    rich.print(file_to_upload_list)

    file_to_upload = file_functions.filter_media(file_to_upload_list)

    LOGGER.debug(f"get_files_to_upload -> file_to_upload = {file_to_upload}")

    rich.print(file_to_upload)
    return file_to_upload


def run_tree(tmpdirname: str):
    """run_tree

    Args:
        tmpdirname (str): _description_

    Returns:
        _type_: _description_
    """

    # Now that we are finished processing, we can upload the files to discord

    tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
    rich.print("tree_list ->")
    rich.print(tree_list)

    file_to_upload_list = [f"{p}" for p in tree_list]
    LOGGER.debug(f"compress_video-> file_to_upload_list = {file_to_upload_list}")
    rich.print(file_to_upload_list)

    file_to_upload = file_functions.filter_media(file_to_upload_list)

    return file_to_upload


async def compress_video(tmpdirname: str, file_to_compress: str, bot: Any, ctx: Any) -> bool:
    """_summary_

    Args:
        tmpdirname (str): _description_
        file_to_compress (str): _description_
        bot (Any): _description_
        ctx (Any): _description_

    Returns:
        List[str]: _description_
    """
    if (pathlib.Path(f"{file_to_compress}").is_file()) and pathlib.Path(
        f"{file_to_compress}"
    ).suffix in file_functions.VIDEO_EXTENSIONS:

        msg_upload = await ctx.send(embed=discord.Embed(description=f"compressing file -> {file_to_compress}"))

        LOGGER.debug(f"compressing file -> {file_to_compress}")
        ######################################################
        # compress the file if it is too large
        ######################################################
        compress_command = [
            "compress-discord.sh",
            f"{file_to_compress}",
        ]

        try:

            _ = await shell._aio_run_process_and_communicate(compress_command, cwd=f"{tmpdirname}")

            LOGGER.debug(
                f"compress_video: new file size for {file_to_compress} = {pathlib.Path(file_to_compress).stat().st_size}"
            )

            ######################################################
            # nuke the uncompressed version
            ######################################################

            LOGGER.info(f"nuking uncompressed: {file_to_compress}")

            # nuke the originals
            unlink_func = functools.partial(unlink_orig_file, f"{file_to_compress}")

            # 2. Run in a custom thread pool:
            with concurrent.futures.ThreadPoolExecutor() as pool:
                unlink_result = await bot.loop.run_in_executor(pool, unlink_func)
                # rich.print(f"count: {count} - Unlink", unlink_result)

            # Nuke old message now that everything is done
            await msg_upload.delete()
            return True
        except Exception as ex:
            print(ex)
            exc_type, exc_value, exc_traceback = sys.exc_info()
            LOGGER.error(f"Error Class: {str(ex.__class__)}")
            output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
            LOGGER.warning(output)
            LOGGER.error(f"exc_type: {exc_type}")
            LOGGER.error(f"exc_value: {exc_value}")
            traceback.print_tb(exc_traceback)

    else:
        LOGGER.debug(f"no videos to process in {tmpdirname}")
        return False


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/133702ceb8682ec3927530ac35ad28d47a42802e/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/cogs/settings.py
class Twitter(commands.Cog):
    def __init__(self, cerebro):
        self.bot = cerebro

    @commands.Cog.listener()
    async def on_ready(self):
        print(f"{type(self).__name__} Cog ready.")

    @commands.Cog.listener()
    async def on_guild_join(self, guild):
        """Add new guilds to the database"""
        _ = await guild_factory.Guild(id=guild.id)

    # 4 images
    # $dl_twitter https://twitter.com/bandeauxbae/status/1459532067239337985
    # 1 video
    # $dl_twitter https://twitter.com/bandeauxbae/status/1459541697109663748
    # 1 photo
    # $dl_twitter https://twitter.com/bandeauxbae/status/1462144520364204043
    @commands.command(aliases=["dlt", "t", "twitter"])
    async def dl_twitter(self, ctx, uri: str = None):
        """*Use dl_twitter to download video with thumbnail dl_twitter*
        **Example**: `{dl_twitter}dl_twitter !`
        """
        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, uri = {uri}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        message = ctx.message

        # DMChannel
        # ---------------------------------------------------------------
        dl_uri = uritools.urisplit(uri)
        cmd_args = ["dl_twitter"]
        cmd_kargs = {
            "cmd": DL_SAFE_TWITTER_COMMAND.format(dl_uri=dl_uri.geturi()),
            "uri": f"{dl_uri.geturi()}",
        }

        cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

        LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                await ctx.send(embed=discord.Embed(description="Beginning download ...."))

                gallery_dl_cmd = [
                    "gallery-dl",
                    "--no-mtime",
                    "-v",
                    "--write-info-json",
                    "--write-metadata",
                    f"{dl_uri.geturi()}",
                ]

                ret = await shell._aio_run_process_and_communicate(gallery_dl_cmd, cwd=f"{tmpdirname}")

                await ctx.send(embed=discord.Embed(description=f"Success, downloaded {cmd_metadata.uri}"))

                # refactor this into a function
                file_to_upload = get_files_to_upload(tmpdirname)
                LOGGER.debug(f"BEFORE: {type(self).__name__} -> file_to_upload = {file_to_upload}")

                needs_compression = False
                # if it is a video, we should compress it
                for meme in file_to_upload:
                    res = await compress_video(f"{tmpdirname}", f"{meme}", self.bot, ctx)

                    # if it compressed at least one video, return true
                    if res:
                        # since something was compressed, we want to rerun get_files_to_upload
                        needs_compression = True
                    LOGGER.debug(f"AFTER COMPRESSION: {file_to_upload} -> file_to_upload = {file_to_upload}")

                # If something was compressed, regenerate file_to_upload var.
                if needs_compression:
                    # NOTE: It's possible this list changed due to compression, verify it.
                    # refactor this into a function
                    file_to_upload = get_files_to_upload(tmpdirname)

                LOGGER.debug(f"AFTER: {type(self).__name__} -> file_to_upload = {file_to_upload}")

                for meme in file_to_upload:
                    # if it is a video, compress it
                    if pathlib.Path(meme).stat().st_size > constants.MAX_BYTES_UPLOAD_DISCORD:
                        await ctx.send(
                            embed=discord.Embed(description=f"File is over 8MB... Uploading to dropbox -> {meme}....")
                        )

                        to_upload_list = [meme]
                        await aiodbx.dropbox_upload(to_upload_list)

                        await ctx.send(
                            embed=discord.Embed(description=f"File successfully uploaded to dropbox! -> {meme}....")
                        )
                    else:
                        await ctx.send(embed=discord.Embed(description=f"Uploading to discord -> {file_to_upload}...."))

                        my_files = []

                        for f in file_to_upload:
                            rich.print(f)
                            my_files.append(discord.File(f"{f}"))

                        LOGGER.debug(f"{type(self).__name__} -> my_files = {my_files}")
                        rich.print(my_files)

                        try:
                            msg: Message
                            msg = await ctx.send(files=my_files)
                            await ctx.send(
                                embed=discord.Embed(description=f"File successfully uploaded -> {my_files}....")
                            )
                        except Exception as ex:
                            await ctx.send(embed=discord.Embed(description="Could not upload story to discord...."))
                            print(ex)
                            exc_type, exc_value, exc_traceback = sys.exc_info()
                            LOGGER.error(f"Error Class: {str(ex.__class__)}")
                            output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                            LOGGER.warning(output)
                            await ctx.send(embed=discord.Embed(description=output))
                            LOGGER.error(f"exc_type: {exc_type}")
                            LOGGER.error(f"exc_value: {exc_value}")
                            traceback.print_tb(exc_traceback)

                        # await message.delete(delay=10)

                        # LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, args = {args}")

                        # await ctx.send(files=my_files)

    @dl_twitter.error
    async def dl_twitter_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(description="Sorry, you need `MANAGE SERVER` permissions to change the dl_twitter!")
            )

    @commands.command(aliases=["thread", "dt"])
    async def dl_thread(self, ctx, uri: str = None):
        """*Use dl_thread to download video with thumbnail dl_thread*
        **Example**: `{dl_thread}dl_thread !`
        """
        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, uri = {uri}")

        message: Message
        message = ctx.message

        sent_message: Message
        sent_message = await message.channel.send(f"Downloading Twitter Thread uri -> {uri} ...")

        await sent_message.edit(content=f"{sent_message.content} | ")

        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, uri = {uri}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user: Optional[User]
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        # DMChannel
        # ---------------------------------------------------------------
        dl_uri = uritools.urisplit(uri)
        cmd_kargs = {
            "cmd": DL_TWITTER_THREAD_COMMAND.format(dl_uri=dl_uri.geturi()),
            "uri": f"{dl_uri.geturi()}",
        }

        cmd_args = ["dl_thread"]
        cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

        LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

        await sent_message.edit(
            content=f"{sent_message.content} {type(self).__name__} -> cmd_metadata = {cmd_metadata}..."
        )

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                try:
                    await sent_message.edit(
                        content=f"{sent_message.content} Processing...",
                        delete_after=60.0,
                    )

                    await asyncio.gather(
                        asyncio.create_task(
                            shell.run_coroutine_subprocess(
                                cmd=cmd_metadata.cmd,
                                uri=cmd_metadata.uri,
                                working_dir=f"{tmpdirname}",
                            )
                        ),
                    )
                    await ctx.send(
                        embed=discord.Embed(description=f"Success, downloaded {cmd_metadata.uri}"),
                        delete_after=25.0,
                    )
                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not download twitter thread...."))
                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    tb = traceback.TracebackException(exc_type, exc_value, exc_traceback)
                    traceback_str = "".join(tb.format_exception_only())
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    await ctx.send(embed=discord.Embed(description=f"ERROR: Error Class: {str(ex.__class__)}"))
                    await ctx.send(embed=discord.Embed(description=f"ERROR: Traceback\n\n {traceback_str}"))
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    LOGGER.warning(output)
                    await ctx.send(embed=discord.Embed(description=output))
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
                rich.print(tree_list)

                file_to_upload_list = [f"{p}" for p in tree_list]
                LOGGER.debug(f"{type(self).__name__} -> file_to_upload_list = {file_to_upload_list}")
                rich.print(file_to_upload_list)

                file_to_upload = file_functions.filter_media(file_to_upload_list)

                LOGGER.debug(f"{type(self).__name__} -> file_to_upload = {file_to_upload}")

                await ctx.send(
                    f"{type(self).__name__} -> file_to_upload = {file_to_upload}",
                    delete_after=25.0,
                )

                rich.print(file_to_upload)

                await ctx.send(
                    embed=discord.Embed(description=f"Uploading to discord -> {file_to_upload}...."),
                    delete_after=25.0,
                )

                # dropbox upload
                # my_files = []

                to_upload_list = []

                for f in file_to_upload:
                    rich.print(f)

                    to_upload_list.append(f)

                await ctx.send(
                    embed=discord.Embed(description="Uploading twitter conversation to dropbox ..."),
                    delete_after=25.0,
                )
                try:
                    await aiodbx.dropbox_upload(to_upload_list)

                    await ctx.send(
                        embed=discord.Embed(description=f"File successfully uploaded to dropbox! -> {f}....")
                    )
                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not download twitter thread...."))
                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    tb = traceback.TracebackException(exc_type, exc_value, exc_traceback)
                    traceback_str = "".join(tb.format_exception_only())
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    await ctx.send(embed=discord.Embed(description=f"ERROR: Error Class: {str(ex.__class__)}"))
                    await ctx.send(embed=discord.Embed(description=f"ERROR: Traceback\n\n {traceback_str}"))
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    LOGGER.warning(output)
                    await ctx.send(embed=discord.Embed(description=output))
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                # # chunked_lists = list(misc.divide_chunks(file_to_upload, n=10))
                # # discord has a limit of 10 media uploads per api call. break them up.
                # # SOURCE: https://www.geeksforgeeks.org/break-list-chunks-size-n-python/
                # n = 10
                # final = [
                #     file_to_upload[i * n : (i + 1) * n]
                #     for i in range((len(file_to_upload) + n - 1) // n)
                # ]

                # for count, chunk in enumerate(final):

                #     await ctx.send(
                #         embed=discord.Embed(description=f"Uploading batch {count}...."),
                #         delete_after=30.0
                #     )

                #     my_files = []

                #     for f in chunk:
                #         rich.print(f)
                #         my_files.append(discord.File(f"{f}"))

                #     LOGGER.debug(f"{type(self).__name__} -> my_files = {my_files}")
                #     rich.print(my_files)

                #     try:
                #         msg: Message
                #         msg = await recipient_user.send(files=my_files)
                #         # await msg.pin()
                #     except Exception as ex:
                #         await ctx.send(
                #         embed=discord.Embed(description=f"Could not upload twitter thread to discord....")
                #         )
                #         print(str(ex))
                #         exc_type, exc_value, exc_traceback = sys.exc_info()
                #         tb = traceback.TracebackException(exc_type, exc_value, exc_traceback)
                #         traceback_str = ''.join(tb.format_exception_only())
                #         LOGGER.error("Error Class: {}".format(str(ex.__class__)))
                #         await ctx.send(
                #             embed=discord.Embed(description="ERROR: Error Class: {}".format(str(ex.__class__)))
                #         )
                #         await ctx.send(
                #             embed=discord.Embed(description="ERROR: Traceback\n\n {}".format(traceback_str))
                #         )
                #         output = "[{}] {}: {}".format("UNEXPECTED", type(ex).__name__, ex)
                #         LOGGER.warning(output)
                #         await ctx.send(embed=discord.Embed(description=output))
                #         LOGGER.error("exc_type: {}".format(exc_type))
                #         LOGGER.error("exc_value: {}".format(exc_value))
                #         traceback.print_tb(exc_traceback)

    @dl_thread.error
    async def dl_thread_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(description="Sorry, you need `MANAGE SERVER` permissions to change the dl_thread!")
            )

    # 4 images
    # $dl_card https://twitter.com/bandeauxbae/status/1459532067239337985
    # 1 video
    # $dl_card https://twitter.com/bandeauxbae/status/1459541697109663748
    # 1 photo
    # $dl_card https://twitter.com/bandeauxbae/status/1462144520364204043
    @commands.command()
    async def dl_card(self, ctx, uri: str = None):
        """*Use dl_card to download video with thumbnail dl_card*
        **Example**: `{dl_card}dl_card !`
        """
        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, uri = {uri}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        # DMChannel
        # ---------------------------------------------------------------
        dl_uri = uritools.urisplit(uri)
        cmd_args = ["dl_card"]
        cmd_kargs = {
            "cmd": DL_TWITTER_CARD_COMMAND.format(dl_uri=dl_uri.geturi()),
            "uri": f"{dl_uri.geturi()}",
        }

        cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

        LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                await asyncio.gather(
                    asyncio.create_task(
                        shell.run_coroutine_subprocess(
                            cmd=cmd_metadata.cmd,
                            uri=cmd_metadata.uri,
                            working_dir=f"{tmpdirname}",
                        )
                    ),
                )
                await ctx.send(embed=discord.Embed(description=f"Success, downloaded {cmd_metadata.uri}"))

                tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
                rich.print(tree_list)

                file_to_upload_list = [f"{p}" for p in tree_list]
                LOGGER.debug(f"{type(self).__name__} -> file_to_upload_list = {file_to_upload_list}")
                rich.print(file_to_upload_list)

                file_to_upload = file_functions.filter_media(file_to_upload_list)

                LOGGER.debug(f"{type(self).__name__} -> file_to_upload = {file_to_upload}")

                rich.print(file_to_upload)

                await ctx.send(embed=discord.Embed(description=f"Uploading to discord -> {file_to_upload}...."))

                my_files = []

                for f in file_to_upload:
                    rich.print(f)
                    my_files.append(discord.File(f"{f}"))

                LOGGER.debug(f"{type(self).__name__} -> my_files = {my_files}")
                rich.print(my_files)

                await recipient_user.send(files=my_files)

    @dl_card.error
    async def dl_card_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(description="Sorry, you need `MANAGE SERVER` permissions to change the dl_card!")
            )


async def setup(cerebro):
    await cerebro.add_cog(Twitter(cerebro))


# TODO: Add a feature for tweetpic https://tweetpik.com/#app. will need to use selenium or something.

</document_content>
</document>
<document index="16">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/cogs/upscale.py</source>
<document_content>
"""cerebro_bot.cogs.upscale"""
# pylint: disable=no-member
from __future__ import annotations

import asyncio
from collections import OrderedDict
import functools
import gc
from io import BytesIO
import logging
import math
import os
import os.path
import pathlib
import sys
import tempfile
import traceback
import typing
import urllib.request

from codetiming import Timer
import cv2
import discord
from discord.ext import commands
from discord.message import Message
from fuzzywuzzy import process
import imutils
import numpy as np
import rich
import torch

from cerebro_bot import constants, helpers, shell
from cerebro_bot.bot_logger import get_logger
from cerebro_bot.factories import cmd_factory, guild_factory
from cerebro_bot.utils import aiodbx, file_functions
from cerebro_bot.utils.arch.RRDB import RRDBNet as RRDB
from cerebro_bot.utils.arch.SPSR import SPSRNet as SPSR
from cerebro_bot.utils.arch.SRVGG import SRVGGNetCompact as RealESRGANv2
import cerebro_bot.utils.imgops as ops
import cerebro_bot.utils.unpickler as unpickler

# Note If from __future__ import annotations is used in Python 3.7 or later, annotations are not evaluated at function definition time. Instead, they are stored as strings in __annotations__, This makes it unnecessary to use quotes around the annotation. (see PEP 563).

if typing.TYPE_CHECKING:
    from cerebro_bot.bot import Cerebro

DISCORD_GUILD = os.environ.get("DISCORD_SERVER_ID")

LOGGER = get_logger(__name__, provider="Upscale", level=logging.DEBUG)

IMG_SIZE_CUTOFF = 1080

TYPE_IMAGE_ARRAY = typing.Union[np.ndarray, typing.Any]

TYPE_SCALE = typing.Union[str, int]

CUDA_AVAILABLE = torch.cuda.is_available()  # True


def unique_list(
    list1: typing.Union[typing.List[str], typing.List[bytes]]
) -> typing.Union[typing.List[str], typing.List[bytes]]:
    """_summary_

    Args:
        list1 (typing.Union[typing.List[str], typing.List[bytes]]): _description_

    Returns:
        typing.Union[typing.List[str], typing.List[bytes]]: _description_
    """
    # insert the list to the set
    processed_set = set(list1)
    return list(processed_set)


# https://github.com/discord-math/bot/blob/babb41b71a68b4b099684b3e1ed583f84083f971/plugins/log.py#L63
def path_for(attm: discord.Attachment, basedir: str = "./") -> pathlib.Path:
    """_summary_

    Args:
        attm (discord.Attachment): _description_
        basedir (str, optional): _description_. Defaults to "./".

    Returns:
        pathlib.Path: _description_
    """
    p = pathlib.Path(basedir, str(attm.filename))
    LOGGER.debug(f"path_for: p -> {p}")
    return p


# https://github.com/discord-math/bot/blob/babb41b71a68b4b099684b3e1ed583f84083f971/plugins/log.py#L63


async def save_attachment(attm: discord.Attachment, basedir: str = "./") -> None:
    """_summary_

    Args:
        attm (discord.Attachment): _description_
        basedir (str, optional): _description_. Defaults to "./".
    """
    path = path_for(attm, basedir=basedir)
    LOGGER.debug(f"save_attachment: path -> {path}")
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        ret_code = await attm.save(path, use_cached=True)
        await asyncio.sleep(5)
    except discord.HTTPException:
        await attm.save(path)
    # rich.print("ret_code ", ret_code)
    # print(ret_code)
    # print(ret_code)
    # print(ret_code)
    # print(ret_code)
    # print(ret_code)


async def save_and_process_video_resize(message: Message, basedir: str = "./") -> None:
    """_summary_

    Args:
        message (Message): _description_
        basedir (str, optional): _description_. Defaults to "./".
    """
    if not message.attachments:
        return
    try:
        filepaths = set()
        filepaths |= {path_for(attm, basedir=basedir) for attm in message.attachments}
        LOGGER.debug(f"save_and_process_video_resize: filepaths -> {filepaths}")
        attm_data = await asyncio.gather(
            *[save_attachment(attm, basedir=basedir) for attm in message.attachments],
            return_exceptions=True,
        )
        LOGGER.debug(f"save_and_process_video_resize: attm_data -> {attm_data}")
        for attm, exc in zip(message.attachments, attm_data):
            LOGGER.debug(f"save_and_process_video_resize: attm -> {attm}")
            LOGGER.debug(f"save_and_process_video_resize: exc -> {exc}")
            if exc is not None:
                LOGGER.info(
                    f"Could not save attachment {attm.proxy_url} for {message.id}",
                    exc_info=exc,
                )
                # try:
                #     os.unlink(path_for(attm))
                # except FileNotFoundError:
                #     pass
        filepaths = set()
    finally:
        # for filepath in filepaths:
        #     try:
        #         # os.unlink(filepath)
        #         print(f"filepath -> {filepath}")
        #     except FileNotFoundError:
        #         pass
        pass


async def ffmpeg_square_attachments(message: Message, tmpdirname, args, ctx) -> None:
    """_summary_

    Args:
        message (Message): _description_
        tmpdirname (_type_): _description_
        args (_type_): _description_
        ctx (_type_): _description_
    """
    if message.attachments:
        await save_and_process_video_resize(message, basedir=tmpdirname)


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/133702ceb8682ec3927530ac35ad28d47a42802e/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/cogs/settings.py
class Upscale(commands.Cog):
    """_summary_

    Args:
        commands (_type_): _description_
    """

    def __init__(self, cerebro: Cerebro):
        self.bot = cerebro

    @commands.Cog.listener()
    async def on_ready(self) -> None:
        """_summary_"""
        print(f"{type(self).__name__} Cog ready.")

    @commands.Cog.listener()
    async def on_guild_join(self, guild: guild_factory.Guild) -> None:
        """Add new guilds to the database"""
        await guild_factory.Guild(id=guild.id)

    @commands.command(
        aliases=[
            "list-models",
            "list_models",
            "lm",
            "show-models",
            "show_models",
            "sm",
            "get-models",
            "get_models",
            "gm",
        ]
    )
    async def models(self, ctx: commands.context.Context, *args) -> None:  # type: ignore
        """`$models [-dm]` // Lists all available models as a .txt file. Can add `-dm` flag to be DM'd a regular list."""
        if "-dm" in args:
            models = iter([m[:-4] for m in self.bot.models])
            plus = False
            sublists, current = [], f"+ {next(models)}"
            for model in models:
                if len(current) + 4 + len(model) > 1990:
                    sublists.append(current)
                    current = model
                else:
                    current += f'\n{"+" if plus else "-"} {model}'
                    plus = not plus
            sublists.append(current)
            rich.print(f"sublists -> {sublists}")
            unique_sublists = unique_list(sublists)
            for sublist in unique_sublists:
                message = f"```diff\n{sublist}```"
                await ctx.author.send(message)

        else:
            models = [m[:-4] for m in self.bot.models]
            unique_models = unique_list(models)
            LOGGER.info(f"{type(self).__name__} unique_models={unique_models}")
            rich.print(f"{type(self).__name__} unique_models={unique_models}")
            await ctx.message.channel.send(
                "",
                file=discord.File(BytesIO(("\n".join(unique_models)).encode("utf8")), "models.txt"),
            )

    @commands.command()
    async def addmodel(self, ctx: commands.context.Context, url: str, nickname: str) -> None:
        """`$addmodel [url] [nickname]` // Adds model from url with nickname. Please include the scale of the model in the name, for example, 4xBox."""
        await ctx.message.channel.send(f"Adding model {nickname}...")
        model_name = nickname.replace(".pth", "") + ".pth"
        try:
            if not os.path.exists(f"./{self.bot.ml_models_path}/{model_name}"):
                urllib.request.urlretrieve(url, f"./{self.bot.ml_models_path}/{model_name}")
                await ctx.message.channel.send(f"Model {nickname} successfully added.")
                self.bot.models.append(model_name)
                self.bot.models.sort()
                self.bot.fuzzymodels, self.bot.aliases = self.bot.build_aliases()
            else:
                await ctx.message.channel.send(f"Model {nickname} already exists.")
        except Exception:
            await ctx.message.channel.send(f"Error adding model {nickname}!")

    @commands.command()
    async def replacemodel(self, ctx: commands.context.Context, url: str, nickname: str) -> None:
        """replace model .pth"""
        await ctx.message.channel.send(f"Replacing model {nickname}...")
        model_name = nickname.replace(".pth", "") + ".pth"
        try:
            if os.path.exists(f"./{self.bot.ml_models_path}/{model_name}"):
                urllib.request.urlretrieve(url, f"./{self.bot.ml_models_path}/{model_name}")
                await ctx.message.channel.send(f"Model {nickname} successfully added.")
                self.bot.models.append(model_name)
                self.bot.models.sort()
                self.bot.fuzzymodels, self.bot.aliases = self.bot.build_aliases()
            else:
                await ctx.message.channel.send(f"Model {nickname} does not exist.")
        except Exception:
            await ctx.message.channel.send(f"Error replacing model {nickname}!")

    @commands.command()
    async def removemodel(self, ctx: commands.context.Context, nickname: str) -> None:
        """remove model .pth"""
        LOGGER.debug(f"type(nickname) -> {type(nickname)}")

        model_name = nickname.replace(".pth", "") + ".pth"
        if model_name in self.bot.models and os.path.exists(f"./{self.bot.ml_models_path}/{model_name}"):
            self.bot.models.remove(model_name)
            self.bot.models.sort()
            os.unlink(f"./{self.bot.ml_models_path}/{model_name}")
            self.bot.fuzzymodels, self.bot.aliases = self.bot.build_aliases()
            await ctx.message.channel.send(f"Removed model {nickname}!")
        else:
            await ctx.message.channel.send(f"Model {nickname} doesn't exist!")

    @commands.command()
    async def reloadmodels(self, ctx: commands.context.Context) -> None:
        """reload model .pth"""
        self.bot.models = []
        pth_list_only = helpers.walk_ml_model_dir()
        self.bot.models.extend(f"{m.name}" for m in pth_list_only)
        self.bot.models.sort()
        self.bot.fuzzymodels, self.bot.aliases = self.bot.build_aliases()
        await ctx.message.channel.send("Done.")

    @removemodel.error
    @replacemodel.error
    async def not_mod_handler(
        self,
        ctx: commands.context.Context,
        error: typing.Union[commands.MissingRole, typing.Any],
    ) -> None:
        if isinstance(error, commands.MissingRole):
            await ctx.message.channel.send("You do not have permission to perform that command!")

    @commands.command()
    async def montage(self, ctx: commands.context.Context, img1: str, img2: str, label: str) -> None:
        """`$montage [url1] [url2] [label]` // Creates a montage of two specified images with specified label"""
        try:
            image_1 = self.download_img_from_url(img1)
            image_2 = self.download_img_from_url(img2)
        except Exception:
            await ctx.message.channel.send(f"{ctx.message.author.mention}, one of your images could not be downloaded.")
            return

        await ctx.message.channel.send(f"Creating montage {ctx.message.author.mention} ...")

        try:
            montage = self.make_montage(image_1, image_2, label)
        except Exception:
            await ctx.message.channel.send(f"{ctx.message.author.mention}, there was an error creating your montage.")
            return

        data = BytesIO(cv2.imencode(".png", montage, [cv2.IMWRITE_PNG_COMPRESSION, 16])[1].tostring())

        await ctx.message.channel.send("", file=discord.File(data, "montage.png"))

    @commands.command()
    async def downscale(
        self,
        ctx: commands.context.Context,
        img: str,
        amt: typing.Union[str, int],
        filter: str = "area",
    ) -> None:
        """`$downscale [url] [amount] [filter]` // Downscales the image by the amount listed. Filter is optional and defaults to box/area."""

        try:
            image = self.download_img_from_url(img)
            filename = img[img.rfind("/") + 1 :]
        except Exception:
            await ctx.message.channel.send(f"{ctx.message.author.mention}, your images could not be downloaded.")
            return

        await ctx.message.channel.send("Downscaling image...")

        if filter in {"point", "nearest", "nn", "nearest_neighbor", "nearestneighbor"}:
            interpolation = cv2.INTER_NEAREST
        elif filter in {"box", "area"}:
            interpolation = cv2.INTER_AREA
        elif filter in {"linear", "bilinear", "triangle"}:
            interpolation = cv2.INTER_LINEAR
        elif filter in {"cubic", "bicubic"}:
            interpolation = cv2.INTER_CUBIC
        elif filter in {"exact", "linear_exact", "linearexact"}:
            interpolation = cv2.INTER_LINEAR_EXACT
        elif filter in {"lanczos", "lanczos64"}:
            interpolation = cv2.INTER_LANCZOS4
        else:
            interpolation = cv2.INTER_AREA

        image = self.downscale_img(image, interpolation, amt)

        data = BytesIO(cv2.imencode(".png", image, [cv2.IMWRITE_PNG_COMPRESSION, 16])[1].tostring())

        msg: Message
        msg = await ctx.message.channel.send(
            f"{ctx.author.mention}, your image has been downscaled by {amt}.",
            file=discord.File(data, f'{filename.split(".")[0]}.png'),
        )
        # await msg.pin()

    async def logic_image_resize(self, args, message, image, filename):
        arg_width = int(args[1])
        arg_height = int(args[2])
        try:
            sent_message = await message.channel.send(f"Image is being resized using width={args[1]},height={args[2]}")

            image = self.run_resize_img(image, arg_width, arg_height)

            img_height, img_width = image.shape[:2]

            await sent_message.edit(content=f"{sent_message.content} | ")

            await sent_message.edit(content=f"{sent_message.content} Processing...")

            img = image.astype("uint8")

            await sent_message.edit(content=f"{sent_message.content} Sending...")

            # converts result image to png bytestream
            ext = ".png"
            data = BytesIO(cv2.imencode(".png", img, [cv2.IMWRITE_PNG_COMPRESSION, 16])[1].tobytes())
            if len(data.getvalue()) >= 8000000:
                ext = ".webp"
                data = BytesIO(cv2.imencode(".webp", img, [cv2.IMWRITE_WEBP_QUALITY, 64])[1].tobytes())

            # send result through discord
            await message.channel.send(
                f"Image has been resized towidth={img_width},height={img_height}.",
                file=discord.File(data, filename.split(".")[0] + ext),
            )
            await sent_message.edit(content=f"{sent_message.content} Done.")

        except Exception as ex:
            print(ex)
            print(ex)
            exc_type, exc_value, exc_traceback = sys.exc_info()
            # [ERROR] MEMES REPOSITORIES: exc_value: table memes already exists
            LOGGER.error(f"Error Class: {str(ex.__class__)}")
            output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
            LOGGER.warning(output)
            LOGGER.error(f"exc_type: {exc_type}")
            LOGGER.error(f"exc_value: {exc_value}")
            traceback.print_tb(exc_traceback)
            await message.channel.send(f"{message.author.mention}, your image could not be resized.")

    @commands.command()
    async def resize(self, ctx: commands.context.Context, *args) -> None:  # type:ignore
        """`$resize image or url` // Resize media.

        Example: `$resize www.imageurl.com/image.png 64 64`
        """
        message: Message
        message = ctx.message
        rich.inspect(message, methods=True)
        args = list(args)
        # Grab image URL
        if message.attachments:
            url = message.attachments[0].url
            args.insert(0, url)
            filename = message.attachments[0].filename
        else:
            try:
                url = args[0]
                filename = url[url.rfind("/") + 1 :]
            except Exception:
                await message.channel.send(
                    f"{message.author.mention}, you need to provide a url or an image attachment.".format(
                        message.author.mention
                    )
                )

        await message.channel.send(
            f"{message.author.mention}, You called resize with arguments -> {args} and url -> {url}."
        )

        if f".{filename.split('.')[1]}" in file_functions.IMAGE_EXTENSIONS:
            try:
                image = self.download_img_from_url(url)

                await message.channel.send(f"{message.author.mention}, got image -> {type(image)}.")
            except Exception:
                await message.channel.send(f"{message.author.mention}, your image could not be downloaded.")
                return

            await self.logic_image_resize(args, message, image, filename)

        elif f".{filename.split('.')[1]}" in file_functions.VIDEO_EXTENSIONS:
            await message.channel.send(f"{message.author.mention}, looks like this is a video, processing ...")

            with tempfile.TemporaryDirectory() as tmpdirname:
                print("created temporary directory", tmpdirname)

                if message.attachments:
                    path_to_file = f"{tmpdirname}/{message.attachments[0].filename}"
                    sent_message = await message.channel.send(f"Saving file locally for processing -> {path_to_file}")

                    await message.attachments[0].save(path_to_file)

                    await sent_message.edit(content=f"{sent_message.content} | ")

                    input_file = pathlib.Path(path_to_file)

                    assert input_file.exists()

                    full_path_input_file = f"{input_file.absolute()}"

                    (
                        output_file_str,
                        output_file,
                        full_path_output_file,
                    ) = get_square_filename(input_file)

                    arg_width = int(args[1])
                    int(args[2])

                    # If we'd like to keep the aspect ratio, we need to specify only one component, either width or height, and set the other component to -1. For example, this command line:
                    FFMPEG_SQUARE_MP4_COMMAND = f'ffmpeg -y -hide_banner -loglevel warning -i "{full_path_input_file}" -vf "scale=w={arg_width}:h=-1:force_original_aspect_ratio=decrease,setdar=1:1" "{full_path_output_file}"'

                    _cmd = FFMPEG_SQUARE_MP4_COMMAND

                    # rich.print(_cmd)

                    cmd_args = ["squared"]
                    cmd_kargs = {
                        "cmd": _cmd,
                        "uri": "",
                    }

                    cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

                    LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

                    await sent_message.edit(content=f"{sent_message.content} Resizing...")

                    try:
                        with Timer(text="\nTotal elapsed time: {:.1f}"):
                            await asyncio.gather(
                                asyncio.create_task(
                                    shell.run_coroutine_subprocess(
                                        cmd=cmd_metadata.cmd,
                                        uri=cmd_metadata.uri,
                                        working_dir=f"{tmpdirname}",
                                    )
                                ),
                            )

                            await sent_message.edit(content=f"{sent_message.content} Resized.")

                    except Exception as ex:
                        print(ex)
                        exc_type, exc_value, exc_traceback = sys.exc_info()
                        # [ERROR] MEMES REPOSITORIES: exc_value: table memes already exists
                        LOGGER.error(f"Error Class: {str(ex.__class__)}")
                        output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                        LOGGER.warning(output)
                        LOGGER.error(f"exc_type: {exc_type}")
                        LOGGER.error(f"exc_value: {exc_value}")
                        traceback.print_tb(exc_traceback)

                os.rename(full_path_output_file, full_path_input_file)

                tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
                rich.print(tree_list)

                file_to_upload_list = [f"{p}" for p in tree_list]
                LOGGER.debug(f"{type(self).__name__} -> file_to_upload_list = {file_to_upload_list}")
                rich.print(file_to_upload_list)

                files_to_upload = file_functions.filter_media(file_to_upload_list)

                LOGGER.debug(f"{type(self).__name__} -> file_to_upload = {files_to_upload}")

                LOGGER.debug(f"{type(self).__name__} -> files_to_upload = {files_to_upload}")

                file_to_upload = f"{files_to_upload[0]}"

                # for meme_to_upload in files_to_upload:
                rich.print(f"[meme to upload] -> {file_to_upload}")

                LOGGER.debug(f"{type(self).__name__} -> file_to_upload = {file_to_upload}")

                if pathlib.Path(file_to_upload).stat().st_size > constants.MAX_BYTES_UPLOAD_DISCORD:
                    await sent_message.edit(content=f"{sent_message.content} File is over 8MB... Uploading to dropbox.")

                    try:
                        await aiodbx.dropbox_upload([file_to_upload])
                        await sent_message.edit(content=f"{sent_message.content} Done.")

                    except Exception:
                        await message.channel.send(f"{message.author.mention}, your video could not be uploaded.")

                else:
                    await ctx.send(embed=discord.Embed(description=f"Uploading to discord -> {file_to_upload}...."))

                    recipient_user: discord.user.User
                    recipient_user = ctx.channel.recipient

                    msg: Message
                    msg = await recipient_user.send(file=discord.File(f"{file_to_upload}"))

    @commands.command(aliases=["multi_resize", "mr", "rm"])
    async def resize_multi(self, ctx: commands.context.Context, *args) -> None:  # type:ignore
        """`$resize image or url` // Resize media.

        Example: `$resize www.imageurl.com/image.png 64 64`
        """
        message: Message
        message = ctx.message
        rich.inspect(message, methods=True)
        args = list(args)
        # Grab image URL
        if message.attachments:
            url = message.attachments[0].url
            args.insert(0, url)
            filename = message.attachments[0].filename
        else:
            try:
                url = args[0]
                filename = url[url.rfind("/") + 1 :]
            except Exception:
                await message.channel.send(
                    f"{message.author.mention}, you need to provide a url or an image attachment.".format(
                        message.author.mention
                    )
                )

        # testing

        await message.channel.send(
            f"{message.author.mention}, You called resize with arguments -> {args} and url -> {url}."
        )

        # resize using multiple default width sizes
        for multi_width in ["64", "128", "256", "512"]:
            # override args
            args[1] = multi_width
            args[2] = multi_width

            if f".{filename.split('.')[1]}" in file_functions.IMAGE_EXTENSIONS:
                try:
                    image = self.download_img_from_url(url)

                    await message.channel.send(f"{message.author.mention}, got image -> {type(image)}.")
                except Exception:
                    await message.channel.send(f"{message.author.mention}, your image could not be downloaded.")
                    return

                await self.logic_image_resize(args, message, image, filename)

            elif f".{filename.split('.')[1]}" in file_functions.VIDEO_EXTENSIONS:
                await message.channel.send(f"{message.author.mention}, looks like this is a video, processing ...")

                with tempfile.TemporaryDirectory() as tmpdirname:
                    print("created temporary directory", tmpdirname)

                    if message.attachments:
                        path_to_file = f"{tmpdirname}/{message.attachments[0].filename}"
                        sent_message = await message.channel.send(
                            f"Saving file locally for processing -> {path_to_file}"
                        )

                        await message.attachments[0].save(path_to_file)

                        await sent_message.edit(content=f"{sent_message.content} | ")

                        input_file = pathlib.Path(path_to_file)

                        assert input_file.exists()

                        full_path_input_file = f"{input_file.absolute()}"

                        (
                            output_file_str,
                            output_file,
                            full_path_output_file,
                        ) = get_square_filename(input_file)

                        arg_width = int(multi_width)
                        int(multi_width)

                        # If we'd like to keep the aspect ratio, we need to specify only one component, either width or height, and set the other component to -1. For example, this command line:
                        FFMPEG_SQUARE_MP4_COMMAND = f'ffmpeg -y -hide_banner -loglevel warning -i "{full_path_input_file}" -vf "scale=w={arg_width}:h=-1:force_original_aspect_ratio=decrease,setdar=1:1" "{full_path_output_file}"'

                        _cmd = FFMPEG_SQUARE_MP4_COMMAND

                        cmd_args = ["squared"]
                        cmd_kargs = {
                            "cmd": _cmd,
                            "uri": "",
                        }

                        cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

                        LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

                        await sent_message.edit(content=f"{sent_message.content} Resizing...")

                        try:
                            with Timer(text="\nTotal elapsed time: {:.1f}"):
                                await asyncio.gather(
                                    asyncio.create_task(
                                        shell.run_coroutine_subprocess(
                                            cmd=cmd_metadata.cmd,
                                            uri=cmd_metadata.uri,
                                            working_dir=f"{tmpdirname}",
                                        )
                                    ),
                                )

                                await sent_message.edit(content=f"{sent_message.content} Resized.")

                        except Exception as ex:
                            print(ex)
                            exc_type, exc_value, exc_traceback = sys.exc_info()
                            # [ERROR] MEMES REPOSITORIES: exc_value: table memes already exists
                            LOGGER.error(f"Error Class: {str(ex.__class__)}")
                            output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                            LOGGER.warning(output)
                            LOGGER.error(f"exc_type: {exc_type}")
                            LOGGER.error(f"exc_value: {exc_value}")
                            traceback.print_tb(exc_traceback)

                    os.rename(full_path_output_file, full_path_input_file)

                    # import bpdb
                    # bpdb.set_trace()
                    tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
                    rich.print(tree_list)

                    file_to_upload_list = [f"{p}" for p in tree_list]
                    LOGGER.debug(f"{type(self).__name__} -> file_to_upload_list = {file_to_upload_list}")
                    rich.print(file_to_upload_list)

                    files_to_upload = file_functions.filter_media(file_to_upload_list)

                    LOGGER.debug(f"{type(self).__name__} -> file_to_upload = {files_to_upload}")

                    LOGGER.debug(f"{type(self).__name__} -> files_to_upload = {files_to_upload}")

                    file_to_upload = f"{files_to_upload[0]}"

                    # for meme_to_upload in files_to_upload:
                    rich.print(f"[meme to upload] -> {file_to_upload}")

                    LOGGER.debug(f"{type(self).__name__} -> file_to_upload = {file_to_upload}")

                    if pathlib.Path(file_to_upload).stat().st_size > constants.MAX_BYTES_UPLOAD_DISCORD:
                        await sent_message.edit(
                            content=f"{sent_message.content} File is over 8MB... Uploading to dropbox."
                        )

                        try:
                            await aiodbx.dropbox_upload([file_to_upload])
                            await sent_message.edit(content=f"{sent_message.content} Done.")

                        except Exception:
                            await message.channel.send(f"{message.author.mention}, your video could not be uploaded.")

                    else:
                        await ctx.send(embed=discord.Embed(description=f"Uploading to discord -> {file_to_upload}...."))

                        recipient_user: discord.user.User
                        recipient_user = ctx.channel.recipient

                        msg: Message
                        msg = await recipient_user.send(file=discord.File(f"{file_to_upload}"))
                        # await msg.pin()

    @commands.command()
    async def upscale(self, ctx: commands.context.Context, *args) -> None:  # type:ignore
        """`$upscale [model]` // Upscales attached image using specified model. Model name input will be automatically matched with the closest model name.

        `$upscale [url] [model]` // Upscales linked image using specified model. Model name input will be automatically matched with the closest model name.

        Optional `$upscale` args:

        `$downscale [amount]` // Downscales the image by the amount listed. For example, `$downscale 4` will make the image 25% of its original size.

        `$filter [filter]` // Filter to be used for downscaling. Must be a valid OpenCV image interpolation filter, with ImageMagick aliases supported as well. Defaults to box/area.

        `$blur [type] [amount]` // Blurs the image before upscaling using the specified blur type and the amount specified. Only Gaussian and median blur are currently supported.

        `$montage` // Creates aside by side comparison of the LR and result after upscaling.

        `$seamless` // Duplicates the image around the edges to make a seamless texture retain its seamlessness

        Example: `$upscale www.imageurl.com/image.png 4xBox.pth $downscale 4 $filter point $montage`
        """
        message = ctx.message
        args = list(args)
        # Grab image URL
        if message.attachments:
            url = message.attachments[0].url
            args.insert(0, url)
            filename = message.attachments[0].filename
        else:
            try:
                url = args[0]
                filename = url[url.rfind("/") + 1 :]
            except Exception:
                await message.channel.send(
                    f"{message.author.mention}, you need to provide a url or an image attachment."
                )

        # Grab model name
        try:
            model_jobs = args[1].split(";")[:3]
        except Exception:
            await message.channel.send(f"{message.author.mention}, you need to provide a model.")
            return

        try:
            (
                downscale,
                filter,
                montage,
                blur_type,
                blur_amt,
                seamless,
            ) = await self.parse_flags(args, message)
        except ValueError as e:
            await message.channel.send(e)
            return

        try:
            image = self.download_img_from_url(url)
        except Exception:
            await message.channel.send(f"{message.author.mention}, your image could not be downloaded.")
            return

        if downscale:
            try:
                image = self.downscale_img(image, filter, downscale)
            except Exception:
                await message.channel.send(f"{message.author.mention}, your image could not be downscaled.")

        if blur_type:
            try:
                if not blur_amt:
                    await message.channel.send(f"Unknown blur amount {blur_amt}.")
                elif type(blur_amt) != int:
                    await message.channel.send(f"Blur amount {blur_amt} not a number.")
                elif blur_type in {"gauss", "gaussian"}:
                    if blur_amt % 2 != 1:
                        blur_amt += 1
                    image = cv2.GaussianBlur(image, (blur_amt, blur_amt), cv2.BORDER_DEFAULT)
                elif blur_type in {"median"}:
                    if blur_amt % 2 != 1:
                        blur_amt += 1
                    image = cv2.medianBlur(image, blur_amt)
                else:
                    await message.channel.send(f"Unknown blur type {blur_type}.")
            except Exception:
                await message.channel.send(f"{message.author.mention}, your image could not be blurred.")
        if image.shape[0] > IMG_SIZE_CUTOFF or image.shape[1] > IMG_SIZE_CUTOFF:
            await message.channel.send(
                f"{message.author.mention}, your image is larger than the size threshold ({IMG_SIZE_CUTOFF})."
            )

        elif len(self.bot.job_queue) == 0:
            self.bot.job_queue[0] = {"jobs": []}
            for model_job in model_jobs:
                models = (
                    model_job.split(">")[:3]
                    if ":" in model_job or "&" in model_job
                    else [
                        self.bot.aliases[process.extractOne(model.replace(".pth", ""), self.bot.fuzzymodels)[0]]
                        for model in model_job.split(">")[:3]
                    ]
                )
                self.bot.job_queue[0]["jobs"].append(
                    {
                        "message": message,
                        "filename": filename,
                        "models": models,
                        "image": image,
                    }
                )
            while len(self.bot.job_queue[0]["jobs"]) > 0:
                try:
                    job = self.bot.job_queue[0]["jobs"].pop(0)
                    LOGGER.info(f"job -> {job}")
                    sent_message = await message.channel.send(
                        f"{job['filename']} is being upscaled using {', '.join(job['models']) if len(job['models']) > 1 else job['models'][0]}"
                    )

                    img = job["image"]

                    # this is needed for montaging with chains
                    og_image = img

                    for i in range(len(job["models"])):
                        img_height, img_width = img.shape[:2]

                        if not img_height > IMG_SIZE_CUTOFF and not img_width > IMG_SIZE_CUTOFF:
                            await sent_message.edit(content=f"{sent_message.content} | ")

                            if seamless:
                                img = self.make_seamless(img)

                            LOGGER.debug(
                                f"BROKENNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN job[\"models\"][i] -> {job['models'][i]}"
                            )

                            await self.load_model(job["models"][i])
                            scale = self.bot.last_scale

                            await sent_message.edit(content=f"{sent_message.content} Processing...")
                            upscale = functools.partial(ops.auto_split_upscale, img, self.esrgan, scale)
                            rlt, _ = await self.bot.loop.run_in_executor(None, upscale)

                            if seamless:
                                rlt = self.crop_seamless(rlt, scale)
                        else:
                            await message.channel.send(
                                f"Unable to continue chain due to size cutoff ({IMG_SIZE_CUTOFF})."
                            )
                            break

                        if len(models) > 1:
                            img = rlt.astype("uint8")

                    await sent_message.edit(content=f"{sent_message.content} Sending...")

                    data = BytesIO(cv2.imencode(".png", rlt, [cv2.IMWRITE_PNG_COMPRESSION, 16])[1].tobytes())
                    ext = ".png"
                    if len(data.getvalue()) >= 8000000:
                        ext = ".webp"
                        data = BytesIO(cv2.imencode(".webp", rlt, [cv2.IMWRITE_WEBP_QUALITY, 64])[1].tobytes())

                    await self.bot.loop.create_task(
                        job["message"].channel.send(
                            f'{job["message"].author.mention}, your image has been upscaled using {", ".join(job["models"]) if len(job["models"]) > 1 else job["models"][0]}.',
                            file=discord.File(data, job["filename"].split(".")[0] + ext),
                        )
                    )
                    await sent_message.edit(content=f"{sent_message.content} Done.")

                except Exception as ex:
                    print(ex)
                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    # [ERROR] MEMES REPOSITORIES: exc_value: table memes already exists
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    LOGGER.warning(output)
                    await ctx.send(embed=discord.Embed(description=output))
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)
                    await job["message"].channel.send(
                        f'{job["message"].author.mention}, there was an error upscaling your image.'
                    )

                if montage:
                    try:
                        montage_img = self.make_montage(
                            og_image,
                            rlt,
                            ", ".join(job["models"]) if len(job["models"]) > 1 else job["models"][0],
                        )
                        # converts result image to png bytestream
                        ext = ".png"
                        data = BytesIO(
                            cv2.imencode(
                                ".png",
                                montage_img,
                                [cv2.IMWRITE_PNG_COMPRESSION, 16],
                            )[1].tostring()
                        )
                        if len(data.getvalue()) >= 8000000:
                            ext = ".webp"
                            data = BytesIO(
                                cv2.imencode(
                                    ".webp",
                                    montage_img,
                                    [cv2.IMWRITE_WEBP_QUALITY, 64],
                                )[1].tostring()
                            )

                        msg = await job["message"].channel.send(
                            f'{job["message"].author.mention}, your montage has been created.',
                            file=discord.File(
                                data,
                                job["filename"].split(".")[0] + "_montage" + ext,
                            ),
                        )
                    except Exception:
                        await job["message"].channel.send(
                            f'{job["message"].author.mention}, there was an error creating your montage.'
                        )
                # Garbage collection
                gc.collect()
                torch.cuda.empty_cache()
            self.bot.job_queue.pop(0)
        else:
            for model_job in model_jobs:
                models = [
                    self.bot.aliases[process.extractOne(model.replace(".pth", ""), self.bot.fuzzymodels)[0]]
                    for model in model_job.split(">")[:3]
                ]
                self.bot.job_queue[0]["jobs"].append(
                    {
                        "message": message,
                        "filename": filename,
                        "models": models,
                        "image": image,
                    }
                )
                await message.channel.send(
                    f'{message.author.mention}, {filename} has been added to the queue. Your image is #{len(self.bot.job_queue[0]["jobs"])} in line for processing.'
                )

    # This code is a somewhat modified version of BlueAmulet's fork of ESRGAN by Xinntao
    def process(self, img: TYPE_IMAGE_ARRAY) -> TYPE_IMAGE_ARRAY:
        """
        Does the processing part of ESRGAN. This method only exists because the same block of code needs to be ran twice for images with transparency.

                Parameters:
                        img (array): The image to process

                Returns:
                        rlt (array): The processed image
        """
        if img.shape[2] == 3:
            img = img[:, :, [2, 1, 0]]
        elif img.shape[2] == 4:
            img = img[:, :, [2, 1, 0, 3]]
        img = torch.from_numpy(np.transpose(img, (2, 0, 1))).float()
        img_LR = img.unsqueeze(0)
        img_LR = img_LR.to(self.bot.device, non_blocking=True)
        img_LR = img_LR.half()

        output = self.model(img_LR).data.squeeze(0).float().cpu().clamp_(0, 1).numpy()
        if output.shape[0] == 3:
            output = output[[2, 1, 0], :, :]
        elif output.shape[0] == 4:
            output = output[[2, 1, 0, 3], :, :]
        output = np.transpose(output, (1, 2, 0))
        return output

    async def load_model(self, model_name: str) -> None:
        """_summary_

        Args:
            model_name (str): _description_
        """
        if model_name == self.bot.last_model:
            return
        if ":" in model_name or "&" in model_name:  # interpolating OTF, example: 4xBox:25&4xPSNR:75
            interps = model_name.split("&")[:2]

            _path_to_model1 = self.bot.ml_models_path + interps[0].split(":")[0]
            _path_to_model2 = self.bot.ml_models_path + interps[1].split(":")[0]

            LOGGER.debug(f"_path_to_model1 -> {_path_to_model1}")
            LOGGER.debug(f"_path_to_model2 -> {_path_to_model2}")

            model_1 = torch.load(
                _path_to_model1,
                pickle_module=unpickler.RestrictedUnpickle,
            )
            model_2 = torch.load(
                _path_to_model2,
                pickle_module=unpickler.RestrictedUnpickle,
            )
            state_dict = OrderedDict()
            for k, v_1 in model_1.items():
                v_2 = model_2[k]
                state_dict[k] = (int(interps[0].split(":")[1]) / 100) * v_1 + (
                    int(interps[1].split(":")[1]) / 100
                ) * v_2
        else:
            model_path = self.bot.ml_models_path + model_name
            LOGGER.debug(f"model_path -> {model_path}")
            state_dict = torch.load(model_path, pickle_module=unpickler.RestrictedUnpickle)

        if "params" in state_dict.keys() and "body.0.weight" in state_dict["params"].keys():
            LOGGER.warning("Model type: RealESRGANv2")
            self.model = RealESRGANv2(state_dict)
            self.bot.last_in_nc = self.model.num_in_ch
            self.bot.last_out_nc = self.model.num_out_ch
            self.bot.last_nf = self.model.num_feat
            self.bot.last_nb = self.model.num_conv
        elif "f_HR_conv1.0.weight" in state_dict:
            LOGGER.warning("Model type: SPSR")
            self.model = SPSR(state_dict)
            self.bot.last_in_nc = self.model.in_nc
            self.bot.last_out_nc = self.model.out_nc
            self.bot.last_nf = self.model.num_filters
            self.bot.last_nb = self.model.num_blocks
        else:
            LOGGER.warning("Model type: RRDB")
            self.model = RRDB(state_dict)
            self.bot.last_in_nc = self.model.in_nc
            self.bot.last_out_nc = self.model.out_nc
            self.bot.last_nf = self.model.num_filters
            self.bot.last_nb = self.model.num_blocks
        self.bot.last_model = model_name
        self.bot.last_scale = self.model.scale

        del state_dict
        self.model.eval()
        for k, v in self.model.named_parameters():
            v.requires_grad = False
        self.model = self.model.to(self.bot.device, non_blocking=True).half()

    # This code is a somewhat modified version of BlueAmulet's fork of ESRGAN by Xinntao
    def esrgan(self, img: TYPE_IMAGE_ARRAY) -> TYPE_IMAGE_ARRAY:
        """
        Runs ESRGAN on all the images passed in with the specified model

                Parameters:
                        imgs (array): The images to run ESRGAN on
                        model_name (string): The model to use

                Returns:
                        rlts (array): The processed images
        """
        img = img * 1.0 / np.iinfo(img.dtype).max

        if img.ndim == 3 and img.shape[2] == 4 and self.bot.last_in_nc == 3 and self.bot.last_out_nc == 3:
            img1 = np.copy(img[:, :, :3])
            img2 = cv2.merge((img[:, :, 3], img[:, :, 3], img[:, :, 3]))
            output1 = self.process(img1)
            output2 = self.process(img2)
            output = cv2.merge((output1[:, :, 0], output1[:, :, 1], output1[:, :, 2], output2[:, :, 0]))
        else:
            if img.ndim == 2:
                img = np.tile(np.expand_dims(img, axis=2), (1, 1, min(self.bot.last_in_nc, 3)))
            if img.shape[2] > self.bot.last_in_nc:  # remove extra channels
                print("Warning: Truncating image channels")
                img = img[:, :, : self.bot.last_in_nc]
            # pad with solid alpha channel
            elif img.shape[2] == 3 and self.bot.last_in_nc == 4:
                img = np.dstack((img, np.full(img.shape[:-1], 1.0)))
            output = self.process(img)

        output = (output * 255.0).round()
        # if output.ndim == 3 and output.shape[2] == 4:

        # rlts.append(output)
        try:
            # if "NVIDIA" in DEVICE_NAME:
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        except Exception as ex:
            print(ex)
            exc_type, exc_value, exc_traceback = sys.exc_info()
            LOGGER.error(f"Error Class: {str(ex.__class__)}")
            output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
            LOGGER.warning(output)
            LOGGER.error(f"exc_type: {exc_type}")
            LOGGER.error(f"exc_value: {exc_value}")
            traceback.print_tb(exc_traceback)
        return output

    def make_montage(self, img1: TYPE_IMAGE_ARRAY, img2: TYPE_IMAGE_ARRAY, label: str) -> TYPE_IMAGE_ARRAY:
        """Creates a side-by-side comparison of two images with a label

        Parameters:
                img1 (array): The left image
                img2 (array): The right image
                label (string): The label to apply underneath (usually model name)
        Returns:
                img (array): The montaged image
        """
        img1 = cv2.resize(img1, (img2.shape[1], img2.shape[0]), interpolation=cv2.INTER_NEAREST)
        img1 = img1.astype(np.float64)
        img2 = img2.astype(np.float64)
        img = cv2.hconcat([img1, img2])
        img = cv2.copyMakeBorder(img, 0, 36, 0, 0, cv2.BORDER_CONSTANT, value=(0, 0, 0, 255))

        font = cv2.FONT_HERSHEY_SIMPLEX
        font_size = 1
        font_thickness = 2

        textsize = cv2.getTextSize(label, font, font_size, font_thickness)[0]
        textX = math.floor((img.shape[1] - textsize[0]) / 2)
        textY = math.ceil(img.shape[0] - ((40 - textsize[1]) / 2))

        cv2.putText(
            img,
            label,
            (textX, textY),
            font,
            font_size,
            color=(255, 255, 255, 255),
            thickness=font_thickness,
            lineType=cv2.LINE_AA,
        )
        return img

    def make_seamless(self, img: TYPE_IMAGE_ARRAY) -> TYPE_IMAGE_ARRAY:
        """_summary_

        Args:
            img (TYPE_IMAGE_ARRAY): _description_

        Returns:
            TYPE_IMAGE_ARRAY: _description_
        """
        img_height, img_width, img_channels = img.shape
        img = cv2.hconcat([img, img, img])
        img = cv2.vconcat([img, img, img])
        y, x = img_height - 16, img_width - 16
        h, w = img_height + 32, img_width + 32
        img = img[y : y + h, x : x + w]
        return img

    def crop_seamless(self, img: TYPE_IMAGE_ARRAY, scale: TYPE_SCALE) -> TYPE_IMAGE_ARRAY:
        """_summary_

        Args:
            img (TYPE_IMAGE_ARRAY): _description_
            scale (TYPE_SCALE): _description_

        Returns:
            TYPE_IMAGE_ARRAY: _description_
        """
        img_height, img_width, img_channels = img.shape
        y, x = 16 * scale, 16 * scale
        h, w = img_height - (32 * scale), img_width - (32 * scale)
        img = img[y : y + h, x : x + w]
        return img

    async def parse_flags(self, args, message) -> typing.Any:  # type:ignore
        """_summary_

        Args:
            args (_type_): _description_
            message (_type_): _description_

        Raises:
            ValueError: _description_
            ValueError: _description_
            ValueError: _description_
            ValueError: _description_

        Returns:
            typing.Any: _description_
        """
        downscale = None
        filter = cv2.INTER_AREA
        montage = False
        blur_type = None
        blur_amt = None
        seamless = False
        for index, arg in enumerate(args):
            arg = arg.lower()
            if arg in {"-downscale", "-d"}:
                try:
                    downscale = float(args[index + 1]) if args[index + 1] != "auto" else "auto"
                except:
                    raise ValueError("Downscale value not specified.")
            elif arg in {"-filter", "-f"}:
                try:
                    interpolation = args[index + 1].lower()
                    if interpolation in {
                        "point",
                        "nearest",
                        "nn",
                        "nearest_neighbor",
                        "nearestneighbor",
                    }:
                        filter = cv2.INTER_NEAREST
                    elif interpolation in {"box", "area"}:
                        filter = cv2.INTER_AREA
                    elif interpolation in {"linear", "bilinear", "triangle"}:
                        filter = cv2.INTER_LINEAR
                    elif interpolation in {"cubic", "bicubic"}:
                        filter = cv2.INTER_CUBIC
                    elif interpolation in {"exact", "linear_exact", "linearexact"}:
                        filter = cv2.INTER_LINEAR_EXACT
                    elif interpolation in {"lanczos", "lanczos4"}:
                        filter = cv2.INTER_LANCZOS4
                    else:
                        raise ValueError(f"Unknown image filter {interpolation}.")
                except:
                    raise ValueError("Filter value not specified.")
            elif arg in {"-blur", "-b"}:
                try:
                    blur_type = args[index + 1]
                    blur_amt = int(args[index + 2])
                except:
                    raise ValueError("Blur requires 2 arguments, type and amount.")
            elif arg in {"-montage", "-m"}:
                montage = True
            elif arg in {"-seamless", "-s"}:
                seamless = True
        LOGGER.debug(
            f"TYPING: downscale, filter, montage, blur_type, blur_amt, seamless -> {type(downscale)}, {type(filter)}, {type(montage)}, {type(blur_type)}, {type(blur_amt)}, {type(seamless)}"
        )
        return downscale, filter, montage, blur_type, blur_amt, seamless

    def run_resize_img(
        self,
        image: TYPE_IMAGE_ARRAY,
        width: typing.Union[str, int],
        height: typing.Union[str, int],
    ) -> TYPE_IMAGE_ARRAY:
        """_summary_

        Args:
            image (TYPE_IMAGE_ARRAY): _description_
            width (typing.Union[str, int]): _description_
            height (typing.Union[str, int]): _description_

        Returns:
            TYPE_IMAGE_ARRAY: _description_
        """
        return imutils.resize(image, width=width, height=height)

    def downscale_img(
        self,
        image: TYPE_IMAGE_ARRAY,
        filter: int,
        amt: typing.Union[str, int],
    ) -> TYPE_IMAGE_ARRAY:
        """_summary_

        Args:
            image (TYPE_IMAGE_ARRAY): _description_
            filter (int): _description_
            amt (typing.Union[str, int]): _description_

        Returns:
            TYPE_IMAGE_ARRAY: _description_
        """
        scale_percent = 1 / float(amt) * 100
        width = int(image.shape[1] * scale_percent / 100)
        height = int(image.shape[0] * scale_percent / 100)
        dim = (width, height)
        image = cv2.resize(image, dim, interpolation=filter)
        return image

    def download_img_from_url(self, img: str) -> TYPE_IMAGE_ARRAY:
        """_summary_

        Args:
            img (str): _description_

        Returns:
            TYPE_IMAGE_ARRAY: _description_
        """
        req = urllib.request.Request(
            img,
            headers={
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36"
            },
        )
        url = urllib.request.urlopen(req)
        image = np.asarray(bytearray(url.read()), dtype="uint8")
        image = cv2.imdecode(image, cv2.IMREAD_UNCHANGED)
        return image

    # test with: https://cdn.discordapp.com/attachments/909986733309972501/920357313523626015/video0.mov


# https://www.codingforentrepreneurs.com/blog/open-cv-python-change-video-resolution-or-scale


# def make_1080p(cap: cv2.VideoCapture):
#     cap.set(3, 1920)
#     cap.set(4, 1080)


# def make_720p(cap: cv2.VideoCapture):
#     cap.set(3, 1280)
#     cap.set(4, 720)


# def make_480p(cap: cv2.VideoCapture):
#     cap.set(3, 640)
#     cap.set(4, 480)


# def change_res(cap: cv2.VideoCapture, width, height):
#     cap.set(3, width)
#     cap.set(4, height)


# def rescale_frame(frame, percent=75):
#     width = int(frame.shape[1] * percent / 100)
#     height = int(frame.shape[0] * percent / 100)
#     dim = (width, height)
#     return cv2.resize(frame, dim, interpolation=cv2.INTER_AREA)


def get_square_filename(p: pathlib.Path):
    """programatically create square up file name outputs.
    Args:
        fileinfo (fileobject.FileInfo): [description]
    Returns:
        [type]: [description]
    """
    # eg. data/fixtures/ig-square-1080x1080-00000-gif1-farming.mp4
    output_file_str = f"{p.parent}/ig-square-1080x1080-{p.stem}{p.suffix}"

    # eg. <fileobject.FileInfo(00000-gif1-farming.mp4)>
    output_file = pathlib.Path(output_file_str)

    # eg. /Users/malcolm/dev/universityofprofessorex/ffmpeg-tools/data/fixtures/00000-gif1-farming.mp4
    full_path_output_file = f"{output_file.absolute()}"

    return output_file_str, output_file, full_path_output_file


async def setup(cerebro: Cerebro) -> None:
    await cerebro.add_cog(Upscale(cerebro))

</document_content>
</document>
<document index="17">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/cogs/utility.py</source>
<document_content>
"""cerebro_bot.cogs.utility"""
from datetime import datetime
import logging
import sys
import time

import discord
from discord.ext import commands

# from cerebro_bot import utils
from cerebro_bot.aio_settings import aiosettings
from cerebro_bot.bot_logger import get_logger

# noqa: E402

PY_VERSION = f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
LOGGER = get_logger(__name__, provider="Utility", level=logging.DEBUG)

# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/133702ceb8682ec3927530ac35ad28d47a42802e/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/cogs/settings.py


def execute(tn, command, pattern=b">>>"):
    tn.write(command.encode("utf-8"))
    data = tn.read_until(pattern, 100)
    return data.decode("utf-8")


class Utility(commands.Cog):
    def __init__(self, cerebro):
        self.bot = cerebro
        self.start_time = datetime.now().replace(microsecond=0)

    @commands.Cog.listener()
    async def on_ready(self):
        print(f"{type(self).__name__} Cog ready.")

    @commands.command()
    async def ping(self, ctx):
        """*Current ping and latency of the bot*
        **Example**: `{prefix}ping`"""
        embed = discord.Embed(description="Test Ping.")
        before_time = time.time()
        msg = await ctx.send(embed=embed)
        latency = round(self.bot.latency * 1000)
        elapsed_ms = round((time.time() - before_time) * 1000) - latency
        embed.add_field(name="ping", value=f"{elapsed_ms}ms")
        embed.add_field(name="latency", value=f"{latency}ms")
        await msg.edit(embed=embed)

    @commands.command()
    async def uptime(self, ctx):
        """*Current uptime of the bot*
        **Example**: `{prefix}uptime`"""
        current_time = datetime.now().replace(microsecond=0)
        embed = discord.Embed(description=f"Time since I went online: {current_time - self.start_time}.")
        await ctx.send(embed=embed)

    @commands.command()
    async def starttime(self, ctx):
        """*When the bot was started*
        **Example**: `{prefix}starttime`"""
        embed = discord.Embed(description=f"I'm up since {self.start_time}.")
        await ctx.send(embed=embed)

    @commands.command()
    async def info(self, ctx):
        """*Shows stats and infos about the bot*
        **Example**: `{prefix}info`"""
        embed = discord.Embed(title="Cerebro", description="Info.")
        # embed.url = f"https://top.gg/bot/{self.bot.user.id}"
        embed.set_thumbnail(url=self.bot.user.avatar_url)
        embed.add_field(
            name="Bot Stats",
            value=f"```py\n"
            f"Guilds: {len(self.bot.guilds)}\n"
            f"Users: {len(self.bot.users)}\n"
            f"Shards: {self.bot.shard_count}\n"
            f"Shard ID: {ctx.guild.shard_id}```",
            inline=False,
        )
        embed.add_field(
            name="Server Configuration",
            value=f"```\n" f"Prefix: {aiosettings.prefix}\n" f"```",
            inline=False,
        )
        embed.add_field(
            name="Software Versions",
            value=f"```py\n"
            f"Cerebro: {self.bot.version}\n"
            f"discord.py: {discord.__version__}\n"
            f"Python: {PY_VERSION}```",
            inline=False,
        )
        embed.add_field(
            name="Links",
            value=f"[Invite]({self.bot.invite})",
            inline=False,
        )
        embed.set_footer(text="Thank you for using Cerebro <3", icon_url=self.bot.user.avatar_url)
        await ctx.send(embed=embed)

    @commands.command(aliases=["socials", "links", "support"])
    async def invite(self, ctx):
        """*Shows invite link and other socials for the bot*
        **Aliases**: `socials`, `links`, `support`
        **Example**: `{prefix}invite`"""
        embed = discord.Embed(description="Invite.")
        embed.description = f"[Invite]({self.bot.invite})"
        embed.set_footer(text="Thank you for using Cerebro <3", icon_url=self.bot.user.avatar_url)
        await ctx.send(embed=embed)


async def setup(cerebro):
    await cerebro.add_cog(Utility(cerebro))

</document_content>
</document>
<document index="18">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/cogs/youtube.py</source>
<document_content>
import asyncio
import logging
import os
import pathlib
import sys
import tempfile
import traceback
from typing import Optional

import aiohttp
from codetiming import Timer
import discord
from discord.ext import commands
from discord.message import Message
from discord.user import User
import rich
import uritools

from cerebro_bot import constants, shell
from cerebro_bot.bot_logger import get_logger
from cerebro_bot.factories import cmd_factory, guild_factory
from cerebro_bot.utils import aiodbx, events
from cerebro_bot.utils.file_functions import glob_file_by_extension

DISCORD_GUILD = os.environ.get("DISCORD_SERVER_ID")

LOGGER = get_logger(__name__, provider="Youtube", level=logging.DEBUG)

DL_SAFE_COMMAND = """

yt-dlp -v -f best -n --ignore-errors --restrict-filenames --write-thumbnail --embed-thumbnail --no-mtime --recode-video mp4 --cookies=~/Downloads/yt-cookies.txt --write-info-json {dl_uri}

# _RETVAL=$?

if [ "$?" != "0" ]; then
        echo \"Trying yt-best instead\"

        yt-dlp -v -f "bestvideo[ext=mp4]+bestaudio[ext=m4a]/bestvideo+bestaudio" -n --ignore-errors --restrict-filenames --write-thumbnail --embed-thumbnail --no-mtime --recode-video mp4 --cookies=~/Downloads/yt-cookies.txt --write-info-json {dl_uri}

        # _RETVAL=$?

        if [ "$?" != "0" ]; then
                echo "Trying yt-dlp instead"
                yt-dlp --write-info-json {dl_uri}
        fi
fi
"""

DL_CLIP_COMMAND = """
yt-dlp -v -f '(bestvideo[ext=mp4]+bestaudio[ext=m4a]/bestvideo+bestaudio)' --ignore-errors --restrict-filenames --write-thumbnail --embed-thumbnail --no-mtime --recode-video mp4 --cookies=~/Downloads/yt-cookies.txt --external-downloader ffmpeg --external-downloader-args "ffmpeg_i:-ss 00:{start_mm_ss}.00 -to 00:{end_mm_ss}.00" --write-info-json {dl_uri}
"""

FB_SAFE_COMMAND = """

yt-dlp -v -f best --ignore-errors --restrict-filenames --write-thumbnail --embed-thumbnail --no-mtime --recode-video mp4 --cookies=~/Downloads/yt-cookies.txt --write-info-json {dl_uri}

# _RETVAL=$?

if [ "$?" != "0" ]; then
        echo \"Trying yt-best instead\"

        yt-dlp -v -f "bestvideo[ext=mp4]+bestaudio[ext=m4a]/bestvideo+bestaudio" --ignore-errors --restrict-filenames --write-thumbnail --embed-thumbnail --no-mtime --recode-video mp4 --cookies=~/Downloads/yt-cookies.txt --write-info-json {dl_uri}

        # _RETVAL=$?

        if [ "$?" != "0" ]; then
                echo "Trying yt-dlp instead"
                yt-dlp --write-info-json {dl_uri}
        fi
fi
"""

# python3


async def expandURL(link: str):
    async with aiohttp.ClientSession() as session:
        async with session.head(link) as response:
            expanded = await response.getheader("location")
    # conn = http.client.HTTPSConnection('bit.ly')  # use HTTPS !
    # conn.request('HEAD', '/foobar')
    # response = conn.getresponse()
    return expanded


# SOURCE: https://www.programcreek.com/python/?project_name=athphane%2Fuserbot#
async def expand_url(url: str):
    async with aiohttp.ClientSession() as session:
        async with session.get(f"http://expandurl.com/api/v1/?url={url}") as resp:
            expanded = await resp.text()

        return expanded if expanded != "false" and expanded[:-1] != url else None


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/133702ceb8682ec3927530ac35ad28d47a42802e/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/cogs/settings.py
class Youtube(commands.Cog):
    def __init__(self, cerebro):
        self.bot = cerebro

    @commands.Cog.listener()
    async def on_ready(self):
        print(f"{type(self).__name__} Cog ready.")

    @commands.Cog.listener()
    async def on_guild_join(self, guild):
        """Add new guilds to the database"""
        _ = await guild_factory.Guild(id=guild.id)

    # $dl_safe https://www.reddit.com/r/TikTok_Ass/comments/r352rg/hit_it_for_me_one_time/
    # @commands.command()
    @commands.command(aliases=["safe", "yts", "s", "yt", "y", "youtube"])
    async def dl_safe(self, ctx, uri: str = None):
        """*Use youtube_dl to download video with thumbnail dl_safe*
        **Example**: `{dl_safe}dl_safe !`
        """
        # rich.inspect(ctx, methods=True)

        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, uri = {uri}")
        # LOGGER.info(f"{type(self).__name__} -> ctx = {debugger.rich_inspect(ctx)}")

        # DMChannel

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user: Optional[User]
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        # DMChannel
        # ---------------------------------------------------------------
        dl_uri = uritools.urisplit(uri)

        expanded = False

        if dl_uri.authority == "fb.watch":
            expanded = await expand_url(f"{dl_uri.geturi()}")
            LOGGER.error(f"EXPANDED {expanded}")
            # pass

        if expanded:
            dl_uri = uritools.urisplit(expanded)

        cmd_args = ["dl_safe"]
        cmd_kargs = {
            "cmd": DL_SAFE_COMMAND.format(dl_uri=dl_uri.geturi()),
            "uri": f"{dl_uri.geturi()}",
        }

        # If downloading facebook, we use it without the login flags, cause it makes FB act funny
        if dl_uri.authority in ["fb.watch", "facebook"]:
            cmd_kargs = {
                "cmd": FB_SAFE_COMMAND.format(dl_uri=dl_uri.geturi()),
                "uri": f"{dl_uri.geturi()}",
            }

        cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

        LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

        await ctx.send(
            embed=discord.Embed(description=f"Downloading {cmd_metadata.uri} ...."),
            delete_after=25.0,
        )

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                await ctx.send(
                    embed=discord.Embed(description="Beginning download ...."),
                    delete_after=25.0,
                )

                try:
                    await asyncio.gather(
                        asyncio.create_task(
                            shell.run_coroutine_subprocess(
                                cmd=cmd_metadata.cmd,
                                uri=cmd_metadata.uri,
                                working_dir=f"{tmpdirname}",
                            )
                        ),
                    )

                    await ctx.send(
                        embed=discord.Embed(description=f"Success, downloaded {cmd_metadata.uri}"),
                        delete_after=25.0,
                    )

                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not upload to discord...."))

                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    tb_str = "".join(traceback.format_exception(etype=type(ex), value=ex, tb=ex.__traceback__))
                    await ctx.send(embed=discord.Embed(description=f"{tb_str}"))
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    await ctx.send(embed=discord.Embed(description=f"{output}"))
                    LOGGER.warning(output)
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                file_to_upload_list = glob_file_by_extension(f"{tmpdirname}", extension="*.mp4")

                rich.print(f"{file_to_upload_list}")
                rich.print(file_to_upload_list)

                file_to_upload = f"{file_to_upload_list[0]}"
                is_dropbox_upload = False

                LOGGER.debug(f"{type(self).__name__} -> file_to_upload = {file_to_upload}")

                await ctx.send(
                    f"{type(self).__name__} -> file_to_upload = {file_to_upload}",
                    delete_after=25.0,
                )

                rich.print(file_to_upload)

                await ctx.send(
                    embed=discord.Embed(description=f"Uploading to discord -> {file_to_upload}...."),
                    delete_after=25.0,
                )

                ############################################################################
                # NOTE: This is the new functionality to turn all this code into a function
                ############################################################################
                # is_greater_than_max_upload_size, msg_size = check_file_size(file_to_upload)
                # msg_fsize_check = await ctx.send(
                #     embed=discord.Embed(
                #         description=msg_size
                #     )
                # )
                # await msg_fsize_check.delete()

                # if is_greater_than_max_upload_size:

                if pathlib.Path(file_to_upload).stat().st_size > constants.MAX_BYTES_UPLOAD_DISCORD:
                    await ctx.send(
                        embed=discord.Embed(
                            description=f"File is over 8MB... Uploading to dropbox -> {file_to_upload}...."
                        ),
                        delete_after=25.0,
                    )

                    to_upload_list = [file_to_upload]
                    try:
                        await aiodbx.dropbox_upload(to_upload_list)

                        is_dropbox_upload = True

                        await ctx.send(
                            embed=discord.Embed(
                                description=f"File successfully uploaded to dropbox! -> {file_to_upload}...."
                            )
                        )
                    except Exception as ex:
                        await ctx.send(embed=discord.Embed(description="Could not upload to discord...."))

                        print(ex)
                        exc_type, exc_value, exc_traceback = sys.exc_info()
                        tb_str = "".join(traceback.format_exception(etype=type(ex), value=ex, tb=ex.__traceback__))
                        await ctx.send(embed=discord.Embed(description=f"{tb_str}"))
                        LOGGER.error(f"Error Class: {str(ex.__class__)}")
                        output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                        await ctx.send(embed=discord.Embed(description=f"{output}"))
                        LOGGER.warning(output)
                        LOGGER.error(f"exc_type: {exc_type}")
                        LOGGER.error(f"exc_value: {exc_value}")
                        traceback.print_tb(exc_traceback)

                else:
                    my_files = [discord.File(f"{file_to_upload}")]
                    await ctx.send(
                        embed=discord.Embed(description=f"Uploading to discord -> {my_files}...."),
                        delete_after=25.0,
                    )

                    try:
                        msg: Message
                        msg = await ctx.message.channel.send(
                            f"{ctx.message.author.mention}, Here are your images.",
                            files=my_files,
                        )
                        # await ctx.send(file=discord.File(f"{file_to_upload}"))
                        # await msg_upload.delete()
                        # await msg.pin()
                    except Exception as ex:
                        await ctx.send(embed=discord.Embed(description="Could not upload to discord...."))

                        print(ex)
                        exc_type, exc_value, exc_traceback = sys.exc_info()
                        tb_str = "".join(traceback.format_exception(etype=type(ex), value=ex, tb=ex.__traceback__))
                        await ctx.send(embed=discord.Embed(description=f"{tb_str}"))
                        LOGGER.error(f"Error Class: {str(ex.__class__)}")
                        output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                        await ctx.send(embed=discord.Embed(description=f"{output}"))
                        LOGGER.warning(output)
                        LOGGER.error(f"exc_type: {exc_type}")
                        LOGGER.error(f"exc_value: {exc_value}")
                        traceback.print_tb(exc_traceback)

                await ctx.send(
                    embed=discord.Embed(description=f"File successfully uploaded -> {my_files}...."),
                    delete_after=60.0,
                )

                await events.aio_download_event(ctx, f"{tmpdirname}", cmd_metadata, is_dropbox_upload)
                # #######################################################
                # # add event to system channel
                # #######################################################
                # json_file_list = glob_file_by_extension(
                #     f"{tmpdirname}", extension="*.json"
                # )

                # json_file = f"{json_file_list[0]}"
                # LOGGER.debug(f"json_file = {json_file}")
                # print(f"json_file = {json_file}")

                # try:

                #     json_data = await run_aio_json_loads(json_file)
                #     # json_data = await aio_read_jsonfile(json_file)
                #     # json_data = json.loads(
                #     #     await (await aiofiles.open(json_file, mode='r')).read())
                #     # print(
                #     #     "***********************json_data**********************************"
                #     # )
                #     # rich.print(json_data)
                #     # rich.print(json_data)
                # except Exception as ex:
                #     await ctx.send(
                #         embed=discord.Embed(
                #             description=f"Could not open json metadata file"
                #         )
                #     )
                #     print(str(ex))
                #     exc_type, exc_value, exc_traceback = sys.exc_info()
                #     LOGGER.error("Error Class: {}".format(str(ex.__class__)))
                #     output = "[{}] {}: {}".format("UNEXPECTED", type(ex).__name__, ex)
                #     await ctx.send(embed=discord.Embed(description=f"{output}"))
                #     LOGGER.warning(output)
                #     LOGGER.error("exc_type: {}".format(exc_type))
                #     LOGGER.error("exc_value: {}".format(exc_value))
                #     traceback.print_tb(exc_traceback)

                # try:
                #     # 1. Get guild
                #     # ctx.guild.id
                #     # = await guild_factory.Guild(id=guild.id)
                #     current_message: discord.Message
                #     current_message = ctx.message
                #     current_channel: discord.TextChannel
                #     current_channel = ctx.channel
                #     current_guild: discord.Guild
                #     current_guild = current_channel.guild
                #     ##########################################
                #     full_description = json_data["description"]
                #     description = (full_description[:75] + '..') if len(full_description) > 75 else full_description
                #     embed_event = discord.Embed(
                #         title=f"Downloaded: '{json_data['fulltitle']}' in channel #{current_channel.name}",
                #         url=f"{current_message.jump_url}",
                #         description=f"{description}",
                #         color=discord.Color.blue(),
                #     )
                #     # set author
                #     embed_event.set_author(
                #         name=json_data["channel"],
                #         url=json_data["uploader_url"],
                #         icon_url=json_data["thumbnail"],
                #     )

                #     # set thumbnail
                #     embed_event.set_thumbnail(url=json_data["thumbnail"])
                #     embed_event.set_image(url=json_data["thumbnail"])

                #     embed_event.add_field(name="Url", value=f"{cmd_metadata.uri}", inline=False)
                #     # embed_event.set_footer(text=f"Jump to request: [{current_message.jump_url}]({current_message.jump_url})")
                #     ##########################################
                #     # rich.inspect(current_guild, methods=True)
                #     if current_guild.system_channel is not None:
                #         # to_send = 'Welcome {0.mention} to {1.name}!'.format(member, current_guild)
                #         await current_guild.system_channel.send(embed=embed_event)
                # except Exception as ex:
                #     await ctx.send(
                #         embed=discord.Embed(
                #             description=f"Could not send download event to general"
                #         )
                #     )
                #     print(str(ex))
                #     exc_type, exc_value, exc_traceback = sys.exc_info()
                #     LOGGER.error("Error Class: {}".format(str(ex.__class__)))
                #     output = "[{}] {}: {}".format("UNEXPECTED", type(ex).__name__, ex)
                #     await ctx.send(embed=discord.Embed(description=f"{output}"))
                #     LOGGER.warning(output)
                #     LOGGER.error("exc_type: {}".format(exc_type))
                #     LOGGER.error("exc_value: {}".format(exc_value))
                #     traceback.print_tb(exc_traceback)

    @dl_safe.error
    async def dl_safe_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(description="Sorry, you need `MANAGE SERVER` permissions to change the dl_safe!")
            )

    # @commands.has_permissions(manage_guild=True)
    # @commands.command()
    @commands.command(aliases=["dlyt", "thumb"])
    async def dl_thumb(self, ctx, uri: str = None):
        """*Use youtube_dl to download video with thumbnail dl_thumb*
        **Example**: `{dl_thumb}dl_thumb !`
        **Requires permission**: `MANAGER SERVER`
        """
        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, uri = {uri}")
        # LOGGER.info(f"{type(self).__name__} -> ctx = {debugger.rich_inspect(ctx)}")

        # DMChannel

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user: Optional[User]
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        # DMChannel
        # ---------------------------------------------------------------
        dl_uri = uritools.urisplit(uri)
        cmd_args = ["dl_thumb"]
        cmd_kargs = {
            "cmd": f"yt-dlp -v -f best -n --ignore-errors --restrict-filenames --write-thumbnail --no-mtime --embed-thumbnail --recode-video mp4 --cookies=~/Downloads/yt-cookies.txt {dl_uri.geturi()}",
            "uri": f"{dl_uri.geturi()}",
        }

        cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

        LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

        await ctx.send(embed=discord.Embed(description=f"Downloading {cmd_metadata.uri} ...."))

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                await asyncio.gather(
                    asyncio.create_task(
                        shell.run_coroutine_subprocess(
                            cmd=cmd_metadata.cmd,
                            uri=cmd_metadata.uri,
                            working_dir=f"{tmpdirname}",
                        )
                    ),
                )
                await ctx.send(embed=discord.Embed(description=f"Success, downloaded {cmd_metadata.uri}"))
                file_to_upload_list = glob_file_by_extension(f"{tmpdirname}", extension="*.mp4")

                file_to_upload = f"{file_to_upload_list[0]}"

                if pathlib.Path(file_to_upload).stat().st_size > constants.MAX_BYTES_UPLOAD_DISCORD:
                    await ctx.send(
                        embed=discord.Embed(
                            description=f"File is over 8MB... Uploading to dropbox -> {file_to_upload}...."
                        )
                    )

                    await aiodbx.dropbox_upload(file_to_upload_list)

                    await ctx.send(
                        embed=discord.Embed(
                            description=f"File successfully uploaded to dropbox! -> {file_to_upload}...."
                        )
                    )

                else:
                    await ctx.send(embed=discord.Embed(description=f"Uploading to discord -> {file_to_upload}...."))

                    msg: Message

                    msg = await recipient_user.send(file=discord.File(f"{file_to_upload}"))
                    # await msg.pin()

                    await ctx.send(
                        embed=discord.Embed(description=f"File successfully uploaded -> {file_to_upload}....")
                    )

    @dl_thumb.error
    async def dl_thumb_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(description="Sorry, you need `MANAGE SERVER` permissions to change the dl_thumb!")
            )

    @commands.command(aliases=["c", "clip", "ytc"])
    async def dl_clip(self, ctx, uri: str = None, start_mm_ss="00:00", end_mm_ss="00:30"):
        """*Use yt-dlp to download video with thumbnail dl_clip*
        **Example**: `{dl_clip}dl_clip !`
        """
        LOGGER.info(f"{type(self).__name__} -> ctx = {ctx}, uri = {uri}")

        if isinstance(ctx.channel, discord.DMChannel):
            LOGGER.debug(f"{type(self).__name__} -> recieved via DM")
            recipient_user: Optional[User]
            recipient_user = ctx.channel.recipient
            LOGGER.debug(f"{type(self).__name__} -> recipient_user = {recipient_user}")
            LOGGER.debug(f"{type(self).__name__} -> type(recipient_user) = {type(recipient_user)}")

        # DMChannel
        # ---------------------------------------------------------------
        dl_uri = uritools.urisplit(uri)

        cmd_args = ["dl_clip"]
        cmd_kargs = {
            "cmd": DL_CLIP_COMMAND.format(dl_uri=dl_uri.geturi(), start_mm_ss=start_mm_ss, end_mm_ss=end_mm_ss),
            "uri": f"{dl_uri.geturi()}",
        }

        cmd_metadata = cmd_factory.CmdSerializer(*cmd_args, **cmd_kargs)

        LOGGER.debug(f"{type(self).__name__} -> cmd_metadata = {cmd_metadata}")

        await ctx.send(
            embed=discord.Embed(description=f"Downloading {cmd_metadata.uri} ...."),
            delete_after=25.0,
        )

        with tempfile.TemporaryDirectory() as tmpdirname:
            print("created temporary directory", tmpdirname)
            with Timer(text="\nTotal elapsed time: {:.1f}"):
                try:
                    await asyncio.gather(
                        asyncio.create_task(
                            shell.run_coroutine_subprocess(
                                cmd=cmd_metadata.cmd,
                                uri=cmd_metadata.uri,
                                working_dir=f"{tmpdirname}",
                            )
                        ),
                    )

                except Exception as ex:
                    await ctx.send(embed=discord.Embed(description="Could not upload to discord...."))
                    print(ex)
                    exc_type, exc_value, exc_traceback = sys.exc_info()
                    LOGGER.error(f"Error Class: {str(ex.__class__)}")
                    output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                    await ctx.send(embed=discord.Embed(description=f"{output}"))
                    LOGGER.warning(output)
                    LOGGER.error(f"exc_type: {exc_type}")
                    LOGGER.error(f"exc_value: {exc_value}")
                    traceback.print_tb(exc_traceback)

                await ctx.send(
                    embed=discord.Embed(description=f"Success, downloaded {cmd_metadata.uri}"),
                    delete_after=25.0,
                )

                file_to_upload_list = glob_file_by_extension(f"{tmpdirname}", extension="*.mp4")

                file_to_upload = f"{file_to_upload_list[0]}"

                is_dropbox_upload = False

                if pathlib.Path(file_to_upload).stat().st_size > constants.MAX_BYTES_UPLOAD_DISCORD:
                    msg_upload = await ctx.send(
                        embed=discord.Embed(
                            description=f"File is over 8MB... Uploading to dropbox -> {file_to_upload}...."
                        )
                    )

                    is_dropbox_upload = True

                    await msg_upload.delete()

                    await aiodbx.dropbox_upload(file_to_upload_list)

                    await ctx.send(
                        embed=discord.Embed(
                            description=f"File successfully uploaded to dropbox! -> {file_to_upload}...."
                        )
                    )

                else:
                    msg_upload = await ctx.send(
                        embed=discord.Embed(description=f"Uploading to discord -> {file_to_upload}....")
                    )

                    msg: Message
                    msg = await ctx.send(file=discord.File(f"{file_to_upload}"))
                    await msg_upload.delete()

                await events.aio_download_event(ctx, f"{tmpdirname}", cmd_metadata, is_dropbox_upload)

    @dl_clip.error
    async def dl_clip_error_handler(self, ctx, error):
        if isinstance(error, commands.MissingPermissions):
            await ctx.send(
                embed=discord.Embed(description="Sorry, you need `MANAGE SERVER` permissions to change the dl_clip!")
            )


async def setup(cerebro) -> None:
    await cerebro.add_cog(Youtube(cerebro))

</document_content>
</document>
<document index="19">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/__init__.py</source>
<document_content>
"""cerebro_bot.utils"""
# NOTE: Via Red https://github.com/Cog-Creators/Red-DiscordBot/tree/V3/develop/redbot
from __future__ import annotations

import asyncio
from asyncio import Semaphore, as_completed
from asyncio.futures import isfuture
from itertools import chain
import json
import logging
from pathlib import Path
from typing import (
    Any,
    AsyncIterable,
    AsyncIterator,
    Awaitable,
    Callable,
    Coroutine,
    Generator,
    Iterable,
    Iterator,
    List,
    Optional,
    Tuple,
    TypeVar,
    Union,
)

from discord.utils import maybe_coroutine

from cerebro_bot import constants
from cerebro_bot.aio_settings import aiosettings
from cerebro_bot.bot_logger import get_logger

LOGGER = get_logger("cerebro_bot.utils", provider="Utils", level=logging.DEBUG)

_T = TypeVar("_T")
_S = TypeVar("_S")


def deduplicate_iterables(*iterables):
    """
    Returns a list of all unique items in ``iterables``, in the order they
    were first encountered.
    """
    # dict insertion order is guaranteed to be preserved in 3.6+
    return list(dict.fromkeys(chain.from_iterable(iterables)))


# https://github.com/PyCQA/pylint/issues/2717
class AsyncFilter(AsyncIterator[_T], Awaitable[List[_T]]):  # pylint: disable=duplicate-bases
    """Class returned by `async_filter`. See that function for details.

    We don't recommend instantiating this class directly.
    """

    def __init__(
        self,
        func: Callable[[_T], Union[bool, Awaitable[bool]]],
        iterable: Union[AsyncIterable[_T], Iterable[_T]],
    ) -> None:
        self.__func: Callable[[_T], Union[bool, Awaitable[bool]]] = func
        self.__iterable: Union[AsyncIterable[_T], Iterable[_T]] = iterable

        # We assign the generator strategy based on the arguments' types
        if isinstance(iterable, AsyncIterable):
            if asyncio.iscoroutinefunction(func):
                self.__generator_instance = self.__async_generator_async_pred()
            else:
                self.__generator_instance = self.__async_generator_sync_pred()
        elif asyncio.iscoroutinefunction(func):
            self.__generator_instance = self.__sync_generator_async_pred()
        else:
            raise TypeError("Must be either an async predicate, an async iterable, or both.")

    async def __sync_generator_async_pred(self) -> AsyncIterator[_T]:
        for item in self.__iterable:
            if await self.__func(item):
                yield item

    async def __async_generator_sync_pred(self) -> AsyncIterator[_T]:
        async for item in self.__iterable:
            if self.__func(item):
                yield item

    async def __async_generator_async_pred(self) -> AsyncIterator[_T]:
        async for item in self.__iterable:
            if await self.__func(item):
                yield item

    async def __flatten(self) -> List[_T]:
        return [item async for item in self]

    def __aiter__(self):
        return self

    def __await__(self):
        # Simply return the generator filled into a list
        return self.__flatten().__await__()

    def __anext__(self) -> Awaitable[_T]:
        # This will use the generator strategy set in __init__
        return self.__generator_instance.__anext__()


def async_filter(
    func: Callable[[_T], Union[bool, Awaitable[bool]]],
    iterable: Union[AsyncIterable[_T], Iterable[_T]],
) -> AsyncFilter[_T]:
    """Filter an (optionally async) iterable with an (optionally async) predicate.

    At least one of the arguments must be async.

    Parameters
    ----------
    func : Callable[[T], Union[bool, Awaitable[bool]]]
        A function or coroutine function which takes one item of ``iterable``
        as an argument, and returns ``True`` or ``False``.
    iterable : Union[AsyncIterable[_T], Iterable[_T]]
        An iterable or async iterable which is to be filtered.

    Raises
    ------
    TypeError
        If neither of the arguments are async.

    Returns
    -------
    AsyncFilter[T]
        An object which can either be awaited to yield a list of the filtered
        items, or can also act as an async iterator to yield items one by one.

    """
    return AsyncFilter(func, iterable)


async def async_enumerate(async_iterable: AsyncIterable[_T], start: int = 0) -> AsyncIterator[Tuple[int, _T]]:
    """Async iterable version of `enumerate`.

    Parameters
    ----------
    async_iterable : AsyncIterable[T]
        The iterable to enumerate.
    start : int
        The index to start from. Defaults to 0.

    Returns
    -------
    AsyncIterator[Tuple[int, T]]
        An async iterator of tuples in the form of ``(index, item)``.

    """
    async for item in async_iterable:
        yield start, item
        start += 1


async def _sem_wrapper(sem, task):
    async with sem:
        return await task


def bounded_gather_iter(
    *coros_or_futures, limit: int = 4, semaphore: Optional[Semaphore] = None
) -> Iterator[Awaitable[Any]]:
    """
    An iterator that returns tasks as they are ready, but limits the
    number of tasks running at a time.

    Parameters
    ----------
    *coros_or_futures
        The awaitables to run in a bounded concurrent fashion.
    limit : Optional[`int`]
        The maximum number of concurrent tasks. Used when no ``semaphore``
        is passed.
    semaphore : Optional[:class:`asyncio.Semaphore`]
        The semaphore to use for bounding tasks. If `None`, create one
        using ``loop`` and ``limit``.

    Raises
    ------
    TypeError
        When invalid parameters are passed
    """
    loop = asyncio.get_running_loop()

    if semaphore is None:
        if not isinstance(limit, int) or limit <= 0:
            raise TypeError("limit must be an int > 0")

        semaphore = Semaphore(limit)

    pending = []

    for cof in coros_or_futures:
        if isfuture(cof) and cof._loop is not loop:
            raise ValueError("futures are tied to different event loops")

        cof = _sem_wrapper(semaphore, cof)
        pending.append(cof)

    return as_completed(pending)


def bounded_gather(
    *coros_or_futures,
    return_exceptions: bool = False,
    limit: int = 4,
    semaphore: Optional[Semaphore] = None,
) -> Awaitable[List[Any]]:
    """
    A semaphore-bounded wrapper to :meth:`asyncio.gather`.

    Parameters
    ----------
    *coros_or_futures
        The awaitables to run in a bounded concurrent fashion.
    return_exceptions : bool
        If true, gather exceptions in the result list instead of raising.
    limit : Optional[`int`]
        The maximum number of concurrent tasks. Used when no ``semaphore``
        is passed.
    semaphore : Optional[:class:`asyncio.Semaphore`]
        The semaphore to use for bounding tasks. If `None`, create one
        using ``loop`` and ``limit``.

    Raises
    ------
    TypeError
        When invalid parameters are passed
    """
    loop = asyncio.get_running_loop()

    if semaphore is None:
        if not isinstance(limit, int) or limit <= 0:
            raise TypeError("limit must be an int > 0")

        semaphore = Semaphore(limit)

    tasks = (_sem_wrapper(semaphore, task) for task in coros_or_futures)

    return asyncio.gather(*tasks, return_exceptions=return_exceptions)


class AsyncIter(AsyncIterator[_T], Awaitable[List[_T]]):  # pylint: disable=duplicate-bases
    """Asynchronous iterator yielding items from ``iterable``
    that sleeps for ``delay`` seconds every ``steps`` items.

    Parameters
    ----------
    iterable: Iterable
        The iterable to make async.
    delay: Union[float, int]
        The amount of time in seconds to sleep.
    steps: int
        The number of iterations between sleeps.

    Raises
    ------
    ValueError
        When ``steps`` is lower than 1.

    Examples
    --------
    >>> from redbot.core.utils import AsyncIter
    >>> async for value in AsyncIter(range(3)):
    ...     print(value)
    0
    1
    2

    """

    def __init__(self, iterable: Iterable[_T], delay: Union[float, int] = 0, steps: int = 1) -> None:
        if steps < 1:
            raise ValueError("Steps must be higher than or equals to 1")
        self._delay = delay
        self._iterator = iter(iterable)
        self._i = 0
        self._steps = steps
        self._map = None

    def __aiter__(self) -> AsyncIter[_T]:
        return self

    async def __anext__(self) -> _T:
        try:
            item = next(self._iterator)
        except StopIteration as e:
            raise StopAsyncIteration from e
        if self._i == self._steps:
            self._i = 0
            await asyncio.sleep(self._delay)
        self._i += 1
        return await maybe_coroutine(self._map, item) if self._map is not None else item

    def __await__(self) -> Generator[Any, None, List[_T]]:
        """Returns a list of the iterable.

        Examples
        --------
        >>> from redbot.core.utils import AsyncIter
        >>> iterator = AsyncIter(range(5))
        >>> await iterator
        [0, 1, 2, 3, 4]

        """
        return self.flatten().__await__()

    async def next(self, default: Any = ...) -> _T:
        """Returns a next entry of the iterable.

        Parameters
        ----------
        default: Optional[Any]
            The value to return if the iterator is exhausted.

        Raises
        ------
        StopAsyncIteration
            When ``default`` is not specified and the iterator has been exhausted.

        Examples
        --------
        >>> from redbot.core.utils import AsyncIter
        >>> iterator = AsyncIter(range(5))
        >>> await iterator.next()
        0
        >>> await iterator.next()
        1

        """
        try:
            value = await self.__anext__()
        except StopAsyncIteration:
            if default is ...:
                raise
            value = default
        return value

    async def flatten(self) -> List[_T]:
        """Returns a list of the iterable.

        Examples
        --------
        >>> from redbot.core.utils import AsyncIter
        >>> iterator = AsyncIter(range(5))
        >>> await iterator.flatten()
        [0, 1, 2, 3, 4]

        """
        return [item async for item in self]

    def filter(self, function: Callable[[_T], Union[bool, Awaitable[bool]]]) -> AsyncFilter[_T]:
        """Filter the iterable with an (optionally async) predicate.

        Parameters
        ----------
        function: Callable[[T], Union[bool, Awaitable[bool]]]
            A function or coroutine function which takes one item of ``iterable``
            as an argument, and returns ``True`` or ``False``.

        Returns
        -------
        AsyncFilter[T]
            An object which can either be awaited to yield a list of the filtered
            items, or can also act as an async iterator to yield items one by one.

        Examples
        --------
        >>> from redbot.core.utils import AsyncIter
        >>> def predicate(value):
        ...     return value <= 5
        >>> iterator = AsyncIter([1, 10, 5, 100])
        >>> async for i in iterator.filter(predicate):
        ...     print(i)
        1
        5

        >>> from redbot.core.utils import AsyncIter
        >>> def predicate(value):
        ...     return value <= 5
        >>> iterator = AsyncIter([1, 10, 5, 100])
        >>> await iterator.filter(predicate)
        [1, 5]

        """
        return async_filter(function, self)

    def enumerate(self, start: int = 0) -> AsyncIterator[Tuple[int, _T]]:
        """Async iterable version of `enumerate`.

        Parameters
        ----------
        start: int
            The index to start from. Defaults to 0.

        Returns
        -------
        AsyncIterator[Tuple[int, T]]
            An async iterator of tuples in the form of ``(index, item)``.

        Examples
        --------
        >>> from redbot.core.utils import AsyncIter
        >>> iterator = AsyncIter(['one', 'two', 'three'])
        >>> async for i in iterator.enumerate(start=10):
        ...     print(i)
        (10, 'one')
        (11, 'two')
        (12, 'three')

        """
        return async_enumerate(self, start)

    async def without_duplicates(self) -> AsyncIterator[_T]:
        """
        Iterates while omitting duplicated entries.

        Examples
        --------
        >>> from redbot.core.utils import AsyncIter
        >>> iterator = AsyncIter([1,2,3,3,4,4,5])
        >>> async for i in iterator.without_duplicates():
        ...     print(i)
        1
        2
        3
        4
        5

        """
        _temp = set()
        async for item in self:
            if item not in _temp:
                yield item
                _temp.add(item)
        del _temp

    async def find(
        self,
        predicate: Callable[[_T], Union[bool, Awaitable[bool]]],
        default: Optional[Any] = None,
    ) -> AsyncIterator[_T]:
        """Calls ``predicate`` over items in iterable and return first value to match.

        Parameters
        ----------
        predicate: Union[Callable, Coroutine]
            A function that returns a boolean-like result. The predicate provided can be a coroutine.
        default: Optional[Any]
            The value to return if there are no matches.

        Raises
        ------
        TypeError
            When ``predicate`` is not a callable.

        Examples
        --------
        >>> from redbot.core.utils import AsyncIter
        >>> await AsyncIter(range(3)).find(lambda x: x == 1)
        1
        """
        while True:
            try:
                elem = await self.__anext__()
            except StopAsyncIteration:
                return default
            ret = await maybe_coroutine(predicate, elem)
            if ret:
                return elem

    def map(self, func: Callable[[_T], Union[_S, Awaitable[_S]]]) -> AsyncIter[_S]:
        """Set the mapping callable for this instance of `AsyncIter`.

        .. important::
            This should be called after AsyncIter initialization and before any other of its methods.

        Parameters
        ----------
        func: Union[Callable, Coroutine]
            The function to map values to. The function provided can be a coroutine.

        Raises
        ------
        TypeError
            When ``func`` is not a callable.

        Examples
        --------
        >>> from redbot.core.utils import AsyncIter
        >>> async for value in AsyncIter(range(3)).map(bool):
        ...     print(value)
        False
        True
        True

        """

        if not callable(func):
            raise TypeError("Mapping must be a callable.")
        self._map = func
        return self


def get_end_user_data_statement(file: Union[Path, str]) -> Optional[str]:
    """
    This function attempts to get the ``end_user_data_statement`` key from cog's ``info.json``.
    This will log the reason if ``None`` is returned.

    Parameters
    ----------
    file: Union[pathlib.Path, str]
        The ``__file__`` variable for the cog's ``__init__.py`` file.

    Returns
    -------
    Optional[str]
        The end user data statement found in the info.json
        or ``None`` if there was an issue finding one.

    Examples
    --------
    >>> # In cog's `__init__.py`
    >>> from redbot.core.utils import get_end_user_data_statement
    >>> __red_end_user_data_statement__  = get_end_user_data_statement(__file__)
    >>> def setup(bot):
    ...     ...
    """
    try:
        file = Path(file).parent.absolute()
        info_json = file / "info.json"
        statement = get_end_user_data_statement_or_raise(info_json)
    except FileNotFoundError:
        LOGGER.critical("'%s' does not exist.", str(info_json))
    except KeyError:
        LOGGER.critical("'%s' is missing an entry for 'end_user_data_statement'", str(info_json))
    except json.JSONDecodeError as exc:
        LOGGER.critical("'%s' is not a valid JSON file.", str(info_json), exc_info=exc)
    except UnicodeError as exc:
        LOGGER.critical("'%s' has a bad encoding.", str(info_json), exc_info=exc)
    except Exception as exc:
        LOGGER.critical(
            "There was an error when trying to load the end user data statement from '%s'.",
            str(info_json),
            exc_info=exc,
        )
    else:
        return statement
    return None


def get_end_user_data_statement_or_raise(file: Union[Path, str]) -> str:
    """
    This function attempts to get the ``end_user_data_statement`` key from cog's ``info.json``.

    Parameters
    ----------
    file: Union[pathlib.Path, str]
        The ``__file__`` variable for the cog's ``__init__.py`` file.

    Returns
    -------
    str
        The end user data statement found in the info.json.

    Raises
    ------
    FileNotFoundError
        When ``info.json`` does not exist.
    KeyError
        When ``info.json`` does not have the ``end_user_data_statement`` key.
    json.JSONDecodeError
        When ``info.json`` can't be decoded with ``json.load()``
    UnicodeError
        When ``info.json`` can't be decoded due to bad encoding.
    Exception
        Any other exception raised from ``pathlib`` and ``json`` modules
        when attempting to parse the ``info.json`` for the ``end_user_data_statement`` key.
    """
    file = Path(file).parent.absolute()
    info_json = file / "info.json"
    with info_json.open(encoding="utf-8") as fp:
        return json.load(fp)["end_user_data_statement"]


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/133702ceb8682ec3927530ac35ad28d47a42802e/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/utils/__init__.py
# config = Config()


# SOURCE: https://github.com/makupi/cookiecutter-discord.py-postgres/blob/master/%7B%7Bcookiecutter.bot_slug%7D%7D/bot/utils/__init__.py
def get_guild_prefix(_bot, guild_id):
    LOGGER.info(f"get_guild_prefix(_bot, guild_id) - > get_guild_prefix({_bot}, {guild_id})")
    prefix = aiosettings.prefix
    guild_data = _bot.guild_data.get(guild_id, None)
    if guild_data is not None:
        _prefix = guild_data.get("prefix")
        if _prefix is not None:
            prefix = _prefix

    LOGGER.info(f"inside get_guild_prefix(_bot, guild_id) - > get_guild_prefix({_bot}, {guild_id})")
    return prefix

</document_content>
</document>
<document index="20">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/aiodbx.py</source>
<document_content>
"""cerebro_bot.utils.aiodbx"""

# SOURCE: https://github.com/ebai101/aiodbx/blob/main/aiodbx.py
import asyncio
import base64
import json
import logging
import os
import pathlib
import sys
import traceback
import typing
from typing import List

import aiofiles
import aiohttp

from cerebro_bot.aio_settings import aiosettings
from cerebro_bot.bot_logger import get_logger

LOGGER = get_logger(__name__, provider="Dropbox", level=logging.DEBUG)

# TEMPCHANGE: # DROPBOX_CEREBRO_APP_KEY = os.environ.get("DROPBOX_CEREBRO_APP_KEY")
# TEMPCHANGE: # DROPBOX_CEREBRO_APP_SECRET = os.environ.get("DROPBOX_CEREBRO_APP_SECRET")
# TEMPCHANGE: #
# TEMPCHANGE: # DROPBOX_CEREBRO_TOKEN = os.environ.get("DROPBOX_CEREBRO_TOKEN")
# TEMPCHANGE: # DEFAULT_DROPBOX_FOLDER = "/cerebro_downloads"


class DropboxAPIError(Exception):
    """
    Exception for errors thrown by the API. Contains the HTTP status code and the returned error message.
    """

    def __init__(self, status: int, message: typing.Union[str, dict]):
        self.status = status
        self.message = message
        super().__init__(self.message)

    def __str__(self):
        if not isinstance(self.message, str):
            return f"{self.status} {self.message}"
        try:
            self.message = json.loads(self.message)
            return f'{self.status} {self.message["error_summary"]}'
        except Exception:
            return f"{self.status} {self.message}"


class Request:
    """
    Wrapper for a ClientResponse object that allows automatic retries for a certain list of statuses.

    request:
        session method to call that returns a ClientResponse (e.g. session.post)
    url:
        url to request
    log:
        logger to use for log messages (default is a null logger)
    ok_statuses:
        list of statuses that will return without an error (default is [200])
    retry_count:
        number of times that the request will be retried (default is 5)
    retry_statuses:
        list of statuses that will cause the request to be automatically retried (default is [429])
    **kwargs:
        Arbitrary keyword arguments, passed thru to the `request` Callable.
    """

    def __init__(
        self,
        request: typing.Callable[..., typing.Any],
        url: str,
        log: logging.Logger = LOGGER,
        ok_statuses: list[int] = None,
        retry_count: int = 5,
        retry_statuses: list[int] = None,
        **kwargs: typing.Any,
    ):
        if ok_statuses is None:
            ok_statuses = [200]
        if retry_statuses is None:
            retry_statuses = [429]
        self.request = request
        self.url = url
        self.log = log
        self.ok_statuses = ok_statuses
        self.retry_count = retry_count
        self.retry_statuses = retry_statuses
        self.kwargs = kwargs
        self.trace_request_ctx = kwargs.pop("trace_request_ctx", {})

        self.current_attempt = 0
        self.resp: typing.Optional[aiohttp.ClientResponse] = None

    async def _do_request(self) -> aiohttp.ClientResponse:
        """
        Performs a request. Automatically retries the request for specific return statuses.
        Should not be called directly. Instead, use an `async with` block with a Request object to manage the response context properly.

        Returns:
            aiohttp.ClientResponse: response returned from the `self.request` callable.

        Raises:
            DropboxAPIError: If the response status is >= 400 and if it is not in `self.ok_statuses`
        """

        self.current_attempt += 1
        if self.current_attempt > 1:
            self.log.debug(f"Attempt {self.current_attempt} out of {self.retry_count}")

        resp: aiohttp.ClientResponse = await self.request(
            self.url,
            **self.kwargs,
            trace_request_ctx={
                "current_attempt": self.current_attempt,
                **self.trace_request_ctx,
            },
        )

        if resp.status not in self.ok_statuses and resp.status >= 400:
            raise DropboxAPIError(resp.status, await resp.text())

        endpoint_name = self.url[self.url.index("2") + 1 :]
        self.log.debug(f"Request OK: {endpoint_name} returned {resp.status}")
        if self.current_attempt < self.retry_count and resp.status in self.retry_statuses:
            if "Retry-After" in resp.headers:
                sleep_time = int(resp.headers["Retry-After"])
            else:
                sleep_time = 1
            await asyncio.sleep(sleep_time)
            return await self._do_request()

        self.resp = resp
        return resp

    def __await__(self) -> typing.Generator[typing.Any, None, aiohttp.ClientResponse]:
        return self.__aenter__().__await__()

    async def __aenter__(self) -> aiohttp.ClientResponse:
        return await self._do_request()

    async def __aexit__(self, *excinfo) -> None:
        if self.resp is not None and not self.resp.closed:
            self.resp.close()


class AsyncDropboxAPI:
    """
    Dropbox API client using asynchronous HTTP requests.

    Args:
        token:
            a Dropbox API access token
        retry_statuses:
            list of statuses that will automatically be retried (default is [429])
        log:
            logger to use for log messages (default is a null logger)
    """

    def __init__(self, token: str, retry_statuses: list[int] = None, log: logging.Logger = None):
        if retry_statuses is None:
            retry_statuses = [429]
        self.token = token
        self.retry_statuses = retry_statuses
        self.client_session = aiohttp.ClientSession(connector=aiohttp.TCPConnector(limit_per_host=50))
        self.upload_session: list[dict] = []

        self.log = log or logging.getLogger("null")

    async def validate(self):
        """
        Validates the user authentication token.
        https://www.dropbox.com/developers/documentation/http/documentation#check-user

        Returns:
            bool:
                True if the API returns the same string (thus the token is valid)
        Raises:
            DropboxApiError:
                If the token is invalid
        """

        self.log.debug("Validating token")

        nonce = base64.b64encode(os.urandom(8), altchars=b"-_").decode("utf-8")
        url = "https://api.dropboxapi.com/2/check/user"
        headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json",
        }
        data = json.dumps({"query": nonce})

        async with Request(self.client_session.post, url, self.log, headers=headers, data=data) as resp:
            resp_data = await resp.json()
            if resp_data["result"] != nonce:
                raise DropboxAPIError(resp.status, "Token is invalid")
            self.log.debug("Token is valid")
            return True

    async def download_file(self, dropbox_path: str, local_path: str = None) -> str:
        """
        Downloads a single file.
        https://www.dropbox.com/developers/documentation/http/documentation#files-download

        Args:
            dropbox_path:
                File path on Dropbox to download from
            local_path:
                Path on the local disk to download to (defaults to None, which downloads to the current directory)
        Returns:
            str:
                `local_path` where the file was downloaded to
        """

        # default to current directory
        if local_path is None:
            local_path = os.path.basename(dropbox_path)

        self.log.info(f"Downloading {os.path.basename(local_path)}")
        self.log.debug(f"from {dropbox_path}")

        url = "https://content.dropboxapi.com/2/files/download"
        headers = {
            "Authorization": f"Bearer {self.token}",
            "Dropbox-API-Arg": json.dumps({"path": dropbox_path}),
        }

        async with Request(self.client_session.post, url, self.log, headers=headers) as resp:
            async with aiofiles.open(local_path, "wb") as f:
                async for chunk, _ in resp.content.iter_chunks():
                    await f.write(chunk)
                return local_path

    async def download_folder(self, dropbox_path: str, local_path: str = None) -> str:
        """
        Downloads a folder as a zip file.
        https://www.dropbox.com/developers/documentation/http/documentation#files-download_zip

        Args:
            dropbox_path:
                Folder path on Dropbox to download from
            local_path:
                Path on the local disk to download to (defaults to None, which downloads to the current directory)
        Returns:
            str:
                `local_path` where the zip file was downloaded to
        """

        # default to current directory
        if local_path is None:
            local_path = os.path.basename(dropbox_path)

        self.log.info(f"Downloading {os.path.basename(local_path)}")
        self.log.debug(f"from {dropbox_path}")

        url = "https://content.dropboxapi.com/2/files/download_zip"
        headers = {
            "Authorization": f"Bearer {self.token}",
            "Dropbox-API-Arg": json.dumps({"path": dropbox_path}),
        }

        async with Request(self.client_session.post, url, self.log, headers=headers) as resp:
            async with aiofiles.open(local_path, "wb") as f:
                async for chunk, _ in resp.content.iter_chunks():
                    await f.write(chunk)
                return local_path

    async def download_shared_link(self, shared_link: str, local_path: str = None) -> str:
        """
        Downloads a file from a shared link.
        https://www.dropbox.com/developers/documentation/http/documentation#sharing-get_shared_link_file

        Args:
            shared_link:
                Shared link to download from
            local_path:
                Path on the local disk to download to (defaults to None, which downloads to the current directory)
        Returns:
            str:
                `local_path` where the file was downloaded to
        """

        # default to current directory, with the path in the shared link
        if local_path is None:
            local_path = os.path.basename(shared_link[: shared_link.index("?")])

        self.log.info(f"Downloading {os.path.basename(local_path)}")
        self.log.debug(f"from {shared_link}")

        url = "https://content.dropboxapi.com/2/sharing/get_shared_link_file"
        headers = {
            "Authorization": f"Bearer {self.token}",
            "Dropbox-API-Arg": json.dumps({"url": shared_link}),
        }

        async with Request(self.client_session.post, url, self.log, headers=headers) as resp:
            async with aiofiles.open(local_path, "wb") as f:
                async for chunk, _ in resp.content.iter_chunks():
                    await f.write(chunk)
                return local_path

    async def upload_start(self, local_path: str, dropbox_path: str) -> dict:
        """
        Uploads a single file to an upload session. This should be used when uploading large quantities of files.
        https://www.dropbox.com/developers/documentation/http/documentation#files-upload_session-start

        Args:
            local_path:
                Local path to upload from.
            dropbox_path:
                Dropbox path to upload to.
        Returns:
            dict:
                UploadSessionFinishArg dict with information on the upload.
                This dict is automatically stored in `self.upload_session` to be committed later with `upload_finish`.
                It is returned here anyways so that the commit information can be used for other purposes.
        Raises:
            ValueError:
                If `local_path` does not exist.
            RuntimeError:
                If the current upload session is larger than 1000 files.
                To avoid this, call `upload_finish` regularly to split high quantity uploads into batches.
        """

        if not os.path.exists(local_path):
            raise ValueError(f"local_path {local_path} does not exist")
        if len(self.upload_session) >= 1000:
            raise RuntimeError("upload_session is too large, you must call upload_finish to commit the batch")

        self.log.info(f"Uploading {os.path.basename(local_path)}")
        self.log.debug(f"to {dropbox_path}")

        url = "https://content.dropboxapi.com/2/files/upload_session/start"
        headers = {
            "Authorization": f"Bearer {self.token}",
            "Dropbox-API-Arg": json.dumps({"close": True}),
            "Content-Type": "application/octet-stream",
        }

        async with aiofiles.open(local_path, "rb") as f:
            data = await f.read()
            async with Request(self.client_session.post, url, self.log, headers=headers, data=data) as resp:
                resp_data = await resp.json()

                # construct commit entry for finishing batch later
                commit = {
                    "cursor": {
                        "session_id": resp_data["session_id"],
                        "offset": os.path.getsize(local_path),
                    },
                    "commit": {
                        "path": dropbox_path,
                        "mode": "add",
                        "autorename": False,
                        "mute": False,
                    },
                }
                self.upload_session.append(commit)
                return commit

    async def upload_finish(self, check_interval: float = 3) -> list[dict]:
        """
        Finishes an upload batch.
        https://www.dropbox.com/developers/documentation/http/documentation#files-upload_session-finish_batch

        Args:
            check_interval:
                how often to check on the upload completion status (default is 3)
        Returns:
            list[dict]:
                List of FileMetadata dicts containing metadata on each uploaded file
        Raises:
            DropboxAPIError:
                If an unknown response is returned from the API.
        """

        if len(self.upload_session) == 0:
            raise RuntimeError("upload_session is empty, have you uploaded any files yet?")

        self.log.info("Finishing upload batch")
        self.log.debug(f"Batch size is {len(self.upload_session)}")

        url = "https://api.dropboxapi.com/2/files/upload_session/finish_batch"
        headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json",
        }
        data = json.dumps({"entries": self.upload_session})

        async with Request(self.client_session.post, url, self.log, headers=headers, data=data) as resp:
            resp_data = await resp.json()
            self.upload_session = []  # empty the local upload session

            if resp_data[".tag"] == "async_job_id":
                # check regularly for job completion
                return await self._upload_finish_check(resp_data["async_job_id"], check_interval=check_interval)
            elif resp_data[".tag"] == "complete":
                self.log.info("Upload batch finished")
                return resp_data["entries"]
            else:
                err = await resp.text()
                raise DropboxAPIError(resp.status, f"Unknown upload_finish response: {err}")

    async def _upload_finish_check(self, job_id: str, check_interval: float = 5) -> list[dict]:
        """
        Checks on an `upload_finish` async job every `check_interval` seconds.
        Should not be called directly, this is automatically called from `upload_finish`.
        https://www.dropbox.com/developers/documentation/http/documentation#files-upload_session-finish_batch-check:w

        Args:
            job_id:
                the job ID to check the status of
            check_interval:
                how often in seconds to check the status
        Returns:
            list[dict]:
                List of FileMetadata dicts containing metadata on each uploaded file
        """

        self.log.debug(f"Batch not finished, checking every {check_interval} seconds")

        url = "https://api.dropboxapi.com/2/files/upload_session/finish_batch/check"
        headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json",
        }
        data = json.dumps({"async_job_id": job_id})

        while True:
            await asyncio.sleep(check_interval)
            async with Request(self.client_session.post, url, self.log, headers=headers, data=data) as resp:
                resp_data = await resp.json()

                if resp_data[".tag"] == "complete":
                    self.log.info("Upload batch finished")
                    return resp_data["entries"]
                elif resp_data[".tag"] == "in_progress":
                    self.log.debug(f"Checking again in {check_interval} seconds")
                    continue

    async def upload_single(self, local_path: str, dropbox_path: str, args: dict = None) -> dict:
        """
        Uploads a single file. This should only be used for small quantities of files, for larger quantities use `upload_start` and `upload_finish`.
        https://www.dropbox.com/developers/documentation/http/documentation#files-upload

        Args:
            local_path:
                Local path to upload from.
            dropbox_path:
                Dropbox path to upload to.
            args:
                Dictionary of arguments to pass to the API.
        Returns:
            dict:
                FileMetadata of the uploaded file, if successful.
        Raises:
            ValueError:
                If `local_path` does not exist.
        """

        if args is None:
            args = {"mode": "add", "autorename": False, "mute": False}
        if not os.path.exists(local_path):
            raise ValueError(f"local_path {local_path} does not exist")
        args["path"] = dropbox_path

        self.log.info(f"Uploading {os.path.basename(local_path)}")
        self.log.debug(f"to {dropbox_path}")

        url = "https://content.dropboxapi.com/2/files/upload"
        headers = {
            "Authorization": f"Bearer {self.token}",
            "Dropbox-API-Arg": json.dumps(args),
            "Content-Type": "application/octet-stream",
        }

        async with aiofiles.open(local_path, "rb") as f:
            data = await f.read()
            async with Request(self.client_session.post, url, self.log, headers=headers, data=data) as resp:
                return await resp.json()

    async def create_shared_link(self, dropbox_path: str) -> str:
        """
        Create a shared link for a file in Dropbox.
        https://www.dropbox.com/developers/documentation/http/documentation#sharing-create_shared_link_with_settings

        Args:
            dropbox_path:
                Path of a file on Dropbox to create a shared link for.
        Returns:
            str:
                A shared link for the given file.
                If a shared link already exists, the existing one is returned, otherwise a new one is created.
        Raises:
            DropboxAPIError:
                If `dropbox_path` does not exist on Dropbox, or if an otherwise unknown status is returned.
        """

        self.log.info(f"Creating shared link for file {os.path.basename(dropbox_path)}")
        self.log.debug(f"Full path is {dropbox_path}")

        url = "https://api.dropboxapi.com/2/sharing/create_shared_link_with_settings"
        headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json",
        }
        data = json.dumps({"path": dropbox_path})

        # accept 409 status to check for existing shared link
        async with Request(
            self.client_session.post,
            url,
            self.log,
            headers=headers,
            data=data,
            ok_statuses=[200, 409],
        ) as resp:
            resp_data = await resp.json()

            if resp.status == 200:
                return resp_data["url"]
            if "shared_link_already_exists" in resp_data["error_summary"]:
                self.log.warning(
                    f"Shared link already exists for {os.path.basename(dropbox_path)}, using existing link"
                )
                return resp_data["error"]["shared_link_already_exists"]["metadata"]["url"]
            elif "not_found" in resp_data["error_summary"]:
                raise DropboxAPIError(resp.status, f"Path {dropbox_path} does not exist")
            else:
                err = await resp.text()
                raise DropboxAPIError(resp.status, f"Unknown Dropbox error: {err}")

    async def get_shared_link_metadata(self, shared_link: str) -> dict:
        """
        Gets the metadata for the file/folder behind a shared link.
        https://www.dropbox.com/developers/documentation/http/documentation#sharing-get_shared_link_metadata

        Args:
            shared_link:
                A shared link which points to the file or folder to get metadata from.
        Returns:
            dict:
                FileMetadata or FolderMetadata for the file/folder behind the shared link
        """

        self.log.info(f"Getting metadata from shared link {shared_link}")

        url = "https://api.dropboxapi.com/2/sharing/get_shared_link_metadata"
        headers = {
            "Authorization": f"Bearer {self.token}",
            "Content-Type": "application/json",
        }
        data = json.dumps({"url": shared_link})

        async with Request(self.client_session.post, url, self.log, headers=headers, data=data) as resp:
            return await resp.json()

    async def __aenter__(self):
        return self

    async def __aexit__(self, *excinfo):
        await self.client_session.close()


async def run_upload_to_dropbox(dbx: AsyncDropboxAPI, path_to_file: pathlib.PosixPath) -> None:
    # upload the new file to an upload session
    # this returns a "commit" dict, which will be passed to upload_finish later
    # the commit is saved in the AsyncDropboxAPI object already, so unless you need
    # information from it you can discard the return value
    await dbx.upload_start(path_to_file, f"/{pathlib.Path(path_to_file).name}")


async def dropbox_upload(list_of_files_to_upload: List[str]) -> None:
    """Async upload function for dropbox. Call this to kick off a dbx.upload_start

    Args:
        list_of_files_to_upload (List[str]): [description]
    """
    # TEMPCHANGE: # async with AsyncDropboxAPI(DROPBOX_CEREBRO_TOKEN) as dbx:
    # TEMPCHANGE: #     await dbx.validate()
    async with AsyncDropboxAPI(aiosettings.dropbox_cerebro_token) as dbx:
        await dbx.validate()

        # LOGGER.info("simulating cerebro download then upload to dropbox ...")
        # data = await file.read()
        # p = pathlib.Path(file.filename)
        # extension = p.suffix.split(".")[-1]
        # fname = p.stem
        # directory = "/Users/malcolm/dev/bossjones/sandbox/aiodropbox/audit"
        # async with aiofiles.tempfile.NamedTemporaryFile('wb+') as f:
        #     LOGGER.info(f"writing to {f.name}")
        #     await f.write(data)
        #     await f.flush()
        #     await f.seek(0)

        #     filename = f.name
        #     LOGGER.info(f"os.path.exists(filename) -> {os.path.exists(filename)}")
        #     LOGGER.info(f"os.path.isfile(filename) -> {os.path.isfile(filename)}")

        # path_to_file = await writer.write_file(fname, data, extension, directory)
        # path_to_file_api = pathlib.Path(path_to_file).absolute()
        # assert path_to_file_api.exists()

        # list_of_files_to_upload = [path_to_file]

        # create a coroutine for each link in shared_links
        # run them and print a simple confirmation message when we have a result
        coroutines = [run_upload_to_dropbox(dbx, _file) for _file in list_of_files_to_upload]
        for coro in asyncio.as_completed(coroutines):
            try:
                res = await coro
            except Exception as ex:
                print(ex)
                exc_type, exc_value, exc_traceback = sys.exc_info()
                LOGGER.error(f"Error Class: {str(ex.__class__)}")
                output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
                LOGGER.warning(output)
                LOGGER.error(f"exc_type: {exc_type}")
                LOGGER.error(f"exc_value: {exc_value}")
                traceback.print_tb(exc_traceback)
                raise
            else:
                LOGGER.info(f"Processed {res}")

        # once everything is uploaded, finish the upload batch
        # this returns the metadata of all of the uploaded files
        await dbx.upload_finish()

        # print out some info
        LOGGER.info("\nThe files we just uploaded are:")
        for meme in list_of_files_to_upload:
            LOGGER.info(f"{meme}")

        # asyncio.get_event_loop().run_until_complete(main(token, shared_links, log))

</document_content>
</document>
<document index="21">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/aiomodels.py</source>
<document_content>
"""cerebro_bot.utils.aiomodels"""
import typing

import aiohttp
import bs4
from bs4 import BeautifulSoup
from fuzzywuzzy import process
from markdownify import MarkdownConverter
from pytablewriter import TableWriterFactory

VALID_TABLE_HEADERS = ["Model Name", "author", "Scale", "Purpose (short)", "sample"]

MODEL_TABLE_LOOKUP = {
    "Universal Models": 8,
    "Realistic Photos": 10,
    "Art/Pixel Art": 13,
    "Anime": 16,
    "Manga": 18,
    "Cartoons": 20,
    # document.querySelector("#mw-content-text > div > table:nth-child(22)")
    "Digital Animation": 22,
    "Drawings": 24,
    # document.querySelector("#mw-content-text > div > table:nth-child(26)")
    "General Animation": 26,
    # document.querySelector("#mw-content-text > div > table:nth-child(29)")
    "Traditional Animation": 29,
    # document.querySelector("#mw-content-text > div > table:nth-child(34)")
    "JPEG Artifacts": 34,
    "Aliasing": 36,
    "GIF": 38,
    "DDS (BC1/DXT1, BC3/DXT5 Compression)": 40,
    "Dithering": 42,
    "Blurring": 44,
    "Banding": 46,
    "Halo Removal": 48,
    "Noise": 50,
    # document.querySelector("#mw-content-text > div > table:nth-child(53)")
    "Oversharpening": 53,
    "DeToon": 55,
    "Image De/Colorization": 59,
    "Images": 62,
    "Text": 65,
    "Inpainting": 67,
    "Fabric/Cloth": 69,
    "Alphas": 72,
    "CGI": 74,
    "Luminance/Chroma": 76,
    "Cats": 78,
    "Coins": 80,
    "Faces": 82,
    "Foliage/Ground": 84,
    "Game Screenshots": 87,
    "Normal Map/Bump Map Generation": 90,
    "Video Game Textures": 92,
    "Video Compression": 96,
    "VHS Tapes": 98,
    "Model Collections": 100,
    # document.querySelector("#mw-content-text > div > table:nth-child(113)")
    "CAIN Models": 113,
}

SELECTED_URL = "https://upscale.wiki/wiki/Model_Database"


async def get_site_content():
    async with aiohttp.ClientSession() as session:
        async with session.get(SELECTED_URL) as resp:
            text = await resp.read()

    return BeautifulSoup(text.decode("utf-8"), "lxml")


# SOURCE: https://gist.github.com/ergoithz/6cf043e3fdedd1b94fcf


def xpath_soup(element):
    components = []
    child = element if element.name else element.parent
    for parent in child.parents:
        siblings = parent.find_all(child.name, recursive=False)
        components.append(child.name if siblings == [child] else "%s[%d]" % (child.name, 1 + siblings.index(child)))
        child = parent
    components.reverse()
    return f'/{"/".join(components)}'


def get_all_tables(sites_soup: BeautifulSoup) -> bs4.element.ResultSet:
    """Find all h3 tags on page, and add them to an array, all of these items are the headers for model sections.

    Args:
        sites_soup (BeautifulSoup): BeautifulSoup parser object

    Returns:
        bs4.element.ResultSet: List containing string representations of the h3 names, eg "Universal Models"
    """
    return sites_soup.select("#mw-content-text > div > table:nth-child(n)")


def get_tables_by_name(sites_soup: BeautifulSoup, table_name: str) -> bs4.element.ResultSet:
    """Get html from table based on section name

    Args:
        sites_soup (BeautifulSoup): BeautifulSoup parser
        table_name (str): Name of section, eg. "CAIN Models"

    Returns:
        bs4.element.ResultSet: result set html
    """
    fuzzy_table_name = fuzzy_match_model_string(table_name)
    n = MODEL_TABLE_LOOKUP[fuzzy_table_name]
    js_path = f"#mw-content-text > div > table:nth-child({n})"
    return sites_soup.select(js_path)


def get_h3s(sites_soup: BeautifulSoup) -> bs4.element.ResultSet:
    """Find all h3 tags on page, and add them to an array, all of these items are the headers for model sections.

    Args:
        sites_soup (BeautifulSoup): BeautifulSoup parser object

    Returns:
        bs4.element.ResultSet: List containing string representations of the h3 names, eg "Universal Models"
    """
    return sites_soup.find_all("h3")


def get_sections(sites_soup: BeautifulSoup) -> typing.List[str]:
    """Find all h3 tags on page, and add them to an array, all of these items are the headers for model sections.

    Args:
        sites_soup (BeautifulSoup): BeautifulSoup parser object

    Returns:
        typing.List[str]: List containing string representations of the h3 names, eg "Universal Models"
    """
    all_model_sections = get_h3s(sites_soup)

    return [sec.text for sec in all_model_sections]


def list_all_model_types():
    return list(MODEL_TABLE_LOOKUP.keys())


def fuzzy_match_model_string(lookup: str) -> str:
    """Get the Levenshtein Distance of a string and return the correct value.

    Args:
        lookup (str): substring to look up, eg "anime"

    Returns:
        str: Returns actual value, eg "Anime"
    """
    model_list = list_all_model_types()
    res = process.extractOne(lookup, model_list)
    return res[0]


# @snoop
def get_result_set_sublist(records: bs4.element.ResultSet) -> typing.List[str]:
    # VALID_TABLE_HEADERS = ["Model Name", "author", "Scale", "Purpose (short)", "sample"]
    rows = []
    for row in records:
        # bpdb.set_trace()
        row_parser = row.find_all("td")
        # print(f" count = {count}, row = {row}")
        rows.append(
            [
                md_from_beautifulsoup(row_parser[0]),
                row_parser[1].get_text(strip=True),
                row_parser[2].get_text(strip=True),
                row_parser[5].get_text(strip=True),
                md_from_beautifulsoup(row_parser[9]),
            ]
        )

    # print(rows)
    return rows


# SOURCE: https://stackoverflow.com/questions/35755153/extract-only-specific-rows-and-columns-from-a-table-td-in-beautifulsoup-pytho


def get_html_table_headers(res_table: bs4.element.ResultSet):
    """Parse a result set and return only the values we care about

    Args:
        res_table (bs4.element.ResultSet): _description_
    """
    headers = [c.get_text(strip=True) for c in res_table[0].find("tr").find_all("th")]

    # only include the ones we care about
    final_headers = [f"{h}" for h in headers if h in VALID_TABLE_HEADERS]

    # get all table records and nuke the headers only
    all_table_records = res_table[0].find_all("tr")
    del all_table_records[0]

    table_rows_list = get_result_set_sublist(all_table_records)

    return final_headers, table_rows_list


# Create shorthand method for conversion


def md_from_beautifulsoup(sites_soup: BeautifulSoup, **options):
    """Converting BeautifulSoup objects"""
    return MarkdownConverter(**options).convert_soup(sites_soup)


def generate_markdown_table(table_name, final_table_headers, table_table_rows_list, margin):
    # SOURCE: https://github.com/thombashi/pytest-md-report/blob/aeff356c0b0831ad594cf5af45fca9e08dd1f92d/pytest_md_report/plugin.py
    writer = TableWriterFactory.create_from_format_name("md")
    writer.table_name = fuzzy_match_model_string(table_name)
    writer.margin = margin
    writer.headers = final_table_headers
    writer.value_matrix = table_table_rows_list

    return writer.dumps()


async def upscale_model_markdown(fuzzy_search_str: str):
    sites_soup = await get_site_content()
    # model_sections_list = get_sections(sites_soup)
    # all_th_list = sites_soup.find_all('th')
    model_table = get_tables_by_name(sites_soup, fuzzy_search_str)
    # anime_markdown = md_from_beautifulsoup(model_table[0])
    final_table_headers, table_table_rows_list = get_html_table_headers(model_table)
    return generate_markdown_table(fuzzy_search_str, final_table_headers, table_table_rows_list, 1)


# # TODO: implement multi download https://stackoverflow.com/questions/64282309/aiohttp-download-large-list-of-pdf-files
# async def async_download_file(data: dict, dl_dir="./"):
#     async with aiohttp.ClientSession() as session:
#         url: str = data["url"]
#         username: str = data["tweet"]["username"]
#         p = pathlib.Path(url)
#         p_dl_dir = pathlib.Path(dl_dir)
#         full_path_dl_dir = f"{p_dl_dir.absolute()}"
#         LOGGER.debug(f"Downloading {url} to {full_path_dl_dir}/{p.name}")
#         async with session.get(url) as resp:
#             content = await resp.read()

#             # Check everything went well
#             if resp.status != 200:
#                 LOGGER.error(f"Download failed: {resp.status}")
#                 return

#             if resp.status == 200:
#                 async with aiofiles.open(f"{full_path_dl_dir}/{p.name}", mode="+wb") as f:
#                     await f.write(content)
#                     # No need to use close(f) when using with statement
#                 # f = await aiofiles.open(f"{full_path_dl_dir}/{p.name}", mode='wb')
#                 # await f.write(await resp.read())
#                 # await f.close()
# loop = asyncio.get_event_loop()
# sites_soup = loop.run_until_complete(get_site_content())
# loop.close()


# # print(sites_soup)

# # all_tables = sites_soup.find_all('table')

# fuzzy_search_str = "anime"


# # print(markdown_str_final)

</document_content>
</document>
<document index="22">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/aiotweetpik.py</source>
<document_content>
"""cerebro_bot.utils.aiotweetpik"""
# pylint: disable=unused-import
# NOTE: couple sources
# https://github.com/powerfist01/hawk-eyed/blob/f340c6ff814dd3e2a3cac7a30d03b7c07d95d1e4/services/tweet_to_image/tweetpik.py
# https://github.com/bwhli/birdcatcher/blob/a4b33feff4f2d88d5412cd50b11760312bdd4f1d/app/util/Tweet.py
from __future__ import annotations

import asyncio
import json
import logging
import os
import pathlib
import re
import sys
import typing
from typing import (
    TYPE_CHECKING,
    Any,
    ClassVar,
    Coroutine,
    Dict,
    Iterable,
    List,
    Optional,
    Tuple,
    Type,
    TypeVar,
    Union,
)
from urllib.parse import quote as _uriquote
import weakref

import aiofiles
import aiohttp

from cerebro_bot.bot_logger import get_logger

_from_json = json.loads

LOGGER = get_logger(__name__, provider="Tweetpik", level=logging.DEBUG)

TWEETPIK_AUTHORIZATION = os.environ.get("TWEETPIK_AUTHORIZATION")
TWEETPIK_BUCKET_ID = "323251495115948625"

TWEETPIK_DIMENSION_IG_FEED = "1:1"
TWEETPIK_DIMENSION_IG_STORY = "9:16"
TWEETPIK_TIMEZONE = "America/New_York"
TWEETPIK_DISPLAY_LIKES = False
TWEETPIK_DISPLAY_REPLIES = False
TWEETPIK_DISPLAY_RETWEETS = False
TWEETPIK_DISPLAY_VERIFIED = True
TWEETPIK_DISPLAY_SOURCE = True
TWEETPIK_DISPLAY_TIME = True
TWEETPIK_DISPLAY_MEDIA_IMAGES = True
TWEETPIK_DISPLAY_LINK_PREVIEW = True
# Any number higher than zero. This value is representing a percentage
TWEETPIK_TEXT_WIDTH = "100"
# Any number higher than zero. This value is used in pixels(px) units
TWEETPIK_CANVAS_WIDTH = "510"

TWEETPIK_BACKGROUND_COLOR = "#FFFFFF"  # Change the background color of the tweet screenshot
TWEETPIK_TEXT_PRIMARY_COLOR = (
    "#000000"  # Change the text primary color used for the main text of the tweet and user's name
)
TWEETPIK_TEXT_SECONDARY_COLOR = (
    "#5B7083"  # Change the text secondary used for the secondary info of the tweet like the username
)
TWEETPIK_LINK_COLOR = "#1B95E0"  # Change the link colors used for the links, hashtags and mentions
TWEETPIK_VERIFIED_ICON = "#1B95E0"  # Change the verified icon color


def _to_json(obj: Any) -> str:
    return json.dumps(obj, separators=(",", ":"), ensure_ascii=True)


if TYPE_CHECKING:
    from aiohttp import ClientResponse

    try:
        from requests import Response

        _ResponseType = Union[ClientResponse, Response]
    except ModuleNotFoundError:
        _ResponseType = ClientResponse

    Snowflake = Union[str, int]
    SnowflakeList = List[Snowflake]

    from types import TracebackType

    T = TypeVar("T")
    BE = TypeVar("BE", bound=BaseException)
    MU = TypeVar("MU", bound="MaybeUnlock")
    Response = Coroutine[Any, Any, T]


class _MissingSentinel:
    def __eq__(self, other):
        return False

    def __bool__(self):
        return False

    def __repr__(self):
        return "..."


MISSING: Any = _MissingSentinel()


def get_tweet_id(tweet_url: str) -> str:
    return re.findall(r"[http?s//]?twitter\.com\/.*\/status\/(\d+)", tweet_url)[0]


def build_tweetpik_download_url(tweetId: str) -> str:
    """Building the URL
    The URL is predictable, so you don't have to worry about storing it. You just need to make sure you generated it before using it. The URL will always consist of your bucket ID and the tweet ID. https://ik.imagekit.io/tweetpik/323251495115948625/tweetId

    Returns:
        str: Url of the image we plan to download
    """
    return f"https://ik.imagekit.io/tweetpik/{TWEETPIK_BUCKET_ID}/{tweetId}"


class TweetpikAPIError(Exception):
    """
    Exception for errors thrown by the API. Contains the HTTP status code and the returned error message.
    """

    def __init__(self, status: int, message: typing.Union[str, dict]):
        self.status = status
        self.message = message
        super().__init__(self.message)

    def __str__(self):
        if not isinstance(self.message, str):
            return f"{self.status} {self.message}"
        try:
            self.message = json.loads(self.message)
            return f'{self.status} {self.message["error_summary"]}'
        except Exception:
            return f"{self.status} {self.message}"


class TweetpikException(Exception):
    """Base exception class for tweetpik

    Ideally speaking, this could be caught to handle any exceptions raised from this library.
    """


class ClientException(TweetpikException):
    """Exception that's raised when an operation in the :class:`Client` fails.

    These are usually for exceptions that happened due to user input.
    """


class NoMoreItems(TweetpikException):
    """Exception that is raised when an async iteration operation has no more items."""


class GatewayNotFound(TweetpikException):
    """An exception that is raised when the gateway for Tweetpik could not be found"""

    def __init__(self):
        message = "The gateway to connect to discord was not found."
        super().__init__(message)


def _flatten_error_dict(d: Dict[str, Any], key: str = "") -> Dict[str, str]:
    items: List[Tuple[str, str]] = []
    for k, v in d.items():
        new_key = f"{key}.{k}" if key else k

        if isinstance(v, dict):
            try:
                _errors: List[Dict[str, Any]] = v["_errors"]
            except KeyError:
                items.extend(_flatten_error_dict(v, new_key).items())
            else:
                items.append((new_key, " ".join(x.get("message", "") for x in _errors)))
        else:
            items.append((new_key, v))

    return dict(items)


class HTTPException(TweetpikException):
    """Exception that's raised when an HTTP request operation fails.

    Attributes
    ------------
    response: :class:`aiohttp.ClientResponse`
        The response of the failed HTTP request. This is an
        instance of :class:`aiohttp.ClientResponse`. In some cases
        this could also be a :class:`requests.Response`.

    text: :class:`str`
        The text of the error. Could be an empty string.
    status: :class:`int`
        The status code of the HTTP request.
    code: :class:`int`
        The Tweetpik specific error code for the failure.
    """

    def __init__(self, response: _ResponseType, message: Optional[Union[str, Dict[str, Any]]]):
        self.response: _ResponseType = response
        self.status: int = response.status  # type: ignore
        self.code: int
        self.text: str
        if isinstance(message, dict):
            self.code = message.get("code", 0)
            base = message.get("message", "")
            if errors := message.get("errors"):
                errors = _flatten_error_dict(errors)
                helpful = "\n".join("In %s: %s" % t for t in errors.items())
                self.text = base + "\n" + helpful
            else:
                self.text = base
        else:
            self.text = message or ""
            self.code = 0

        fmt = "{0.status} {0.reason} (error code: {1})"
        if len(self.text):
            fmt += ": {2}"

        super().__init__(fmt.format(self.response, self.code, self.text))


class Forbidden(HTTPException):
    """Exception that's raised for when status code 403 occurs.

    Subclass of :exc:`HTTPException`
    """


class NotFound(HTTPException):
    """Exception that's raised for when status code 404 occurs.

    Subclass of :exc:`HTTPException`
    """


class TweetpikServerError(HTTPException):
    """Exception that's raised for when a 500 range status code occurs.

    Subclass of :exc:`HTTPException`.

    .. versionadded:: 1.5
    """


class InvalidData(ClientException):
    """Exception that's raised when the library encounters unknown
    or invalid data from Tweetpik.
    """


class InvalidArgument(ClientException):
    """Exception that's raised when an argument to a function
    is invalid some way (e.g. wrong value or wrong type).

    This could be considered the analogous of ``ValueError`` and
    ``TypeError`` except inherited from :exc:`ClientException` and thus
    :exc:`TweetpikException`.
    """


class ConnectionClosed(ClientException):
    """Exception that's raised when the gateway connection is
    closed for reasons that could not be handled internally.

    Attributes
    -----------
    code: :class:`int`
        The close code of the websocket.
    reason: :class:`str`
        The reason provided for the closure.
    shard_id: Optional[:class:`int`]
        The shard ID that got closed if applicable.
    """

    def __init__(self, socket: ClientResponse, *, code: Optional[int] = None):
        # This exception is just the same exception except
        # reconfigured to subclass ClientException for users
        self.code: int = code or socket.close_code or -1
        # aiohttp doesn't seem to consistently provide close reason
        self.reason: str = ""
        super().__init__(f"HTTP Request closed with {self.code}")


# SOURCE: discord.py
async def json_or_text(response: aiohttp.ClientResponse) -> Union[Dict[str, Any], str]:
    text = await response.text(encoding="utf-8")
    try:
        if response.headers["content-type"] == "application/json":
            return _from_json(text)
    except KeyError:
        # Thanks Cloudflare
        pass

    return text


# SOURCE: discord.py
class TweetpikRoute:
    BASE: ClassVar[str] = "https://tweetpik.com/api"

    def __init__(self, method: str, path: str, **parameters: Any) -> None:
        self.path: str = path
        self.method: str = method
        url = self.BASE + self.path
        if parameters:
            url = url.format_map({k: _uriquote(v) if isinstance(v, str) else v for k, v in parameters.items()})
        self.url: str = url
        self.bucket_id: str = TWEETPIK_BUCKET_ID

    @property
    def bucket(self) -> str:
        # the bucket is just method + path w/ major parameters
        return f"{self.bucket_id}"


# SOURCE: discord.py
class MaybeUnlock:
    def __init__(self, lock: asyncio.Lock) -> None:
        self.lock: asyncio.Lock = lock
        self._unlock: bool = True

    def __enter__(self: MU) -> MU:
        return self

    def defer(self) -> None:
        self._unlock = False

    def __exit__(
        self,
        exc_type: Optional[Type[BE]],
        exc: Optional[BE],
        traceback: Optional[TracebackType],
    ) -> None:
        if self._unlock:
            self.lock.release()


# SOURCE: discord.py
class TweetpikHTTPClient:
    """Represents an HTTP client sending HTTP requests to the Tweetpik API."""

    def __init__(
        self,
        connector: Optional[aiohttp.BaseConnector] = None,
        *,
        proxy: Optional[str] = None,
        proxy_auth: Optional[aiohttp.BasicAuth] = None,
        loop: Optional[asyncio.AbstractEventLoop] = None,
        unsync_clock: bool = True,
    ) -> None:
        self.loop: asyncio.AbstractEventLoop = asyncio.get_event_loop() if loop is None else loop
        self.connector = connector
        # self.__session: aiohttp.ClientSession = MISSING  # filled in static_login
        self.__session: aiohttp.ClientSession = aiohttp.ClientSession(connector=aiohttp.TCPConnector(limit_per_host=50))
        self._locks: weakref.WeakValueDictionary = weakref.WeakValueDictionary()
        self._global_over: asyncio.Event = asyncio.Event()
        self._global_over.set()
        self.token: Optional[str] = None
        self.bot_token: bool = False
        self.proxy: Optional[str] = proxy
        self.proxy_auth: Optional[aiohttp.BasicAuth] = proxy_auth
        self.use_clock: bool = not unsync_clock

        user_agent = "TweetpikHTTPClient (https://github.com/universityofprofessorex/cerebro-bot {0}) Python/{1[0]}.{1[1]} aiohttp/{2}"
        self.user_agent: str = user_agent.format("0.1.0", sys.version_info, aiohttp.__version__)

    async def request(
        self,
        route: TweetpikRoute,
        *,
        # files: Optional[Sequence[File]] = None,
        form: Optional[Iterable[Dict[str, Any]]] = None,
        **kwargs: Any,
    ) -> Any:
        print(f"{form}")

        bucket = route.bucket
        method = route.method
        url = route.url

        lock = self._locks.get(bucket)
        if lock is None:
            lock = asyncio.Lock()
            if bucket is not None:
                self._locks[bucket] = lock

        # header creation
        headers: Dict[str, str] = {
            "User-Agent": self.user_agent,
            "Authorization": TWEETPIK_AUTHORIZATION,
            "Content-Type": "application/json",
        }

        kwargs["data"] = _to_json(kwargs.pop("json"))

        kwargs["headers"] = headers

        # Proxy support
        if self.proxy is not None:
            kwargs["proxy"] = self.proxy
        if self.proxy_auth is not None:
            kwargs["proxy_auth"] = self.proxy_auth

        if not self._global_over.is_set():
            # wait until the global lock is complete
            await self._global_over.wait()

        response: Optional[aiohttp.ClientResponse] = None
        data: Optional[Union[Dict[str, Any], str]] = None
        await lock.acquire()
        with MaybeUnlock(lock) as maybe_lock:
            for tries in range(5):
                # if files:
                #     for f in files:
                #         f.reset(seek=tries)

                # if form:
                #     form_data = aiohttp.FormData()
                #     for params in form:
                #         form_data.add_field(**params)
                #     kwargs['data'] = form_data

                try:
                    async with self.__session.request(method, url, **kwargs) as response:
                        LOGGER.debug(f"{method} {url} with {kwargs.get('data')} has returned {response.status}")

                        # even errors have text involved in them so this is safe to call
                        data = await json_or_text(response)

                        LOGGER.debug("HERE IS THE DATA WE GET BACK FROM THE API CALL BELOVED")
                        LOGGER.debug(data)

                        # # check if we have rate limit header information
                        # remaining = response.headers.get('X-Ratelimit-Remaining')
                        # if remaining == '0' and response.status != 429:
                        #     # we've depleted our current bucket
                        #     delta = utils._parse_ratelimit_header(response, use_clock=self.use_clock)
                        #     LOGGER.debug('A rate limit bucket has been exhausted (bucket: %s, retry: %s).', bucket, delta)
                        #     maybe_lock.defer()
                        #     self.loop.call_later(delta, lock.release)

                        # the request was successful so just return the text/json
                        if 300 > response.status >= 200:
                            LOGGER.debug(f"{method} {url} has received {data}")
                            return data

                        # we are being rate limited
                        if response.status == 429:
                            if not response.headers.get("Via") or isinstance(data, str):
                                # Banned by Cloudflare more than likely.
                                raise HTTPException(response, data)

                            fmt = 'We are being rate limited. Retrying in %.2f seconds. Handled under the bucket "%s"'

                            # sleep a bit
                            retry_after: float = data["retry_after"]
                            LOGGER.warning(fmt, retry_after, bucket)

                            # # check if it's a global rate limit
                            # is_global = data.get('global', False)
                            # if is_global:
                            #     LOGGER.warning('Global rate limit has been hit. Retrying in %.2f seconds.', retry_after)
                            #     self._global_over.clear()

                            # await asyncio.sleep(retry_after)
                            # LOGGER.debug('Done sleeping for the rate limit. Retrying...')

                            # # release the global lock now that the
                            # # global rate limit has passed
                            # if is_global:
                            #     self._global_over.set()
                            #     LOGGER.debug('Global rate limit is now over.')

                            continue

                        # we've received a 500, 502, or 504, unconditional retry
                        if response.status in {500, 502, 504}:
                            await asyncio.sleep(1 + tries * 2)
                            continue

                        # the usual error cases
                        if response.status == 403:
                            raise Forbidden(response, data)
                        elif response.status == 404:
                            raise NotFound(response, data)
                        elif response.status >= 500:
                            raise TweetpikServerError(response, data)
                        else:
                            raise HTTPException(response, data)

                # This is handling exceptions from the request
                except OSError as e:
                    # Connection reset by peer
                    if tries < 4 and e.errno in (54, 10054):
                        await asyncio.sleep(1 + tries * 2)
                        continue
                    raise

            if response is not None:
                # We've run out of retries, raise.
                if response.status >= 500:
                    raise TweetpikServerError(response, data)

                raise HTTPException(response, data)

            raise RuntimeError("Unreachable code in HTTP handling")

    async def get_from_cdn(self, url: str) -> bytes:
        async with self.__session.get(url) as resp:
            if resp.status == 200:
                return await resp.read()
            elif resp.status == 404:
                raise NotFound(resp, "asset not found")
            elif resp.status == 403:
                raise Forbidden(resp, "cannot retrieve asset")
            else:
                raise HTTPException(resp, "failed to get asset")

    # state management

    async def close(self) -> None:
        if self.__session:
            await self.__session.close()

    def images(
        self,
        tweet_url: Optional[str],
        *,
        dimension_ig_feed: Optional[str] = TWEETPIK_DIMENSION_IG_FEED,
        dimension_ig_story: Optional[str] = TWEETPIK_DIMENSION_IG_STORY,
        timezone: Optional[str] = TWEETPIK_TIMEZONE,
        display_likes: Optional[str] = TWEETPIK_DISPLAY_LIKES,
        display_replies: Optional[str] = TWEETPIK_DISPLAY_REPLIES,
        display_retweets: Optional[str] = TWEETPIK_DISPLAY_RETWEETS,
        display_verified: Optional[str] = TWEETPIK_DISPLAY_VERIFIED,
        display_source: Optional[str] = TWEETPIK_DISPLAY_SOURCE,
        display_time: Optional[str] = TWEETPIK_DISPLAY_TIME,
        display_media_images: Optional[str] = TWEETPIK_DISPLAY_MEDIA_IMAGES,
        display_link_preview: Optional[str] = TWEETPIK_DISPLAY_LINK_PREVIEW,
        text_width: Optional[str] = TWEETPIK_TEXT_WIDTH,
        canvas_width: Optional[str] = TWEETPIK_CANVAS_WIDTH,
        background_color: Optional[str] = TWEETPIK_BACKGROUND_COLOR,
        text_primary_color: Optional[str] = TWEETPIK_TEXT_PRIMARY_COLOR,
        text_secondary_color: Optional[str] = TWEETPIK_TEXT_SECONDARY_COLOR,
        link_color: Optional[str] = TWEETPIK_LINK_COLOR,
        verified_icon: Optional[str] = TWEETPIK_VERIFIED_ICON,
    ) -> Any:
        r = TweetpikRoute("POST", "/images", tweet_url=tweet_url)
        payload = {}

        # if tweet_url:
        #     payload["tweet_url"] = tweet_url
        if tweet_url:
            payload["tweetId"] = get_tweet_id(tweet_url)

        if dimension_ig_feed:
            payload["dimension_ig_feed"] = dimension_ig_feed
        if dimension_ig_story:
            payload["dimension_ig_story"] = dimension_ig_story
        if timezone:
            payload["timezone"] = timezone
        if display_likes:
            payload["display_likes"] = display_likes
        if display_replies:
            payload["display_replies"] = display_replies
        if display_retweets:
            payload["display_retweets"] = display_retweets
        if display_verified:
            payload["display_verified"] = display_verified
        if display_source:
            payload["display_source"] = display_source
        if display_time:
            payload["display_time"] = display_time
        if display_media_images:
            payload["display_media_images"] = display_media_images
        if display_link_preview:
            payload["display_link_preview"] = display_link_preview
        if text_width:
            payload["text_width"] = text_width
        if canvas_width:
            payload["canvas_width"] = canvas_width
        if background_color:
            payload["background_color"] = background_color
        if text_primary_color:
            payload["text_primary_color"] = text_primary_color
        if text_secondary_color:
            payload["text_secondary_color"] = text_secondary_color
        if link_color:
            payload["link_color"] = link_color
        if verified_icon:
            payload["verified_icon"] = verified_icon

        LOGGER.debug("payload debuggggggggggggggggggggggggggg")
        LOGGER.debug(payload)

        return self.request(r, json=payload)

    async def aimages(
        self,
        tweet_url: Optional[str],
        *,
        dimension_ig_feed: Optional[str] = TWEETPIK_DIMENSION_IG_FEED,
        dimension_ig_story: Optional[str] = TWEETPIK_DIMENSION_IG_STORY,
        timezone: Optional[str] = TWEETPIK_TIMEZONE,
        display_likes: Optional[str] = TWEETPIK_DISPLAY_LIKES,
        display_replies: Optional[str] = TWEETPIK_DISPLAY_REPLIES,
        display_retweets: Optional[str] = TWEETPIK_DISPLAY_RETWEETS,
        display_verified: Optional[str] = TWEETPIK_DISPLAY_VERIFIED,
        display_source: Optional[str] = TWEETPIK_DISPLAY_SOURCE,
        display_time: Optional[str] = TWEETPIK_DISPLAY_TIME,
        display_media_images: Optional[str] = TWEETPIK_DISPLAY_MEDIA_IMAGES,
        display_link_preview: Optional[str] = TWEETPIK_DISPLAY_LINK_PREVIEW,
        text_width: Optional[str] = TWEETPIK_TEXT_WIDTH,
        canvas_width: Optional[str] = TWEETPIK_CANVAS_WIDTH,
        background_color: Optional[str] = TWEETPIK_BACKGROUND_COLOR,
        text_primary_color: Optional[str] = TWEETPIK_TEXT_PRIMARY_COLOR,
        text_secondary_color: Optional[str] = TWEETPIK_TEXT_SECONDARY_COLOR,
        link_color: Optional[str] = TWEETPIK_LINK_COLOR,
        verified_icon: Optional[str] = TWEETPIK_VERIFIED_ICON,
    ) -> Any:
        r = TweetpikRoute("POST", "/images", tweet_url=tweet_url)
        payload = {}

        if tweet_url:
            payload["tweetId"] = get_tweet_id(tweet_url)

        if dimension_ig_feed:
            payload["dimension_ig_feed"] = dimension_ig_feed
        if dimension_ig_story:
            payload["dimension_ig_story"] = dimension_ig_story
        if timezone:
            payload["timezone"] = timezone
        if display_likes:
            payload["display_likes"] = display_likes
        if display_replies:
            payload["display_replies"] = display_replies
        if display_retweets:
            payload["display_retweets"] = display_retweets
        if display_verified:
            payload["display_verified"] = display_verified
        if display_source:
            payload["display_source"] = display_source
        if display_time:
            payload["display_time"] = display_time
        if display_media_images:
            payload["display_media_images"] = display_media_images
        if display_link_preview:
            payload["display_link_preview"] = display_link_preview
        if text_width:
            payload["text_width"] = text_width
        if canvas_width:
            payload["canvas_width"] = canvas_width
        if background_color:
            payload["background_color"] = background_color
        if text_primary_color:
            payload["text_primary_color"] = text_primary_color
        if text_secondary_color:
            payload["text_secondary_color"] = text_secondary_color
        if link_color:
            payload["link_color"] = link_color
        if verified_icon:
            payload["verified_icon"] = verified_icon

        LOGGER.debug("payload debuggggggggggggggggggggggggggg")
        LOGGER.debug(payload)
        data = await self.request(r, json=payload)
        await self.close()

        return data


# TODO: implement multi download https://stackoverflow.com/questions/64282309/aiohttp-download-large-list-of-pdf-files


async def async_download_file(data: dict, dl_dir="./"):
    async with aiohttp.ClientSession() as session:
        url: str = data["url"]
        username: str = data["tweet"]["username"]
        p = pathlib.Path(url)
        p_dl_dir = pathlib.Path(dl_dir)
        full_path_dl_dir = f"{p_dl_dir.absolute()}"
        LOGGER.debug(f"Downloading {url} to {full_path_dl_dir}/{p.name}")
        async with session.get(url) as resp:
            content = await resp.read()

            # Check everything went well
            if resp.status != 200:
                LOGGER.error(f"Download failed: {resp.status}")
                return

            async with aiofiles.open(f"{full_path_dl_dir}/{p.name}", mode="+wb") as f:
                await f.write(content)
                # No need to use close(f) when using with statement
                # f = await aiofiles.open(f"{full_path_dl_dir}/{p.name}", mode='wb')
                # await f.write(await resp.read())
                # await f.close()


# SOURCE: https://github.com/powerfist01/hawk-eyed/blob/f340c6ff814dd3e2a3cac7a30d03b7c07d95d1e4/services/tweet_to_image/tweetpik.py


# class TweetPik:
#     """
#     TweetPik API client using asynchronous HTTP requests.

#     Args:
#         tweet_url:
#             url of tweet we want to download [str]
#         retry_statuses:
#             list of statuses that will automatically be retried (default is [429])
#     """

#     tweetpik_uri = "https://tweetpik.com/api/images"
#     headers = {
#         "Content-Type": "application/json",
#         "authorization": TWEETPIK_AUTHORIZATION,
#     }

#     def __init__(self, tweet_url: str, retry_statuses: list[int] = [429]):
#         """Default constructor"""
#         self.tweet_url = tweet_url
#         self.tweet_id = self.get_tweet_id()
#         self.retry_statuses = retry_statuses
#         self.client_session = aiohttp.ClientSession(
#             connector=aiohttp.TCPConnector(limit_per_host=50)
#         )
#         self.upload_session: list[dict] = []

#     def get_tweet_id(self) -> str:
#         tweet_id = re.findall(
#             r"[http?s//]?twitter\.com\/.*\/status\/(\d+)", self.tweet_url
#         )[0]
#         return tweet_id

#     def fetch_tweet_image_url(self):
#         """To download get the url of the tweet image from tweetpik"""
#         try:
#             data = {"tweetId": self.tweet_id}

#             response = requests.post(
#                 self.tweetpik_uri, headers=self.headers, data=json.dumps(data)
#             )

#             if response.status_code == 201:
#                 data = response.json()
#                 return data["url"]
#             else:
#                 print("Error occured in fetching the image!")
#         except Exception as e:
#             print(e)

#     def download_image_using_tweet_id(self):
#         """To download the image using url"""

#         image_url = self.fetch_tweet_image_url()

#         res = requests.get(image_url, stream=True)
#         if res.status_code == 200:
#             path = "downloads/" + image_url.split("/")[-1]
#             with open(path, "wb") as f:
#                 for chunk in res:
#                     f.write(chunk)
#             path = self.crop_image(path)
#             return path
#         else:
#             print("Error Occured in downloading image!")

#     def crop_image(self, path):
#         """To crop the image using PILLOW"""

#         with Image.open(path) as im:

#             width, height = im.size  # Get dimensions
#             left = width / 1000
#             top = height / 10
#             right = width - width / 1000
#             bottom = height - height / 1000

#             # Here the image "im" is cropped and assigned to new variable im_crop
#             im_crop = im.crop((left, top, right, bottom))

#             im_crop.save(path, "png")

#         if str(path).endswith(".png"):
#             path = self.convert_to_jpeg(path)

#         return path

#     def convert_to_jpeg(self, path):
#         """To convert to jpg"""

#         im = Image.open(path)
#         rgb_im = im.convert("RGB")
#         path = path.replace(".png", ".jpg")
#         rgb_im.save(path)
#         return path


# # SOURCE: https://github.com/bwhli/birdcatcher/blob/a4b33feff4f2d88d5412cd50b11760312bdd4f1d/app/util/Tweet.py
# class Tweet:
#     def __init__(self, tweet_url: str):
#         self.tweet_url = tweet_url

#     def get_tweet_id(self) -> str:
#         tweet_id = re.findall(
#             r"[http?s//]?twitter\.com\/.*\/status\/(\d+)", self.tweet_url
#         )[0]
#         return tweet_id

#     def get_tweet_user(self) -> str:
#         tweet_user = re.findall(
#             r"[http?s//]?twitter\.com\/(.*)\/status\/\d+", self.tweet_url
#         )[0]
#         return tweet_user

#     def get_tweet_body(self) -> str:
#         if self.is_valid_tweet() == True:
#             tweet_id = self.get_tweet_id()
#             api_endpoint = f"https://api.twitter.com/2/tweets?ids={tweet_id}&tweet.fields=author_id,conversation_id,created_at,source"
#             request_headers = {"Authorization": "Bearer"}
#             response = requests.get(
#                 api_endpoint, headers=request_headers, timeout=5
#             ).json()["data"][0]
#             return json.dumps(response, ensure_ascii=False, sort_keys=True)
#         else:
#             return "Tweet ID is invalid."

#     def generate_tweet_image_url(self):
#         tweet_id = self.get_tweet_id()
#         headers = {
#             "Content-Type": "application/json",
#             "Authorization": "",
#         }
#         data = {"tweetId": str(tweet_id)}
#         response = requests.post(
#             "https://tweetpik.com/api/images", headers=headers, data=json.dumps(data)
#         ).json()
#         image_url = response["url"]
#         return image_url

#     def generate_tweet_image_b64_string(self):
#         image_url = self.generate_tweet_image_url()
#         response = requests.get(image_url, stream=True)
#         response.raw.decode_content = True
#         image = Image.open(response.raw)
#         buffered = BytesIO()
#         image.save(buffered, format="PNG", optimize=True)
#         tweet_image_b64_string = (
#             f"data:image/png;base64,{base64.b64encode(buffered.getvalue()).decode()}"
#         )
#         return tweet_image_b64_string

#     def is_valid_tweet(self) -> bool:
#         tweet_id = self.get_tweet_id()
#         api_endpoint = f"https://api.twitter.com/2/tweets?ids={tweet_id}"
#         request_headers = {"Authorization": "Bearer"}
#         response = requests.get(api_endpoint, headers=request_headers, timeout=5).json()
#         if "errors" in response:
#             return False
#         else:
#             return True

</document_content>
</document>
<document index="23">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/architecture.py</source>
<document_content>
# # https://github.com/joeyballentine/ESRGAN-Bot/commit/82c06f7612f7781696185afb665d6c21e9249895

</document_content>
</document>
<document index="24">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/async_.py</source>
<document_content>
"""Asyncio utilities."""
# SOURCE: https://github.com/home-assistant/core/blob/5983fac5c213acab799339c7baec43cf4300f196/homeassistant/util/async_.py

from __future__ import annotations

from asyncio import Semaphore, coroutines, ensure_future, gather, get_running_loop
from asyncio.events import AbstractEventLoop
import concurrent.futures
import functools
import logging
import threading
import time
from traceback import extract_stack
from typing import Any, Awaitable, Callable, Coroutine, TypeVar

from codetiming import Timer

from cerebro_bot.bot_logger import get_logger

_LOGGER = get_logger(__name__, provider="Async Logger", level=logging.DEBUG)

_SHUTDOWN_RUN_CALLBACK_THREADSAFE = "_shutdown_run_callback_threadsafe"

T = TypeVar("T")


# https://stackoverflow.com/questions/33128325/how-to-set-class-attribute-with-await-in-init
class aobject:
    """Inheriting this class allows you to define an async __init__.

    So you can create objects by doing something like `await MyClass(params)`
    """

    async def __new__(cls, *a, **kw):
        instance = super().__new__(cls)
        await instance.__init__(*a, **kw)
        return instance

    async def __init__(self):
        pass


def fire_coroutine_threadsafe(coro: Coroutine, loop: AbstractEventLoop) -> None:
    """Submit a coroutine object to a given event loop.

    This method does not provide a way to retrieve the result and
    is intended for fire-and-forget use. This reduces the
    work involved to fire the function on the loop.
    """
    ident = loop.__dict__.get("_thread_ident")
    if ident is not None and ident == threading.get_ident():
        raise RuntimeError("Cannot be called from within the event loop")

    if not coroutines.iscoroutine(coro):
        raise TypeError(f"A coroutine object is required: {coro}")

    def callback() -> None:
        """Handle the firing of a coroutine."""
        ensure_future(coro, loop=loop)

    loop.call_soon_threadsafe(callback)


def run_callback_threadsafe(
    loop: AbstractEventLoop, callback: Callable[..., T], *args: Any
) -> concurrent.futures.Future[T]:  # pylint: disable=unsubscriptable-object
    """Submit a callback object to a given event loop.

    Return a concurrent.futures.Future to access the result.
    """
    ident = loop.__dict__.get("_thread_ident")
    if ident is not None and ident == threading.get_ident():
        raise RuntimeError("Cannot be called from within the event loop")

    future: concurrent.futures.Future = concurrent.futures.Future()

    def run_callback() -> None:
        """Run callback and store result."""
        try:
            future.set_result(callback(*args))
        except Exception as exc:  # pylint: disable=broad-except
            if future.set_running_or_notify_cancel():
                future.set_exception(exc)
            else:
                _LOGGER.warning("Exception on lost future: ", exc_info=True)

    loop.call_soon_threadsafe(run_callback)

    if hasattr(loop, _SHUTDOWN_RUN_CALLBACK_THREADSAFE):
        #
        # If the final `HomeAssistant.async_block_till_done` in
        # `HomeAssistant.async_stop` has already been called, the callback
        # will never run and, `future.result()` will block forever which
        # will prevent the thread running this code from shutting down which
        # will result in a deadlock when the main thread attempts to shutdown
        # the executor and `.join()` the thread running this code.
        #
        # To prevent this deadlock we do the following on shutdown:
        #
        # 1. Set the _SHUTDOWN_RUN_CALLBACK_THREADSAFE attr on this function
        #    by calling `shutdown_run_callback_threadsafe`
        # 2. Call `hass.async_block_till_done` at least once after shutdown
        #    to ensure all callbacks have run
        # 3. Raise an exception here to ensure `future.result()` can never be
        #    called and hit the deadlock since once `shutdown_run_callback_threadsafe`
        #    we cannot promise the callback will be executed.
        #
        raise RuntimeError("The event loop is in the process of shutting down.")

    return future


def check_loop() -> None:
    """Warn if called inside the event loop."""
    try:
        get_running_loop()
        in_loop = True
    except RuntimeError:
        in_loop = False

    if not in_loop:
        return

    found_frame = None

    for frame in reversed(extract_stack()):
        for path in ("custom_components/", "homeassistant/components/"):
            try:
                index = frame.filename.index(path)
                found_frame = frame
                break
            except ValueError:
                continue

        if found_frame is not None:
            break

    # Did not source from integration? Hard error.
    if found_frame is None:
        raise RuntimeError("Detected I/O inside the event loop. This is causing stability issues. Please report issue")

    start = index + len(path)
    end = found_frame.filename.index("/", start)

    integration = found_frame.filename[start:end]

    if path == "custom_components/":
        extra = " to the custom component author"
    else:
        extra = ""

    _LOGGER.warning(
        "Detected I/O inside the event loop. This is causing stability issues. Please report issue%s for %s doing I/O at %s, line %s: %s",
        extra,
        integration,
        found_frame.filename[index:],
        found_frame.lineno,
        found_frame.line.strip(),
    )
    raise RuntimeError(
        f"I/O must be done in the executor; Use `await hass.async_add_executor_job()` "
        f"at {found_frame.filename[index:]}, line {found_frame.lineno}: {found_frame.line.strip()}"
    )


def protect_loop(func: Callable) -> Callable:
    """Protect function from running in event loop."""

    @functools.wraps(func)
    def protected_loop_func(*args, **kwargs):  # type: ignore
        check_loop()
        return func(*args, **kwargs)

    return protected_loop_func


async def gather_with_concurrency(limit: int, *tasks: Any, return_exceptions: bool = False) -> Any:
    """Wrap asyncio.gather to limit the number of concurrent tasks.

    From: https://stackoverflow.com/a/61478547/9127614
    """
    semaphore = Semaphore(limit)

    async def sem_task(task: Awaitable[Any]) -> Any:
        async with semaphore:
            return await task

    return await gather(*(sem_task(task) for task in tasks), return_exceptions=return_exceptions)


def shutdown_run_callback_threadsafe(loop: AbstractEventLoop) -> None:
    """Call when run_callback_threadsafe should prevent creating new futures.

    We must finish all callbacks before the executor is shutdown
    or we can end up in a deadlock state where:

    `executor.result()` is waiting for its `._condition`
    and the executor shutdown is trying to `.join()` the
    executor thread.

    This function is considered irreversible and should only ever
    be called when Home Assistant is going to shutdown and
    python is going to exit.
    """
    setattr(loop, _SHUTDOWN_RUN_CALLBACK_THREADSAFE, True)


# SOURCE: https://livebook.manning.com/book/concurrency-in-python-with-asyncio/chapter-2/v-10/123
def async_timed():
    def wrapper(func: Callable) -> Callable:
        @functools.wraps(func)
        async def wrapped(*args, **kwargs) -> Any:
            print(f"starting {func} with args {args} {kwargs}")
            start = time.time()
            try:
                return await func(*args, **kwargs)
            finally:
                end = time.time()
                total = end - start
                print(f"finished {func} in {total:.4f} second(s)")

        return wrapped

    return wrapper


# Based on this originally, but modified to use Timer
# SOURCE: https://livebook.manning.com/book/concurrency-in-python-with-asyncio/chapter-2/v-10/123
def async_timer():
    def wrapper(func: Callable) -> Callable:
        @functools.wraps(func)
        async def wrapped(*args, **kwargs) -> Any:
            timer = Timer(text=f"Task {__name__} elapsed time: {{:.1f}}")
            print(f"starting {func} with args {args} {kwargs}")
            timer.start()
            try:
                return await func(*args, **kwargs)
            finally:
                timer.stop()

        return wrapped

    return wrapper

</document_content>
</document>
<document index="25">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/block.py</source>
<document_content>

</document_content>
</document>
<document index="26">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/chat_formatting.py</source>
<document_content>
"""cerebro_bot.utils.chat_formatting"""
import datetime
from io import BytesIO
import itertools
import textwrap
from typing import Iterator, List, Optional, Sequence, SupportsInt, Union

from babel.lists import format_list as babel_list
from babel.numbers import format_decimal
import discord


def error(text: str) -> str:
    """Get text prefixed with an error emoji.

    Parameters
    ----------
    text : str
        The text to be prefixed.

    Returns
    -------
    str
        The new message.

    """
    return f"\N{NO ENTRY SIGN} {text}"


def warning(text: str) -> str:
    """Get text prefixed with a warning emoji.

    Parameters
    ----------
    text : str
        The text to be prefixed.

    Returns
    -------
    str
        The new message.

    """
    return f"\N{WARNING SIGN}\N{VARIATION SELECTOR-16} {text}"


def info(text: str) -> str:
    """Get text prefixed with an info emoji.

    Parameters
    ----------
    text : str
        The text to be prefixed.

    Returns
    -------
    str
        The new message.

    """
    return f"\N{INFORMATION SOURCE}\N{VARIATION SELECTOR-16} {text}"


def success(text: str) -> str:
    """Get text prefixed with a success emoji.

    Parameters
    ----------
    text : str
        The text to be prefixed.

    Returns
    -------
    str
        The new message.

    """
    return f"\N{WHITE HEAVY CHECK MARK} {text}"


def question(text: str) -> str:
    """Get text prefixed with a question emoji.

    Parameters
    ----------
    text : str
        The text to be prefixed.

    Returns
    -------
    str
        The new message.

    """
    return f"\N{BLACK QUESTION MARK ORNAMENT}\N{VARIATION SELECTOR-16} {text}"


def bold(text: str, escape_formatting: bool = True) -> str:
    """Get the given text in bold.

    Note: By default, this function will escape ``text`` prior to emboldening.

    Parameters
    ----------
    text : str
        The text to be marked up.
    escape_formatting : `bool`, optional
        Set to :code:`False` to not escape markdown formatting in the text.

    Returns
    -------
    str
        The marked up text.

    """
    return f"**{escape(text, formatting=escape_formatting)}**"


def box(text: str, lang: str = "") -> str:
    """Get the given text in a code block.

    Parameters
    ----------
    text : str
        The text to be marked up.
    lang : `str`, optional
        The syntax highlighting language for the codeblock.

    Returns
    -------
    str
        The marked up text.

    """
    return f"```{lang}\n{text}\n```"


def inline(text: str) -> str:
    """Get the given text as inline code.

    Parameters
    ----------
    text : str
        The text to be marked up.

    Returns
    -------
    str
        The marked up text.

    """
    return f"``{text}``" if "`" in text else f"`{text}`"


def italics(text: str, escape_formatting: bool = True) -> str:
    """Get the given text in italics.

    Note: By default, this function will escape ``text`` prior to italicising.

    Parameters
    ----------
    text : str
        The text to be marked up.
    escape_formatting : `bool`, optional
        Set to :code:`False` to not escape markdown formatting in the text.

    Returns
    -------
    str
        The marked up text.

    """
    return f"*{escape(text, formatting=escape_formatting)}*"


def spoiler(text: str, escape_formatting: bool = True) -> str:
    """Get the given text as a spoiler.

    Note: By default, this function will escape ``text`` prior to making the text a spoiler.

    Parameters
    ----------
    text : str
        The text to be marked up.
    escape_formatting : `bool`, optional
        Set to :code:`False` to not escape markdown formatting in the text.

    Returns
    -------
    str
        The marked up text.

    """
    return f"||{escape(text, formatting=escape_formatting)}||"


def bordered(*columns: Sequence[str], ascii_border: bool = False) -> str:
    """Get two blocks of text inside borders.

    Note
    ----
    This will only work with a monospaced font.

    Parameters
    ----------
    *columns : `sequence` of `str`
        The columns of text, each being a list of lines in that column.
    ascii_border : bool
        Whether or not the border should be pure ASCII.

    Returns
    -------
    str
        The bordered text.

    """
    borders = {
        "TL": "+" if ascii_border else "",  # Top-left
        "TR": "+" if ascii_border else "",  # Top-right
        "BL": "+" if ascii_border else "",  # Bottom-left
        "BR": "+" if ascii_border else "",  # Bottom-right
        "HZ": "-" if ascii_border else "",  # Horizontal
        "VT": "|" if ascii_border else "",  # Vertical
    }

    sep = " " * 4  # Separator between boxes
    widths = tuple(max(len(row) for row in column) + 9 for column in columns)  # width of each col
    colsdone = [False] * len(columns)  # whether or not each column is done
    lines = [sep.join("{TL}" + "{HZ}" * width + "{TR}" for width in widths)]

    for line in itertools.zip_longest(*columns):
        row = []
        for colidx, column in enumerate(line):
            width = widths[colidx]
            done = colsdone[colidx]
            if column is None:
                if not done:
                    # bottom border of column
                    column = "{HZ}" * width
                    row.append("{BL}" + column + "{BR}")
                    colsdone[colidx] = True  # mark column as done
                else:
                    # leave empty
                    row.append(" " * (width + 2))
            else:
                column += " " * (width - len(column))  # append padded spaces
                row.append("{VT}" + column + "{VT}")

        lines.append(sep.join(row))

    final_row = []
    for width, done in zip(widths, colsdone):
        if not done:
            final_row.append("{BL}" + "{HZ}" * width + "{BR}")
        else:
            final_row.append(" " * (width + 2))
    lines.append(sep.join(final_row))

    return "\n".join(lines).format(**borders)


def pagify(
    text: str,
    delims: Sequence[str] = None,
    *,
    priority: bool = False,
    escape_mass_mentions: bool = True,
    shorten_by: int = 8,
    page_length: int = 2000,
) -> Iterator[str]:
    """Generate multiple pages from the given text.

    Note
    ----
    This does not respect code blocks or inline code.

    Parameters
    ----------
    text : str
        The content to pagify and send.
    delims : `sequence` of `str`, optional
        Characters where page breaks will occur. If no delimiters are found
        in a page, the page will break after ``page_length`` characters.
        By default this only contains the newline.

    Other Parameters
    ----------------
    priority : `bool`
        Set to :code:`True` to choose the page break delimiter based on the
        order of ``delims``. Otherwise, the page will always break at the
        last possible delimiter.
    escape_mass_mentions : `bool`
        If :code:`True`, any mass mentions (here or everyone) will be
        silenced.
    shorten_by : `int`
        How much to shorten each page by. Defaults to 8.
    page_length : `int`
        The maximum length of each page. Defaults to 2000.

    Yields
    ------
    `str`
        Pages of the given text.

    """
    if delims is None:
        delims = ["\n"]
    in_text = text
    page_length -= shorten_by
    while len(in_text) > page_length:
        this_page_len = page_length
        if escape_mass_mentions:
            this_page_len -= in_text.count("@here", 0, page_length) + in_text.count("@everyone", 0, page_length)
        closest_delim = (in_text.rfind(d, 1, this_page_len) for d in delims)
        if priority:
            closest_delim = next((x for x in closest_delim if x > 0), -1)
        else:
            closest_delim = max(closest_delim)
        closest_delim = closest_delim if closest_delim != -1 else this_page_len
        if escape_mass_mentions:
            to_send = escape(in_text[:closest_delim], mass_mentions=True)
        else:
            to_send = in_text[:closest_delim]
        if len(to_send.strip()) > 0:
            yield to_send
        in_text = in_text[closest_delim:]

    if len(in_text.strip()) > 0:
        if escape_mass_mentions:
            yield escape(in_text, mass_mentions=True)
        else:
            yield in_text


def strikethrough(text: str, escape_formatting: bool = True) -> str:
    """Get the given text with a strikethrough.

    Note: By default, this function will escape ``text`` prior to applying a strikethrough.

    Parameters
    ----------
    text : str
        The text to be marked up.
    escape_formatting : `bool`, optional
        Set to :code:`False` to not escape markdown formatting in the text.

    Returns
    -------
    str
        The marked up text.

    """
    return f"~~{escape(text, formatting=escape_formatting)}~~"


def underline(text: str, escape_formatting: bool = True) -> str:
    """Get the given text with an underline.

    Note: By default, this function will escape ``text`` prior to underlining.

    Parameters
    ----------
    text : str
        The text to be marked up.
    escape_formatting : `bool`, optional
        Set to :code:`False` to not escape markdown formatting in the text.

    Returns
    -------
    str
        The marked up text.

    """
    return f"__{escape(text, formatting=escape_formatting)}__"


def quote(text: str) -> str:
    """Quotes the given text.

    Parameters
    ----------
    text : str
        The text to be marked up.

    Returns
    -------
    str
        The marked up text.

    """
    return textwrap.indent(text, "> ", lambda l: True)


def escape(text: str, *, mass_mentions: bool = False, formatting: bool = False) -> str:
    """Get text with all mass mentions or markdown escaped.

    Parameters
    ----------
    text : str
        The text to be escaped.
    mass_mentions : `bool`, optional
        Set to :code:`True` to escape mass mentions in the text.
    formatting : `bool`, optional
        Set to :code:`True` to escape any markdown formatting in the text.

    Returns
    -------
    str
        The escaped text.

    """
    if mass_mentions:
        text = text.replace("@everyone", "@\u200beveryone")
        text = text.replace("@here", "@\u200bhere")
    if formatting:
        text = discord.utils.escape_markdown(text)
    return text


def humanize_list(items: Sequence[str], *, locale: Optional[str] = None, style: str = "standard") -> str:
    """Get comma-separated list, with the last element joined with *and*.

    Parameters
    ----------
    items : Sequence[str]
        The items of the list to join together.
    locale : Optional[str]
        The locale to convert, if not specified it defaults to the bot's locale.
    style : str
        The style to format the list with.

        Note: Not all styles are necessarily available in all locales,
        see documentation of `babel.lists.format_list` for more details.

        standard
            A typical 'and' list for arbitrary placeholders.
            eg. "January, February, and March"
        standard-short
             A short version of a 'and' list, suitable for use with short or
             abbreviated placeholder values.
             eg. "Jan., Feb., and Mar."
        or
            A typical 'or' list for arbitrary placeholders.
            eg. "January, February, or March"
        or-short
            A short version of an 'or' list.
            eg. "Jan., Feb., or Mar."
        unit
            A list suitable for wide units.
            eg. "3 feet, 7 inches"
        unit-short
            A list suitable for short units
            eg. "3 ft, 7 in"
        unit-narrow
            A list suitable for narrow units, where space on the screen is very limited.
            eg. "3 7"

    Raises
    ------
    ValueError
        The locale does not support the specified style.

    Examples
    --------
    .. testsetup::

        from cerebro_bot.core.utils.chat_formatting import humanize_list

    .. doctest::

        >>> humanize_list(['One', 'Two', 'Three'])
        'One, Two, and Three'
        >>> humanize_list(['One'])
        'One'
        >>> humanize_list(['omena', 'peruna', 'aplari'], style='or', locale='fi')
        'omena, peruna tai aplari'

    """

    return babel_list(items, style=style, locale="en-US")


def format_perms_list(perms: discord.Permissions) -> str:
    """Format a list of permission names.

    This will return a humanized list of the names of all enabled
    permissions in the provided `discord.Permissions` object.

    Parameters
    ----------
    perms : discord.Permissions
        The permissions object with the requested permissions to list
        enabled.

    Returns
    -------
    str
        The humanized list.

    """
    perm_names: List[str] = []
    for perm, value in perms:
        if value is True:
            perm_name = '"' + perm.replace("_", " ").title() + '"'
            perm_names.append(perm_name)
    return humanize_list(perm_names).replace("Guild", "Server")


def humanize_timedelta(
    *,
    timedelta: Optional[datetime.timedelta] = None,
    seconds: Optional[SupportsInt] = None,
) -> str:
    """
    Get a locale aware human timedelta representation.

    This works with either a timedelta object or a number of seconds.

    Fractional values will be omitted, and values less than 1 second
    an empty string.

    Parameters
    ----------
    timedelta: Optional[datetime.timedelta]
        A timedelta object
    seconds: Optional[SupportsInt]
        A number of seconds

    Returns
    -------
    str
        A locale aware representation of the timedelta or seconds.

    Raises
    ------
    ValueError
        The function was called with neither a number of seconds nor a timedelta object
    """

    try:
        obj = seconds if seconds is not None else timedelta.total_seconds()
    except AttributeError as e:
        raise ValueError("You must provide either a timedelta or a number of seconds") from e

    seconds = int(obj)
    periods = [
        (("year"), ("years"), 60 * 60 * 24 * 365),
        (("month"), ("months"), 60 * 60 * 24 * 30),
        (("day"), ("days"), 60 * 60 * 24),
        (("hour"), ("hours"), 60 * 60),
        (("minute"), ("minutes"), 60),
        (("second"), ("seconds"), 1),
    ]

    strings = []
    for period_name, plural_period_name, period_seconds in periods:
        if seconds >= period_seconds:
            period_value, seconds = divmod(seconds, period_seconds)
            if period_value == 0:
                continue
            unit = plural_period_name if period_value > 1 else period_name
            strings.append(f"{period_value} {unit}")

    return ", ".join(strings)


def humanize_number(val: Union[int, float], override_locale=None) -> str:
    """
    Convert an int or float to a str with digit separators based on bot locale

    Parameters
    ----------
    val : Union[int, float]
        The int/float to be formatted.
    override_locale: Optional[str]
        A value to override bot's regional format.

    Returns
    -------
    str
        locale aware formatted number.
    """
    return format_decimal(val, locale="en-US")


def text_to_file(
    text: str,
    filename: str = "file.txt",
    *,
    spoiler: bool = False,
    encoding: str = "utf-8",
):
    """Prepares text to be sent as a file on Discord, without character limit.

    This writes text into a bytes object that can be used for the ``file`` or ``files`` parameters
    of :meth:`discord.abc.Messageable.send`.

    Parameters
    ----------
    text: str
        The text to put in your file.
    filename: str
        The name of the file sent. Defaults to ``file.txt``.
    spoiler: bool
        Whether the attachment is a spoiler. Defaults to ``False``.

    Returns
    -------
    discord.File
        The file containing your text.

    """
    file = BytesIO(text.encode(encoding))
    return discord.File(file, filename, spoiler=spoiler)

</document_content>
</document>
<document index="27">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/config.py</source>
<document_content>
# from logging import DEBUG, ERROR, INFO, WARN
# import os

# from cerebro_bot import constants

# # from dotenv import load_dotenv


# # TEMPCHANGE: # DISCORD_TOKEN = os.environ.get("DISCORD_TOKEN")
# # TEMPCHANGE: # default_config = {"token": "", "prefix": constants.PREFIX}


# # DISCORD_TOKEN = os.environ.get('DISCORD_TOKEN')
# # LOG_LEVEL = get_log_level(os.environ.get('LOG_LEVEL'))
# # AUDIT_LOG_SEND_CHANNEL = os.environ.get('AUDIT_LOG_SEND_CHANNEL')
# AUDIT_LOG_SEND_CHANNEL = os.environ.get("AUDIT_LOG_SEND_CHANNEL")
# # IS_HEROKU = if_env(os.environ.get('IS_HEROKU'))
# # SAVE_FILE_MESSAGE = os.environ.get('SAVE_FILE_MESSAGE')
# # FIRST_REACTION_CHECK = if_env(os.environ.get('FIRST_REACTION_CHECK'))
# # SCRAPBOX_SID_AND_PROJECTNAME = os.environ.get('SCRAPBOX_SID_AND_PROJECTNAME')
# # COUNT_RANK_SETTING = num_env(os.environ.get('COUNT_RANK_SETTING'))
# # PURGE_TARGET_IS_ME_AND_BOT = if_env(os.environ.get('PURGE_TARGET_IS_ME_AND_BOT'))
# # OHGIRI_JSON_URL = os.environ.get('OHGIRI_JSON_URL')
# # REACTION_CHANNELER_PERMIT_WEBHOOK_ID = os.environ.get('REACTION_CHANNELER_PERMIT_WEBHOOK_ID')
# # WORDWOLF_JSON_URL = os.environ.get('WORDWOLF_JSON_URL')
# # NGWORD_GAME_JSON_URL = os.environ.get('NGWORD_GAME_JSON_URL')


# # SOURCE: discord-bot-heroku
# def if_env(str):
#     return str is not None and str.upper() == "TRUE"


# # SOURCE: discord-bot-heroku
# def get_log_level(str):
#     if str is None:
#         return WARN
#     upper_str = str.upper()
#     if upper_str == "DEBUG":
#         return DEBUG
#     elif upper_str == "INFO":
#         return INFO
#     elif upper_str == "ERROR":
#         return ERROR
#     else:
#         return WARN


# # SOURCE: discord-bot-heroku
# def num_env(param):
#     return 5 if str is None or not str(param).isdecimal() else int(param)


# class Config:
#     def __init__(self):
#         self.config = {
#             "token": DISCORD_TOKEN,
#             "prefix": constants.PREFIX,
#         }
#         self.prefix = self.config.get("prefix", default_config.get("prefix"))
#         self.token = self.config.get("token", default_config.get("token"))

</document_content>
</document>
<document index="28">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/devices.py</source>
<document_content>
# SOURCE: https://github.com/socialhourmobile/SD-hassan-ns/blob/3b6b266b17e0fd0a9b17374cd2afbf4c59b7c245/modules/devices.py
import argparse
import contextlib
from typing import Optional, Union

import torch

from cerebro_bot.core import errors

# from icecream import ic


# has_mps is only available in nightly pytorch (for now) and MasOS 12.3+.
# check `getattr` and try it for compatibility
def has_mps() -> bool:
    if not getattr(torch, "has_mps", False):
        return False
    try:
        torch.zeros(1).to(torch.device("mps"))
        return True
    except Exception:
        return False


def extract_device_id(args, name):
    return next((args[x + 1] for x in range(len(args)) if name in args[x]), None)


def get_optimal_device(args: argparse.Namespace):
    if torch.cuda.is_available():
        # from modules import shared
        device_id: Optional[Union[int, None]]
        device_id = args.gpu

        if device_id is None:
            return torch.device("cuda")

        cuda_device = f"cuda:{device_id}"
        return torch.device(cuda_device)
    return torch.device("mps") if has_mps() else cpu


def torch_gc():
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.ipc_collect()


def enable_tf32():
    if torch.cuda.is_available():
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True


errors.run(enable_tf32, "Enabling TF32")

cpu = torch.device("cpu")
device = device_interrogate = device_gfpgan = device_swinir = device_esrgan = device_scunet = device_codeformer = None
dtype = torch.float16
dtype_vae = torch.float16


def randn(seed: int, shape: int) -> torch.Tensor:
    # Pytorch currently doesn't handle setting randomness correctly when the metal backend is used.
    if device.type == "mps":
        generator = torch.Generator(device=cpu)
        generator.manual_seed(seed)
        return torch.randn(shape, generator=generator, device=cpu).to(device)
    torch.manual_seed(seed)
    return torch.randn(shape, device=device)


def randn_without_seed(shape: int):
    # Pytorch currently doesn't handle setting randomness correctly when the metal backend is used.
    if device.type == "mps":
        generator = torch.Generator(device=cpu)
        return torch.randn(shape, generator=generator, device=cpu).to(device)
    return torch.randn(shape, device=device)


# SOURCE: https://github.com/socialhourmobile/SD-hassan-ns/blob/3b6b266b17e0fd0a9b17374cd2afbf4c59b7c245/modules/shared.py#L42
def autocast(disable=False, precision: str = "autocast"):
    """_summary_

    Args:
        precision (str): Options include ["full", "autocast"]
        disable (bool, optional): _description_. Defaults to False.

    Returns:
        _type_: _description_
    """
    # from modules import shared

    if disable:
        return contextlib.nullcontext()

    if dtype == torch.float32 or precision == "full":
        return contextlib.nullcontext()

    return torch.autocast("cuda")


# MPS workaround for https://github.com/pytorch/pytorch/issues/79383
def mps_contiguous(input_tensor: torch.Tensor, device: torch.device):
    """Returns a contiguous in memory tensor containing the same data as self tensor. If self tensor is already in the specified memory format, this function returns the self tensor.

    Args:
        input_tensor (torch.Tensor): _description_
        device (torch.device): _description_

    Returns:
        _type_: _description_
    """
    return input_tensor.contiguous() if device.type == "mps" else input_tensor


def mps_contiguous_to(input_tensor: torch.Tensor, device: torch.device):
    return mps_contiguous(input_tensor, device).to(device)


def mps_check():
    # Check that MPS is available
    if torch.backends.mps.is_available():
        # ic(torch.has_mps)
        if torch.backends.mps.is_available():
            mps_device = torch.device("mps")
            x = torch.ones(1, device=mps_device)
            print(x)
        else:
            print("MPS device not found.")

        mps_device = torch.device("mps")

        # Create a Tensor directly on the mps device
        x = torch.ones(5, device=mps_device)
        # Or
        x = torch.ones(5, device="mps")

        # Any operation happens on the GPU
        x * 2

    elif not torch.backends.mps.is_built():
        print("MPS not available because the current PyTorch install was not " "built with MPS enabled.")
    else:
        print(
            "MPS not available because the current MacOS version is not 12.3+ "
            "and/or you do not have an MPS-enabled device on this machine."
        )


# SOURCE: https://github.com/pytorch/pytorch/issues/77988
def seed_everything(seed: int):
    # Ref: https://gist.github.com/ihoromi4/b681a9088f348942b01711f251e5f964
    import os
    import random

    import numpy as np
    import torch

    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True

</document_content>
</document>
<document index="29">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/discord_utils.py</source>
<document_content>
# pylint: disable=no-member
"""cerebro_bot.utils.discord_utils"""

from __future__ import annotations

import asyncio
import concurrent.futures
from enum import IntEnum
import functools
import logging
import os
import os.path
import pathlib
import sys
import tempfile
import time
from timeit import default_timer as timer
import traceback
import typing
from typing import Any, Dict, List, NewType, Optional

from PIL import Image
import aiohttp
from codetiming import Timer
import cv2
import discord
from discord.ext import commands
from discord.message import Message
from discord.user import User
import numpy as np
import rich
import torch
from torch import nn
import torchvision.transforms as transforms
import torchvision.transforms.functional as FT
import torchvision.transforms.functional as pytorch_transforms_functional
from tqdm.auto import tqdm
import uritools

from cerebro_bot import constants, shell
from cerebro_bot.bot_logger import get_logger
from cerebro_bot.factories import cmd_factory, guild_factory
from cerebro_bot.utils import aiodbx, file_functions
from cerebro_bot.utils.arch.ScreenCropNet import (
    ObjLocModel as ScreenCropNet_ObjLocModel,
)

if typing.TYPE_CHECKING:
    from cerebro_bot.bot import Cerebro

LOGGER = get_logger(__name__, provider="Discord Utils", level=logging.DEBUG)

IMG_SIZE_CUTOFF = 1080

TYPE_IMAGE_ARRAY = typing.Union[np.ndarray, typing.Any]

TYPE_SCALE = typing.Union[str, int]

CUDA_AVAILABLE = torch.cuda.is_available()  # True


class Dimensions(IntEnum):
    HEIGHT = 224
    WIDTH = 224


ImageNdarrayBGR = NewType("ImageBGR", np.ndarray)
ImageNdarrayHWC = NewType("ImageHWC", np.ndarray)
TensorCHW = NewType("TensorCHW", torch.Tensor)

OPENCV_GREEN = (0, 255, 0)
OPENCV_RED = (255, 0, 0)


def unlink_orig_image(images_filepath: str):
    # for orig_to_rm in images_filepaths:
    rich.print(f"deleting ... {images_filepath}")
    os.unlink(f"{images_filepath}")
    return images_filepath


def resize_image_and_bbox(
    image: torch.Tensor,
    boxes: torch.Tensor,
    dims=(300, 300),
    return_percent_coords=False,
    device: torch.device = None,
):
    """
    Resize image. For the SSD300, resize to (300, 300).
    Since percent/fractional coordinates are calculated for the bounding boxes (w.r.t image dimensions) in this process,
    you may choose to retain them.
    :param image: image, a PIL Image
    :param boxes: bounding boxes in boundary coordinates, a tensor of dimensions (n_objects, 4)
    :return: resized image, updated bounding box coordinates (or fractional coordinates, in which case they remain the same)
    """

    image_tensor_to_resize_height = image.shape[1]
    image_tensor_to_resize_width = image.shape[2]

    # Resize image
    new_image = FT.resize(image, dims)

    # Resize bounding boxes
    old_dims = (
        torch.FloatTensor(
            [
                image_tensor_to_resize_width,
                image_tensor_to_resize_height,
                image_tensor_to_resize_width,
                image_tensor_to_resize_height,
            ]
        )
        .unsqueeze(0)
        .to(device)
    )
    new_boxes = boxes / old_dims  # percent coordinates

    if not return_percent_coords:
        new_dims = torch.FloatTensor([dims[1], dims[0], dims[1], dims[0]]).unsqueeze(0).to(device)
        new_boxes = new_boxes * new_dims

    return new_image, new_boxes


# SOURCE: https://www.learnpytorch.io/09_pytorch_model_deployment/
# 1. Create a function to return a list of dictionaries with sample, truth label, prediction, prediction probability and prediction time
def pred_and_store(
    paths: List[pathlib.Path],
    model: torch.nn.Module,
    # transform: torchvision.transforms,
    # class_names: List[str],
    device: torch.device = "",
) -> List[Dict]:
    # 3. Loop through target paths
    for path in tqdm(paths):
        # 4. Create empty dictionary to store prediction information for each sample
        pred_dict = {"image_path": path}

        # 6. Start the prediction timer
        timer()

        targetSize = Dimensions.HEIGHT
        # 7. Open image path

        img: ImageNdarrayBGR  # type: ignore

        img_channel: int
        img_height: int
        img_width: int

        # import bpdb
        # bpdb.set_trace()

        img, img_channel, img_height, img_width = read_image_to_bgr(f"{paths[0]}")

        resized = cv2.resize(img, (targetSize, targetSize), interpolation=cv2.INTER_AREA)
        print(resized.shape)

        # normalize and change output to (c, h, w)
        resized_tensor: torch.Tensor = torch.from_numpy(resized).permute(2, 0, 1) / 255.0

        # 9. Prepare model for inference by sending it to target device and turning on eval() mode
        model.to(device)
        model.eval()

        with torch.inference_mode():
            # Convert to (bs, c, h, w)
            unsqueezed_tensor = resized_tensor.unsqueeze(0).to(device)

            # predict
            out_bbox: torch.Tensor = model(unsqueezed_tensor)

            # ic(out_bbox)

            xmin, ymin, xmax, ymax = out_bbox[0]
            pt1 = (int(xmin), int(ymin))
            pt2 = (int(xmax), int(ymax))

            starting_point = pt1
            end_point = pt2
            color = (255, 0, 0)
            thickness = 2

            # import bpdb
            # bpdb.set_trace()

            # img = image.astype("uint8")
            # generate the image with bounding box on it
            out_img = cv2.rectangle(
                unsqueezed_tensor.squeeze().permute(1, 2, 0).cpu().numpy().astype("uint8"),
                starting_point,
                end_point,
                color,
                thickness,
            )

            # TODO: Enable this?
            # if --display
            # plt.imshow(out_img)

            # NOTE: At this point we have our bounding box for the smaller image, lets figure out what the values would be for a larger image.
            # First setup variables we need
            # -------------------------------------------------------
            image_tensor_to_resize = resized_tensor
            resized_bboxes_tensor = out_bbox[0]
            resized_height = img_height
            resized_width = img_width
            resized_dims = (resized_height, resized_width)

            image_tensor_to_resize.shape[0]
            image_tensor_to_resize.shape[1]
            image_tensor_to_resize.shape[2]

            # perform fullsize transformation
            fullsize_image, fullsize_bboxes = resize_image_and_bbox(
                image_tensor_to_resize,
                resized_bboxes_tensor,
                dims=resized_dims,
                return_percent_coords=False,
                device=device,
            )

            # get fullsize bboxes
            (
                xmin_fullsize,
                ymin_fullsize,
                xmax_fullsize,
                ymax_fullsize,
            ) = fullsize_bboxes[0]

            (int(xmin_fullsize), int(ymin_fullsize))
            (int(xmax_fullsize), int(ymax_fullsize))

            color = OPENCV_RED
            thickness = 1

    print(fullsize_bboxes)

    return fullsize_bboxes


def get_pil_image_channels(image_path: str) -> int:
    """Open an image and get the number of channels it has.

    Args:
        image_path (str): _description_

    Returns:
        int: _description_
    """
    # load pillow image
    pil_img = Image.open(image_path)

    # Converts a PIL Image (H x W x C) to a Tensor of shape (C x H x W).
    pil_img_tensor = transforms.PILToTensor()(pil_img)

    return pil_img_tensor.shape[0]


def convert_pil_image_to_rgb_channels(image_path: str):
    """Convert Pil image to have the appropriate number of color channels

    Args:
        image_path (str): _description_

    Returns:
        _type_: _description_
    """
    return Image.open(image_path).convert("RGB") if get_pil_image_channels(image_path) != 4 else Image.open(image_path)


def read_image_to_bgr(image_path: str) -> ImageNdarrayBGR:  # type: ignore
    """Read the image from image id.

    returns ImageNdarrayBGR.

    Opencv returns ndarry in format = row (height) x column (width) x color (3)
    """

    # image = cv2.imread(image_path, cv2.IMREAD_COLOR)
    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)
    # image /= 255.0  # Normalize

    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    # import bpdb
    # bpdb.set_trace()
    # img_shape = image.shape
    img_channel = image.shape[2]
    img_height = image.shape[0]
    img_width = image.shape[1]
    return image, img_channel, img_height, img_width


def convert_image_from_hwc_to_chw(img: ImageNdarrayBGR) -> torch.Tensor:  # type: ignore
    img: torch.Tensor = torch.from_numpy(img).permute(2, 0, 1) / 255.0  # (h,w,c) -> (c,h,w)
    return img


# convert image back and forth if needed: https://stackoverflow.com/questions/68207510/how-to-use-torchvision-io-read-image-with-image-as-variable-not-stored-file
def convert_pil_image_to_torch_tensor(pil_image: Image) -> torch.Tensor:
    """Convert PIL image to pytorch tensor

    Args:
        pil_image (PIL.Image): _description_

    Returns:
        torch.Tensor: _description_
    """
    return pytorch_transforms_functional.to_tensor(pil_image)


# convert image back and forth if needed: https://stackoverflow.com/questions/68207510/how-to-use-torchvision-io-read-image-with-image-as-variable-not-stored-file
def convert_tensor_to_pil_image(tensor_image: torch.Tensor) -> Image:
    """Convert tensor image to Pillow object

    Args:
        tensor_image (torch.Tensor): _description_

    Returns:
        PIL.Image: _description_
    """
    return pytorch_transforms_functional.to_pil_image(tensor_image)


def predict_from_file(path_to_image_from_cli: str, model: torch.nn.Module, device: torch.device):
    """wrapper function to perform predictions on individual files

    Args:
        path_to_image_from_cli (str): eg.  "/Users/malcolm/Downloads/2020-11-25_10-47-32_867.jpeg
        model (torch.nn.Module): _description_
        transform (torchvision.transforms): _description_
        class_names (List[str]): _description_
        device (torch.device): _description_
        args (argparse.Namespace): _description_
    """
    # ic(f"Predict | individual file {path_to_image_from_cli} ...")
    image_path_api = pathlib.Path(path_to_image_from_cli).resolve()
    # ic(image_path_api)

    paths = [image_path_api]
    img = convert_pil_image_to_rgb_channels(f"{paths[0]}")

    bboxes = pred_and_store(paths, model, device=device)

    return img, bboxes


def get_pixel_rgb(image_pil: Image):
    """Get first pixel in image and return a humanreadable name of what color is represented

    Args:
        image_pil (Image): _description_

    Returns:
        _type_: _description_
    """
    r, g, b = image_pil.getpixel((1, 1))
    # ic(r,g,b)

    color = "white" if (r, g, b) == (255, 255, 255) else "darkmode"
    print(f"GOT COLOR {color} -- {r},{g},{b}")
    return color


def resize_and_pillarbox(image_pil: Image, width: int, height: int, background="white"):
    """
    Resize PIL image keeping ratio and using white background.
    """
    autodetect_background = get_pixel_rgb(image_pil)

    ratio_w = width / image_pil.width
    ratio_h = height / image_pil.height
    if ratio_w < ratio_h:
        # It must be fixed by width
        resize_width = width
        resize_height = round(ratio_w * image_pil.height)
    else:
        # Fixed by height
        resize_width = round(ratio_h * image_pil.width)
        resize_height = height
    image_resize = image_pil.resize((resize_width, resize_height), Image.Resampling.LANCZOS)
    if background and autodetect_background == "white":
        background = Image.new("RGBA", (width, height), (255, 255, 255, 255))
    elif background and autodetect_background == "darkmode":
        background = Image.new("RGBA", (width, height), (22, 32, 42, 1))
    offset = (round((width - resize_width) / 2), round((height - resize_height) / 2))
    background.paste(image_resize, offset)
    return background.convert("RGB")


def handle_autocrop(
    images_filepaths: List[str],
    cols=5,
    model=None,
    device=None,
    args=None,
    resize=False,
    predict_results=None,
):
    cropped_image_file_paths = []
    for i, image_filepath in enumerate(images_filepaths):
        image, bboxes = predict_results[i]
        # image, bboxes = predict_from_file(image_filepath, model, device)
        img_as_array = np.asarray(image)
        img_as_array = cv2.cvtColor(img_as_array, cv2.COLOR_RGB2BGR)

        # get fullsize bboxes
        xmin_fullsize, ymin_fullsize, xmax_fullsize, ymax_fullsize = bboxes[0]

        startY = int(ymin_fullsize)
        endY = int(ymax_fullsize)
        startX = int(xmin_fullsize)
        endX = int(xmax_fullsize)

        # roi = image[startY:endY, startX:endX]
        cropped_image = img_as_array[startY:endY, startX:endX]

        # import bpdb
        # bpdb.set_trace()

        image_path_api = pathlib.Path(image_filepath).resolve()
        fname = f"{image_path_api.parent}/cropped-{model.name}-{image_path_api.stem}{image_path_api.suffix}"

        # if f"{image_path_api.suffix}".lower() == ".png":
        #     cv2.imwrite(fname, cropped_image, [int(cv2.IMWRITE_PNG_COMPRESSION),5])
        # elif f"{image_path_api.suffix}".lower() == (".jpg" or ".jpeg"):
        #     cv2.imwrite(fname, cropped_image, [cv2.IMWRITE_JPEG_QUALITY , 80])
        cv2.imwrite(fname, cropped_image)

        cropped_full_path = file_functions.fix_path(fname)

        cropped_image_file_paths.append(cropped_full_path)

    return cropped_image_file_paths


def handle_autocrop_one(
    images_filepath: str,
    cols=5,
    model=None,
    device=None,
    args=None,
    resize=False,
    predict_results=None,
):
    # cropped_image_file_paths = []
    # for i, image_filepath in enumerate(images_filepaths):

    # import bpdb
    # bpdb.set_trace()

    image, bboxes = predict_results
    temp = image.copy()
    # image, bboxes = predict_from_file(image_filepath, model, device)
    img_as_array = np.asarray(temp)
    img_as_array = cv2.cvtColor(img_as_array, cv2.COLOR_RGB2BGR)

    # get fullsize bboxes
    xmin_fullsize, ymin_fullsize, xmax_fullsize, ymax_fullsize = bboxes[0]

    # if we have a negative point to make a rectange with, set it to 0
    startY = max(int(ymin_fullsize), 0)
    endY = max(int(ymax_fullsize), 0)
    startX = max(int(xmin_fullsize), 0)
    endX = max(int(xmax_fullsize), 0)

    rich.print(startY, endY, startX, endX)

    cropped_image = img_as_array[startY:endY, startX:endX]

    image_path_api = pathlib.Path(images_filepath).resolve()
    fname = f"{image_path_api.parent}/cropped-{model.name}-{image_path_api.stem}{image_path_api.suffix}"

    cv2.imwrite(fname, cropped_image)

    return file_functions.fix_path(fname)


def handle_resize(
    images_filepaths: List[str],
    cols=5,
    model=None,
    device=None,
    args=None,
    resize=False,
):
    resized_image_file_paths = []
    for i, image_filepath in enumerate(images_filepaths):
        image_path_api = pathlib.Path(image_filepath).resolve()
        fname = f"{image_path_api.parent}/cropped-{model.name}-{image_path_api.stem}{image_path_api.suffix}"

        cropped_full_path = file_functions.fix_path(fname)

        if resize:
            to_resize = Image.open(cropped_full_path).convert("RGB")
            resized_pil_image = resize_and_pillarbox(to_resize, 1080, 1350, background=resize)
            if f"{image_path_api.suffix}".lower() == ".png":
                # https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html
                resized_pil_image.save(fname, optimize=True, compress_level=9)
            elif f"{image_path_api.suffix}".lower() == (".jpg" or ".jpeg"):
                resized_pil_image.save(fname, quality="web_medium")

        resized_image_file_paths.append(cropped_full_path)

    return resized_image_file_paths


def handle_resize_one(
    images_filepath: str,
    cols=5,
    model=None,
    device=None,
    args=None,
    resize=False,
):
    image_path_api = pathlib.Path(images_filepath).resolve()
    fname = f"{image_path_api.parent}/cropped-{model.name}-{image_path_api.stem}{image_path_api.suffix}"

    cropped_full_path = file_functions.fix_path(fname)

    if resize:
        to_resize = Image.open(cropped_full_path).convert("RGB")
        resized_pil_image = resize_and_pillarbox(to_resize, 1080, 1350, background=resize)
        if f"{image_path_api.suffix}".lower() == ".png":
            # https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html
            resized_pil_image.save(fname, optimize=True, compress_level=9)
        elif f"{image_path_api.suffix}".lower() == (".jpg" or ".jpeg"):
            resized_pil_image.save(fname, quality="web_medium")

    return cropped_full_path


def handle_predict(
    images_filepaths: List[str],
    cols=5,
    model=None,
    device=None,
    args=None,
    resize=False,
):
    image_and_bboxes_list = []
    for image_filepath in images_filepaths:
        image, bboxes = predict_from_file(image_filepath, model, device)
        image_and_bboxes_list.append([image, bboxes])
    return image_and_bboxes_list


def handle_predict_one(
    images_filepath: str,
    cols=5,
    model=None,
    device=None,
    args=None,
    resize=False,
):
    assert cols
    # image_and_bboxes_list = []
    # for i, image_filepath in enumerate(images_filepaths):
    image, bboxes = predict_from_file(images_filepath, model, device)
    # image_and_bboxes_list.append()
    return image, bboxes


# NOTE: https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference
def load_model_for_inference(save_path: str, device: str) -> nn.Module:
    model = ScreenCropNet_ObjLocModel()
    model.name = "ObjLocModelV1"
    model.load_state_dict(torch.load(save_path, map_location=device))
    model.eval()
    print(f"Model loaded from path {save_path} successfully.")
    # Get the model size in bytes then convert to megabytes
    model_size = pathlib.Path(save_path).stat().st_size // (1024 * 1024)
    print(f"{save_path} | feature extractor model size: {model_size} MB")
    return model


# wrapper function of common code
def run_get_model_for_inference(
    model: torch.nn.Module,
    device: torch.device,
    path_to_model: pathlib.PosixPath,
) -> torch.nn.Module:
    """wrapper function to load model .pth file from disk

    Args:
        model (torch.nn.Module): _description_
        device (torch.device): _description_
        class_names (List[str]): _description_

    Returns:
        Tuple[pathlib.PosixPath, torch.nn.Module]: _description_
    """
    return load_model_for_inference(path_to_model, device)


def unique_list(
    list1: typing.Union[typing.List[str], typing.List[bytes]]
) -> typing.Union[typing.List[str], typing.List[bytes]]:
    # insert the list to the set
    list_set = set(list1)
    return list(list_set)


# https://github.com/discord-math/bot/blob/babb41b71a68b4b099684b3e1ed583f84083f971/plugins/log.py#L63
def path_for(attm: discord.Attachment, basedir: str = "./") -> pathlib.Path:
    p = pathlib.Path(basedir, str(attm.filename))
    LOGGER.debug(f"path_for: p -> {p}")
    return p


# https://github.com/discord-math/bot/blob/babb41b71a68b4b099684b3e1ed583f84083f971/plugins/log.py#L63
async def save_attachment(attm: discord.Attachment, basedir: str = "./") -> None:
    path = path_for(attm, basedir=basedir)
    LOGGER.debug(f"save_attachment: path -> {path}")
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        ret_code = await attm.save(path, use_cached=True)
        await asyncio.sleep(5)
    except discord.HTTPException:
        await attm.save(path)


# TODO: Remove this when we eventually upgrade to 2.0 discord.py
def attachment_to_dict(attm: discord.Attachment):
    result = {
        "filename": attm.filename,
        "id": attm.id,
        "proxy_url": attm.proxy_url,
        "size": attm.size,
        "url": attm.url,
        "spoiler": attm.is_spoiler(),
    }
    if attm.height:
        result["height"] = attm.height
    if attm.width:
        result["width"] = attm.width
    if attm.content_type:
        result["content_type"] = attm.content_type

    result["attachment_obj"] = attm

    return result


def file_to_local_data_dict(fname: str, dir_root: str):
    file_api = pathlib.Path(fname)
    return {
        "filename": f"{dir_root}/{file_api.stem}{file_api.suffix}",
        "size": file_api.stat().st_size,
        "ext": f"{file_api.suffix}",
        "api": file_api,
    }


async def handle_save_attachment_locally(attm_data_dict, dir_root):
    fname = f"{dir_root}/orig_{attm_data_dict['id']}_{attm_data_dict['filename']}"
    rich.print(f"Saving to ... {fname}")
    await attm_data_dict["attachment_obj"].save(fname, use_cached=True)
    await asyncio.sleep(1)
    return fname


async def expandURL(link: str):
    async with aiohttp.ClientSession() as session:
        async with session.head(link) as response:
            expanded = await response.getheader("location")
    return expanded


# SOURCE: https://www.programcreek.com/python/?project_name=athphane%2Fuserbot#
async def expand_url(url: str):
    async with aiohttp.ClientSession() as session:
        async with session.get(f"http://expandurl.com/api/v1/?url={url}") as resp:
            expanded = await resp.text()

        return expanded if expanded != "false" and expanded[:-1] != url else None


def unlink_orig_file(a_filepath: str):
    """_summary_

    Args:
        a_filepath (str): _description_

    Returns:
        _type_: _description_
    """
    # for orig_to_rm in media_filepaths:
    rich.print(f"deleting ... {a_filepath}")
    os.unlink(f"{a_filepath}")
    return a_filepath


def get_files_to_upload(tmpdirname: str) -> List[str]:
    """Get directory and iterate over files to upload

    Args:
        tmpdirname (str): _description_

    Returns:
        _type_: _description_
    """
    tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
    rich.print(tree_list)

    file_to_upload_list = [f"{p}" for p in tree_list]
    LOGGER.debug(f"get_files_to_upload -> file_to_upload_list = {file_to_upload_list}")
    rich.print(file_to_upload_list)

    file_to_upload = file_functions.filter_media(file_to_upload_list)

    LOGGER.debug(f"get_files_to_upload -> file_to_upload = {file_to_upload}")

    rich.print(file_to_upload)
    return file_to_upload


def run_tree(tmpdirname: str):
    """run_tree

    Args:
        tmpdirname (str): _description_

    Returns:
        _type_: _description_
    """

    # Now that we are finished processing, we can upload the files to discord

    tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
    rich.print("tree_list ->")
    rich.print(tree_list)

    file_to_upload_list = [f"{p}" for p in tree_list]
    LOGGER.debug(f"compress_video-> file_to_upload_list = {file_to_upload_list}")
    rich.print(file_to_upload_list)

    file_to_upload = file_functions.filter_media(file_to_upload_list)

    return file_to_upload


async def compress_video(tmpdirname: str, file_to_compress: str, bot: Any, ctx: Any) -> List[str]:
    """_summary_

    Args:
        tmpdirname (str): _description_
        file_to_compress (str): _description_
        bot (Any): _description_
        ctx (Any): _description_

    Returns:
        List[str]: _description_
    """
    if (pathlib.Path(f"{file_to_compress}").is_file()) and pathlib.Path(
        f"{file_to_compress}"
    ).suffix in file_functions.VIDEO_EXTENSIONS:

        msg_upload = await ctx.send(embed=discord.Embed(description=f"compressing file -> {file_to_compress}"))

        LOGGER.debug(f"compressing file -> {file_to_compress}")
        ######################################################
        # compress the file if it is too large
        ######################################################
        compress_command = [
            "compress-discord.sh",
            f"{file_to_compress}",
        ]

        try:

            _ = await shell._aio_run_process_and_communicate(compress_command, cwd=f"{tmpdirname}")

            LOGGER.debug(
                f"compress_video: new file size for {file_to_compress} = {pathlib.Path(file_to_compress).stat().st_size}"
            )

            ######################################################
            # nuke the uncompressed version
            ######################################################

            LOGGER.info(f"nuking uncompressed: {file_to_compress}")

            # nuke the originals
            unlink_func = functools.partial(unlink_orig_file, f"{file_to_compress}")

            # 2. Run in a custom thread pool:
            with concurrent.futures.ThreadPoolExecutor() as pool:
                unlink_result = await bot.loop.run_in_executor(pool, unlink_func)
                # rich.print(f"count: {count} - Unlink", unlink_result)

            # Nuke old message now that everything is done
            await msg_upload.delete()
        except Exception as ex:
            print(ex)
            exc_type, exc_value, exc_traceback = sys.exc_info()
            LOGGER.error(f"Error Class: {str(ex.__class__)}")
            output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
            LOGGER.warning(output)
            LOGGER.error(f"exc_type: {exc_type}")
            LOGGER.error(f"exc_value: {exc_value}")
            traceback.print_tb(exc_traceback)

        # # Now that we are finished processing, we can upload the files to discord

        # tree_list = file_functions.tree(pathlib.Path(f"{tmpdirname}"))
        # rich.print("tree_list ->")
        # rich.print(tree_list)

        # file_to_upload_list = [f"{p}" for p in tree_list]
        # LOGGER.debug(f"compress_video-> file_to_upload_list = {file_to_upload_list}")
        # rich.print(file_to_upload_list)

        # file_to_upload = file_functions.filter_media(file_to_upload_list)

        # return file_to_upload
    else:
        LOGGER.debug(f"no videos to process in {tmpdirname}")


async def details_from_file(path_to_media_from_cli: str, cwd: typing.Union[str, None] = None):
    """Take a file path and return the input and output file paths and the timestamp of the input file.

    Args:
        path_to_media_from_cli (str): _description_

    Returns:
        _type_: _description_
    """
    p = pathlib.Path(path_to_media_from_cli)
    full_path_input_file = f"{p.stem}{p.suffix}"
    full_path_output_file = f"{p.stem}_smaller.mp4"
    rich.print(full_path_input_file)
    rich.print(full_path_output_file)
    if sys.platform == "darwin":
        get_timestamp = await shell._aio_run_process_and_communicate(
            ["gstat", "-c", "%y", f"{p.stem}{p.suffix}"], cwd=cwd
        )
    elif sys.platform == "linux":
        get_timestamp = await shell._aio_run_process_and_communicate(
            ["stat", "-c", "%y", f"{p.stem}{p.suffix}"], cwd=cwd
        )

    return full_path_input_file, full_path_output_file, get_timestamp


# def unlink_orig_file(a_filepath: str):
#     """_summary_

#     Args:
#         a_filepath (str): _description_

#     Returns:
#         _type_: _description_
#     """
#     # for orig_to_rm in media_filepaths:
#     rich.print(f"deleting ... {a_filepath}")
#     os.unlink(f"{a_filepath}")
#     return a_filepath


# # https://github.com/discord-math/bot/blob/babb41b71a68b4b099684b3e1ed583f84083f971/plugins/log.py#L63
# def path_for(attm: discord.Attachment, basedir: str = "./") -> pathlib.Path:
#     p = pathlib.Path(basedir, str(attm.filename))
#     LOGGER.debug(f"path_for: p -> {p}")
#     return p


# # https://github.com/discord-math/bot/blob/babb41b71a68b4b099684b3e1ed583f84083f971/plugins/log.py#L63
# async def save_attachment(attm: discord.Attachment, basedir: str = "./") -> None:
#     path = path_for(attm, basedir=basedir)
#     LOGGER.debug(f"save_attachment: path -> {path}")
#     path.parent.mkdir(parents=True, exist_ok=True)
#     try:
#         ret_code = await attm.save(path, use_cached=True)
#         await asyncio.sleep(5)
#     except discord.HTTPException:
#         await attm.save(path)


# # TODO: Remove this when we eventually upgrade to 2.0 discord.py
# def attachment_to_dict(attm: discord.Attachment):
#     """Converts a discord.Attachment object to a dictionary.

#     Args:
#         attm (discord.Attachment): _description_

#     Returns:
#         _type_: _description_
#     """
#     result = {
#         "filename": attm.filename,
#         "id": attm.id,
#         "proxy_url": attm.proxy_url,
#         "size": attm.size,
#         "url": attm.url,
#         "spoiler": attm.is_spoiler(),
#     }
#     if attm.height:
#         result["height"] = attm.height
#     if attm.width:
#         result["width"] = attm.width
#     if attm.content_type:
#         result["content_type"] = attm.content_type

#     result["attachment_obj"] = attm

#     return result


# def file_to_local_data_dict(fname: str, dir_root: str):
#     """Convert a file to a dictionary.

#     Args:
#         fname (str): _description_
#         dir_root (str): _description_

#     Returns:
#         _type_: _description_
#     """
#     file_api = pathlib.Path(fname)
#     return {
#         "filename": f"{dir_root}/{file_api.stem}{file_api.suffix}",
#         "size": file_api.stat().st_size,
#         "ext": f"{file_api.suffix}",
#         "api": file_api,
#     }


# async def handle_save_attachment_locally(attm_data_dict, dir_root):
#     """Save an attachment locally.

#     Args:
#         attm_data_dict (_type_): _description_
#         dir_root (_type_): _description_

#     Returns:
#         _type_: _description_
#     """
#     fname = f"{dir_root}/orig_{attm_data_dict['id']}_{attm_data_dict['filename']}"
#     rich.print(f"Saving to ... {fname}")
#     await attm_data_dict["attachment_obj"].save(fname, use_cached=True)
#     await asyncio.sleep(1)
#     return fname

</document_content>
</document>
<document index="30">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/dropbox_.py</source>
<document_content>
"""cerebro_bot.utils.dropbox_"""
# type: ignore
# pylint: disable=unused-import
from collections import defaultdict
import contextlib
import datetime
import logging
import os
import pathlib
import sys
import time
import traceback
from typing import Union
import unicodedata

import aiofiles
import dropbox
from dropbox import DropboxOAuth2FlowNoRedirect, create_session
from dropbox.dropbox_client import BadInputException
from dropbox.exceptions import ApiError, AuthError
from dropbox.files import WriteMode
from pydantic import BaseSettings, Field
import requests
import rich
import six

from cerebro_bot.aio_settings import aiosettings
from cerebro_bot.bot_logger import get_logger

LOGGER = get_logger(__name__, provider="Dropbox", level=logging.DEBUG)

# TEMPCHANGE: # DROPBOX_CEREBRO_APP_KEY = os.environ.get("DROPBOX_CEREBRO_APP_KEY")
# TEMPCHANGE: # DROPBOX_CEREBRO_APP_SECRET = os.environ.get("DROPBOX_CEREBRO_APP_SECRET")
# TEMPCHANGE: #
# TEMPCHANGE: # DROPBOX_CEREBRO_TOKEN = os.environ.get("DROPBOX_CEREBRO_TOKEN")
# TEMPCHANGE: # DEFAULT_DROPBOX_FOLDER = "/cerebro_downloads"
# DEFAULT_DROPBOX_FOLDER = "/test_cerebro_downloads"
# LOCALFILE = 'data/croc.jpeg'
# BACKUPPATH = '/croc.jpeg'

# Establish connection
# autoflake --imports=dropbox,discord,unicodedata,six,uritools,cerebro_bot --in-place --remove-unused-variables cerebro_bot/utils/dropbox_.py
# NOTE: /Dropbox/Apps/cerebro_downloads


def get_dropbox_session() -> requests.Session:
    """_summary_

    Returns:
        requests.Session: _description_
    """
    return create_session()


# TEMPCHANGE: def get_dropbox_client(token=DROPBOX_CEREBRO_TOKEN) -> Union[dropbox.Dropbox, None]:
def get_dropbox_client(token=aiosettings.dropbox_cerebro_token) -> Union[dropbox.Dropbox, None]:
    dbx = None
    try:
        dbx = dropbox.Dropbox(token)
        dbx.users_get_current_account()
        print("Connected to Dropbox successfully")
    except BadInputException as ex:
        print(ex)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        LOGGER.error(f"Error Class: {str(ex.__class__)}")
        output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
        LOGGER.warning(output)
        LOGGER.error(f"exc_type: {exc_type}")
        LOGGER.error(f"exc_value: {exc_value}")
        traceback.print_tb(exc_traceback)
        raise
    except AuthError:
        sys.exit("ERROR: Invalid access token; try re-generating an " "access token from the app console on the web.")
    except Exception as e:
        print(e)

    # # Check that the access token is valid
    # try:
    #     dbx.users_get_current_account()
    # except AuthError:
    #     sys.exit(
    #         "ERROR: Invalid access token; try re-generating an "
    #         "access token from the app console on the web."
    #     )

    return dbx


def list_files_in_remote_folder(dbx: dropbox.Dropbox) -> None:
    # here dbx is an object which is obtained
    # by connecting to dropbox via token
    # dbx = get_dropbox_client()

    try:
        # TEMPCHANGE: # folder_path = DEFAULT_DROPBOX_FOLDER
        folder_path = aiosettings.default_dropbox_folder

        # dbx object contains all functions that
        # are required to perform actions with dropbox
        files = dbx.files_list_folder(folder_path, recursive=True).entries
        rich.print("------------Listing Files in Folder------------ ")

        for file in files:
            # listing
            rich.print(file.name)

    except Exception as ex:
        print(ex)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        LOGGER.error(f"Error Class: {str(ex.__class__)}")
        output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
        LOGGER.warning(output)
        LOGGER.error(f"exc_type: {exc_type}")
        LOGGER.error(f"exc_value: {exc_value}")
        traceback.print_tb(exc_traceback)
        raise


def download_img(dbx: dropbox.Dropbox, short_file_name: str) -> None:
    # here dbx is an object which is obtained
    # by connecting to dropbox via token
    # dbx = get_dropbox_client()

    try:
        with open(f"{short_file_name}", "wb") as f:
            # TEMPCHANGE: # metadata, res = dbx.files_download(path=f"{DEFAULT_DROPBOX_FOLDER}/{short_file_name}")
            metadata, res = dbx.files_download(path=f"{aiosettings.default_dropbox_folder}/{short_file_name}")
            f.write(res.content)

    except Exception as ex:
        print(ex)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        LOGGER.error(f"Error Class: {str(ex.__class__)}")
        output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
        LOGGER.warning(output)
        LOGGER.error(f"exc_type: {exc_type}")
        LOGGER.error(f"exc_value: {exc_value}")
        traceback.print_tb(exc_traceback)
        raise


@contextlib.contextmanager
def stopwatch(message: str):
    """Context manager to print how long a block of code took."""
    t0 = time.time()
    try:
        yield
    finally:
        t1 = time.time()
        print("Total elapsed time for %s: %.3f" % (message, t1 - t0))


# SOURCE: https://github.com/dropbox/dropbox-sdk-python/blob/master/example/updown.py
def list_folder(dbx: dropbox.Dropbox, folder, subfolder):
    """List a folder.

    Return a dict mapping unicode filenames to
    FileMetadata|FolderMetadata entries.
    """
    path = f'/{folder}/{subfolder.replace(os.path.sep, "/")}'
    while "//" in path:
        path = path.replace("//", "/")
    path = path.rstrip("/")
    try:
        with stopwatch("list_folder"):
            res = dbx.files_list_folder(path)
    except dropbox.exceptions.ApiError as err:
        print("Folder listing failed for", path, "-- assumed empty:", err)
        return {}
    else:
        return {entry.name: entry for entry in res.entries}


# SOURCE: https://github.com/dropbox/dropbox-sdk-python/blob/master/example/updown.py
def download(dbx, folder, subfolder, name):
    """Download a file.

    Return the bytes of the file, or None if it doesn't exist.
    """
    path = f'/{folder}/{subfolder.replace(os.path.sep, "/")}/{name}'
    while "//" in path:
        path = path.replace("//", "/")
    with stopwatch("download"):
        try:
            md, res = dbx.files_download(path)
        except dropbox.exceptions.HttpError as err:
            print("*** HTTP error", err)
            return None
    data = res.content
    print(len(data), "bytes; md:", md)
    return data


# SOURCE: https://github.com/dropbox/dropbox-sdk-python/blob/master/example/updown.py
def upload(dbx, fullname, folder, subfolder, name, overwrite=False):
    """Upload a file.

    Return the request response, or None in case of error.
    """
    path = f'/{folder}/{subfolder.replace(os.path.sep, "/")}/{name}'
    while "//" in path:
        path = path.replace("//", "/")
    mode = dropbox.files.WriteMode.overwrite if overwrite else dropbox.files.WriteMode.add
    mtime = os.path.getmtime(fullname)
    with open(fullname, "rb") as f:
        data = f.read()
    with stopwatch("upload %d bytes" % len(data)):
        try:
            res = dbx.files_upload(
                data,
                path,
                mode,
                client_modified=datetime.datetime(*time.gmtime(mtime)[:6]),
                mute=True,
            )
        except dropbox.exceptions.ApiError as err:
            print("*** API error", err)
            return None
    print("uploaded as", res.name.encode("utf8"))
    return res


# SOURCE: https://github.com/dropbox/dropbox-sdk-python/blob/master/example/updown.py
def iter_dir_and_upload(dbx: dropbox.Dropbox, remote_folder: str, local_folder: str):
    """Parse command line, then iterate over files and directories under
    rootdir and upload all files.  Skips some temporary files and
    directories, and avoids duplicate uploads by comparing size and
    mtime with the server.

    Args:
        dbx (dropbox.Dropbox): Dropbox client
        folder (str): Folder name in your Dropbox. Eg. "/20211127"
        local_folder (str): Local directory to upload. EG. "~/Downloads/dropbox_test"
    """

    folder = remote_folder
    rootdir = os.path.expanduser(local_folder)
    rich.print("Dropbox folder name:", folder)
    rich.print("Local directory:", rootdir)
    if not os.path.exists(rootdir):
        rich.print(rootdir, "does not exist on your filesystem")
        sys.exit(1)
    elif not os.path.isdir(rootdir):
        rich.print(rootdir, "is not a folder on your filesystem")
        sys.exit(1)

    for dn, dirs, files in os.walk(rootdir):
        rich.print(f" dn = {dn}")
        rich.print(f" dirs = {dirs}")
        rich.print(f" files = {files}")
        subfolder = dn[len(rootdir) :].strip(os.path.sep)
        listing = list_folder(dbx, folder, subfolder)
        rich.print("Descending into", subfolder, "...")

        # First do all the files.
        for name in files:
            fullname = os.path.join(dn, name)
            if not isinstance(name, six.text_type):
                name = name.decode("utf-8")
            nname = unicodedata.normalize("NFC", name)
            if name.startswith("."):
                rich.print("Skipping dot file:", name)
            elif name.startswith("@") or name.endswith("~"):
                rich.print("Skipping temporary file:", name)
            elif name.endswith(".pyc") or name.endswith(".pyo"):
                rich.print("Skipping generated file:", name)
            elif nname in listing:
                md = listing[nname]
                mtime = os.path.getmtime(fullname)
                mtime_dt = datetime.datetime(*time.gmtime(mtime)[:6])
                size = os.path.getsize(fullname)
                if isinstance(md, dropbox.files.FileMetadata) and mtime_dt == md.client_modified and size == md.size:
                    rich.print(name, "is already synced [stats match]")
                else:
                    rich.print(name, "exists with different stats, downloading")
                    res = download(dbx, folder, subfolder, name)
                    data = pathlib.Path(fullname).read_text()
                    if res == data:
                        rich.print(name, "is already synced [content match]")
                    else:
                        rich.print(name, "has changed since last sync")
                        rich.print(
                            f"upload(dbx, fullname, folder, subfolder, name, overwrite=True) -> upload({dbx}, {fullname}, {folder}, {subfolder}, {name}, overwrite=True)"
                        )
                        # TODO: Re-enable this # upload(dbx, fullname, folder, subfolder, name, overwrite=True)
                    # elif yesno('Upload %s' % name, True, args):
                    #     upload(dbx, fullname, folder, subfolder, name)

        # Then choose which subdirectories to traverse.
        keep = []
        for name in dirs:
            if name.startswith("."):
                rich.print("Skipping dot directory:", name)
            elif name.startswith("@") or name.endswith("~"):
                rich.print("Skipping temporary directory:", name)
            elif name == "__pycache__":
                rich.print("Skipping generated directory:", name)
            # elif yesno('Descend into %s' % name, True, args):
            #     rich.print('Keeping directory:', name)
            #     keep.append(name)
            else:
                # rich.print('OK, skipping directory:', name)
                rich.print("Keeping directory:", name)
                keep.append(name)
        # override and replace list with slice
        dirs[:] = keep

    # dbx.close()


async def co_upload_to_dropbox(dbx: dropbox.Dropbox, path_to_local_file: str, path_to_remote_dir: str = "/"):
    localfile_pathobj = pathlib.Path(f"{path_to_local_file}").absolute()
    try:
        assert localfile_pathobj.exists()
        assert localfile_pathobj.is_file()
    except Exception as ex:
        print(ex)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        LOGGER.error(f"Error Class: {str(ex.__class__)}")
        output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
        LOGGER.warning(output)
        LOGGER.error(f"exc_type: {exc_type}")
        LOGGER.error(f"exc_value: {exc_value}")
        traceback.print_tb(exc_traceback)
        raise

    _localfile = f"{localfile_pathobj}"
    _backuppath = f"{path_to_remote_dir}/{path_to_local_file}"

    async with aiofiles.open(_localfile, mode="rb") as f:
        rich.print(f"Uploading {_localfile} to Dropbox as {_backuppath}...")
        try:
            contents = await f.read()
            dbx.files_upload(contents, _backuppath, mode=WriteMode("overwrite"))
        except ApiError as err:
            # This checks for the specific error where a user doesn't have
            # enough Dropbox space quota to upload this file
            if err.error.is_path() and err.error.get_path().reason.is_insufficient_space():
                sys.exit("ERROR: Cannot back up; insufficient space.")
            elif err.user_message_text:
                rich.print(err.user_message_text)
                sys.exit()
            else:
                rich.print(err)
                sys.exit()

    # with open(_localfile, "rb") as f:
    #     # We use WriteMode=overwrite to make sure that the settings in the file
    #     # are changed on upload
    #     rich.print("Uploading " + _localfile + " to Dropbox as " + _backuppath + "...")
    #     try:
    #         dbx.files_upload(f.read(), _backuppath, mode=WriteMode("overwrite"))
    #     except ApiError as err:
    #         # This checks for the specific error where a user doesn't have
    #         # enough Dropbox space quota to upload this file
    #         if (
    #             err.error.is_path()
    #             and err.error.get_path().reason.is_insufficient_space()
    #         ):
    #             sys.exit("ERROR: Cannot back up; insufficient space.")
    #         elif err.user_message_text:
    #             rich.print(err.user_message_text)
    #             sys.exit()
    #         else:
    #             rich.print(err)
    #             sys.exit()


def upload_to_dropbox(dbx: dropbox.Dropbox, path_to_local_file: str, path_to_remote_dir: str = "/"):
    localfile_pathobj = pathlib.Path(f"{path_to_local_file}").absolute()
    try:
        assert localfile_pathobj.exists()
        assert localfile_pathobj.is_file()
    except Exception as ex:
        print(ex)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        LOGGER.error(f"Error Class: {str(ex.__class__)}")
        output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
        LOGGER.warning(output)
        LOGGER.error(f"exc_type: {exc_type}")
        LOGGER.error(f"exc_value: {exc_value}")
        traceback.print_tb(exc_traceback)
        raise

    _localfile = f"{localfile_pathobj}"
    _backuppath = f"{path_to_remote_dir}/{path_to_local_file}"

    with open(_localfile, "rb") as f:
        # We use WriteMode=overwrite to make sure that the settings in the file
        # are changed on upload
        rich.print(f"Uploading {_localfile} to Dropbox as {_backuppath}...")
        try:
            dbx.files_upload(f.read(), _backuppath, mode=WriteMode("overwrite"))
        except ApiError as err:
            # This checks for the specific error where a user doesn't have
            # enough Dropbox space quota to upload this file
            if err.error.is_path() and err.error.get_path().reason.is_insufficient_space():
                sys.exit("ERROR: Cannot back up; insufficient space.")
            elif err.user_message_text:
                rich.print(err.user_message_text)
                sys.exit()
            else:
                rich.print(err)
                sys.exit()


def select_revision(dbx: dropbox.Dropbox, filename: str = "", path_to_remote_file_or_dir: str = "/"):
    # _localfile = f"{localfile_pathobj}"
    if filename:
        _backuppath = f"{path_to_remote_file_or_dir}/{filename}"
    else:
        _backuppath = f"{path_to_remote_file_or_dir}/"
    # Get the revisions for a file (and sort by the datetime object, "server_modified")
    rich.print("Finding available revisions on Dropbox...")
    entries = dbx.files_list_revisions(_backuppath, limit=30).entries
    revisions = sorted(entries, key=lambda entry: entry.server_modified)

    for revision in revisions:
        rich.print(revision.rev, revision.server_modified)

    # Return the oldest revision (first entry, because revisions was sorted oldest:newest)
    return revisions[0].rev


def cli_oauth():
    """
    This example walks through a basic oauth flow using the existing long-lived token type
    Populate your app key and app secret in order to run this locally
    """

    # TEMPCHANGE: # auth_flow = DropboxOAuth2FlowNoRedirect(DROPBOX_CEREBRO_APP_KEY, DROPBOX_CEREBRO_APP_SECRET)
    auth_flow = DropboxOAuth2FlowNoRedirect(aiosettings.dropbox_cerebro_app_key, aiosettings.dropbox_cerebro_app_secret)

    authorize_url = auth_flow.start()
    print(f"1. Go to: {authorize_url}")
    print('2. Click "Allow" (you might have to log in first).')
    print("3. Copy the authorization code.")
    auth_code = input("Enter the authorization code here: ").strip()

    try:
        oauth_result = auth_flow.finish(auth_code)
    except Exception as e:
        print(f"Error: {e}")
        exit(1)

    with dropbox.Dropbox(oauth2_access_token=oauth_result.access_token) as dbx:
        dbx.users_get_current_account()
        rich.print("Successfully set up client!")


# SOURCE: https://github.com/MadeByMads/fastapi-cloud-drives/blob/a245bb62c1c41f592549e2cfb7121a667003b41b/docs/dropbox.md
class DropBoxConfig(BaseSettings):
    DROPBOX_ACCESS_TOKEN: str = Field(None, env="DROPBOX_CEREBRO_TOKEN")
    APP_KEY: str = Field(..., env="DROPBOX_CEREBRO_APP_KEY")
    APP_SECRET: str = Field(..., env="DROPBOX_CEREBRO_APP_SECRET")
    DROPBOX_REFRESH_TOKEN: str = Field(None, env="DROPBOX_REFRESH_TOKEN")

    class Config:
        case_sensitive = True


class AsyncDropBox:
    # SOURCE: https://github.com/MadeByMads/fastapi-cloud-drives/blob/a245bb62c1c41f592549e2cfb7121a667003b41b/fastapi_cloud_drives/fastapi_dropbox.py#L8

    def __init__(self, conf):
        self.DROPBOX_ACCESS_TOKEN = conf.DROPBOX_ACCESS_TOKEN
        self.APP_KEY = conf.APP_KEY
        self.APP_SECRET = conf.APP_SECRET
        self.DROPBOX_REFRESH_TOKEN = conf.DROPBOX_REFRESH_TOKEN

        self.client = self.auth()

    async def __aenter__(self):
        return self

    async def __aexit__(self, *args):
        self.client.close()

    def auth(self):
        """
        Authentication done via OAuth2
        You can generate tken for yourself in the App Console.
        See <https://blogs.dropbox.com/developers/2014/05/generate-an-access-token-for-your-own-account/>
        Authentication step  initially it is done with ACCESS_TOKEN, as it is short lived it will expire soon. Therefore better to have Refresh token
        """

        return (
            dropbox.Dropbox(
                oauth2_access_token=self.DROPBOX_ACCESS_TOKEN,
                oauth2_refresh_token=self.DROPBOX_REFRESH_TOKEN,
                app_key=self.APP_KEY,
                app_secret=self.APP_SECRET,
            )
            if self.DROPBOX_REFRESH_TOKEN
            else dropbox.Dropbox(self.DROPBOX_ACCESS_TOKEN)
        )

    async def account_info(self):
        """
        Account information of the current user
        """

        temp = defaultdict(dict)

        result = self.client.users_get_current_account()

        temp["abbreviated_name"] = result.name.abbreviated_name
        temp["display_name"] = result.name.display_name
        temp["familiar_name"] = result.name.familiar_name
        temp["given_name"] = result.name.given_name
        temp["surname"] = result.name.surname

        temp["account_id"] = result.account_id
        temp["country"] = result.country
        temp["disabled"] = result.disabled
        temp["email"] = result.email
        temp["email_verified"] = result.email_verified
        temp["is_paired"] = result.is_paired
        temp["locale"] = result.locale

        temp["profile_photo_url"] = result.profile_photo_url
        temp["referral_link"] = result.referral_link
        temp["team"] = result.team
        temp["team_member_id"] = result.team_member_id
        return temp

    async def list_files(
        self,
        path,
        recursive=False,
        include_media_info=False,
        include_deleted=False,
        include_has_explicit_shared_members=False,
        include_mounted_folders=True,
        limit=None,
        shared_link=None,
        include_property_groups=None,
        include_non_downloadable_files=True,
    ):
        """
        path:
        recursive:
        include_media_info:
        include_deleted:
        include_has_explicit_shared_members:
        include_mounted_folders:
        limit:
        shared_link:
        include_property_groups:
        include_non_downloadable_files:
        """

        response = self.client.files_list_folder(
            path=path,
            recursive=recursive,
            include_media_info=include_media_info,
            include_deleted=include_deleted,
            include_has_explicit_shared_members=include_has_explicit_shared_members,
            include_mounted_folders=include_mounted_folders,
            limit=limit,
            shared_link=shared_link,
            include_property_groups=include_property_groups,
            include_non_downloadable_files=include_non_downloadable_files,
        )
        temp = {}

        try:
            for file in response.entries:
                link = self.client.sharing_create_shared_link(file.path_display)

                path = link.url.replace("0", "1")
                temp[file.path_display] = path

            return temp

        except Exception as er:
            print(er)

    async def upload_file(self, file_from, file_to):
        with open(file_from, "rb") as f:
            self.client.files_upload(f.read(), file_to, mode=WriteMode("overwrite"))

    async def save_file_localy(self, file_path, filename):
        metadata, res = self.client.files_download(file_path + filename)

        with open(metadata.name, "wb") as f:
            f.write(res.content)

    async def get_link_of_file(self, file_path, filename, dowload=False):
        path = self.client.sharing_create_shared_link(file_path + filename)
        if dowload:
            path = path.url.replace("0", "1")

        return {"file": path.url}


async def co_upload_to_dropbox2(path_to_local_file: str, path_to_remote_dir: str = "/"):
    localfile_pathobj = pathlib.Path(f"{path_to_local_file}").absolute()
    try:
        assert localfile_pathobj.exists()
        assert localfile_pathobj.is_file()
    except Exception as ex:
        print(ex)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        LOGGER.error(f"Error Class: {str(ex.__class__)}")
        output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
        LOGGER.warning(output)
        LOGGER.error(f"exc_type: {exc_type}")
        LOGGER.error(f"exc_value: {exc_value}")
        traceback.print_tb(exc_traceback)
        raise

    _localfile = f"{localfile_pathobj}"
    _backuppath = f"{path_to_remote_dir}/{path_to_local_file}"

    dbxconf = DropBoxConfig()
    try:
        async with AsyncDropBox(dbxconf) as drop:
            await drop.upload_file(file_from=_localfile, file_to=_backuppath)
    except ApiError as err:
        # This checks for the specific error where a user doesn't have
        # enough Dropbox space quota to upload this file
        if err.error.is_path() and err.error.get_path().reason.is_insufficient_space():
            sys.exit("ERROR: Cannot back up; insufficient space.")
        elif err.user_message_text:
            rich.print(err.user_message_text)
            sys.exit()
        else:
            rich.print(err)
            sys.exit()

</document_content>
</document>
<document index="31">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/duration_str.py</source>
<document_content>
"""cerebro_bot.utils.duration_str"""
# Copyright 2022 Cisco Systems, Inc. and/or its affiliates.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Adapted from durationpy
# https://github.com/icholy/durationpy/

from datetime import timedelta
import re
from typing import Optional

_nanosecond_size = 1
_microsecond_size = 1000 * _nanosecond_size
_millisecond_size = 1000 * _microsecond_size
_second_size = 1000 * _millisecond_size
_minute_size = 60 * _second_size
_hour_size = 60 * _minute_size
_day_size = 24 * _hour_size
_week_size = 7 * _day_size
_month_size = 30 * _day_size
_year_size = 365 * _day_size

units = {
    "ns": _nanosecond_size,
    "us": _microsecond_size,
    "s": _microsecond_size,
    "s": _microsecond_size,
    "ms": _millisecond_size,
    "s": _second_size,
    "m": _minute_size,
    "h": _hour_size,
    "d": _day_size,
    "w": _week_size,
    "mm": _month_size,
    "y": _year_size,
}


def microseconds_from_duration_str(duration: str) -> float:
    """
    Parse a duration string into a microseconds float value.
    """
    if duration in ("0", "+0", "-0"):
        return 0

    pattern = re.compile(r"([\d\.]+)([a-z]+)")
    matches = pattern.findall(duration)
    if not len(matches):
        raise ValueError(f"Invalid duration '{duration}'")

    total: float = 0
    sign = -1 if duration[0] == "-" else 1

    for value, unit in matches:
        if unit not in units:
            raise ValueError(f"Unknown unit '{unit}' in duration '{duration}'")
        try:
            total += float(value) * units[unit]
        except Exception:
            raise ValueError(f"Invalid value '{value}' in duration '{duration}'")

    return sign * (total / _microsecond_size)


def timedelta_from_duration_str(duration: str) -> timedelta:
    """
    Parse a Golang duration string into a Python timedelta value.

    Raises a ValueError if the string cannot be parsed.

    A duration string is a possibly signed sequence of decimal numbers,
    each with optional fraction and a unit suffix, such as "300ms", "-1.5h" or "2h45m".

    Valid units are :
        ns - nanoseconds
        us - microseconds
        ms - millisecond
        s  - second
        m  - minute
        h  - hour
        w  - week
        mm - month
        y  - year
    """
    return timedelta(microseconds=microseconds_from_duration_str(duration))


def timedelta_to_duration_str(delta: timedelta, extended: bool = False) -> str:
    """
    Return a Golang duration string representation of a timedelta value.

    A duration string is a possibly signed sequence of decimal numbers,
    each with optional fraction and a unit suffix, such as "300ms", "-1.5h" or "2h45m".

    Components of the returned string are:
        ns - nanoseconds
        us - microseconds
        ms - millisecond
        s  - second
        m  - minute
        h  - hour
        w  - week
        mm - month
        y  - year
    """

    total_seconds = delta.total_seconds()
    sign = "-" if total_seconds < 0 else ""
    nanoseconds = abs(total_seconds * _second_size)

    if total_seconds < 1:
        result_str = _to_str_small(nanoseconds, extended)
    else:
        result_str = _to_str_large(nanoseconds, extended)

    return f"{sign}{result_str}"


def _to_str_small(nanoseconds: Optional[float], extended: bool = False) -> str:
    result_str = ""

    if not nanoseconds:
        return "0"

    milliseconds = int(nanoseconds / _millisecond_size)
    if milliseconds:
        nanoseconds -= _millisecond_size * milliseconds
        result_str += "{:g}ms".format(milliseconds)

    microseconds = int(nanoseconds / _microsecond_size)
    if microseconds:
        nanoseconds -= _microsecond_size * microseconds
        result_str += "{:g}us".format(microseconds)

    if nanoseconds:
        result_str += "{:g}ns".format(nanoseconds)

    return result_str


def _to_str_large(nanoseconds: float, extended: bool = False) -> str:
    result_str = ""

    if extended:
        years = int(nanoseconds / _year_size)
        if years:
            nanoseconds -= _year_size * years
            result_str += "{:g}y".format(years)

        months = int(nanoseconds / _month_size)
        if months:
            nanoseconds -= _month_size * months
            result_str += "{:g}mm".format(months)

        days = int(nanoseconds / _day_size)
        if days:
            nanoseconds -= _day_size * days
            result_str += "{:g}d".format(days)

    hours = int(nanoseconds / _hour_size)
    if hours:
        nanoseconds -= _hour_size * hours
        result_str += "{:g}h".format(hours)

    minutes = int(nanoseconds / _minute_size)
    if minutes:
        nanoseconds -= _minute_size * minutes
        result_str += "{:g}m".format(minutes)

    seconds = float(nanoseconds) / float(_second_size)
    if seconds:
        nanoseconds -= _second_size * seconds
        result_str += "{:g}s".format(seconds)

    return result_str

</document_content>
</document>
<document index="32">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/env.py</source>
<document_content>
import os


def environ_get(key, default=None):
    retval = os.environ.get(key, default=default)

    if key not in os.environ:
        print(f"environ_get: Env Var not defined! Using default! Attempted={key}, default={default}")

    return retval


def environ_append(key, value, separator=" ", force=False):
    old_value = os.environ.get(key)
    if old_value is not None:
        value = old_value + separator + value
    os.environ[key] = value


def environ_prepend(key, value, separator=" ", force=False):
    old_value = os.environ.get(key)
    if old_value is not None:
        value = value + separator + old_value
    os.environ[key] = value


def environ_remove(key, value, separator=":", force=False):
    old_value = os.environ.get(key)
    if old_value is not None:
        old_value_split = old_value.split(separator)
        value_split = [x for x in old_value_split if x != value]
        value = separator.join(value_split)
    os.environ[key] = value


def environ_set(key, value):
    os.environ[key] = value


def path_append(value):
    if os.path.exists(value):
        environ_append("PATH", value, ":")


def path_prepend(value, force=False):
    if os.path.exists(value):
        environ_prepend("PATH", value, ":", force)

</document_content>
</document>
<document index="33">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/events.py</source>
<document_content>
"""cerebro_bot.utils.events"""
import logging
import pathlib
import sys
import traceback

import discord
from discord.ext.commands.context import Context
import rich

from cerebro_bot import downloader
from cerebro_bot.bot_logger import get_logger
from cerebro_bot.factories import cmd_factory
from cerebro_bot.utils.file_functions import (
    get_all_media_files_to_upload,
    glob_file_by_extension,
    run_aio_json_loads,
)

# DISCORD_GUILD = os.environ.get("DISCORD_SERVER_ID")

LOGGER = get_logger(__name__, provider="Events", level=logging.DEBUG)


def css_syntax_highlight(text: str):
    return f"```css\n{text}\n```"


def ig_type(typename: str):
    """Take instagram metadata payload typenames and convert them into readable IG post type values, eg Albums, Reels, or Image Post.

    Args:
        typename (str): _description_

    Returns:
        _type_: _description_
    """
    if typename == "GraphSidecar":
        return "Album"
    elif typename == "GraphImage":
        return "Image Post"
    elif typename == "GraphVideo":
        return "Reel"


def aio_create_thumbnail_attachment(tmpdirname: str, recursive: bool = False):
    #######################################################
    # add event to system channel
    #######################################################
    jpg_file_list = glob_file_by_extension(f"{tmpdirname}", extension="*.jpg", recursive=recursive)

    jpg_file = f"{jpg_file_list[0]}"
    LOGGER.debug(f"jpg_file = {jpg_file}")
    print(f"jpg_file = {jpg_file}")

    jpg_attachment = discord.File(jpg_file)
    attachment_url = f"attachment://{jpg_attachment}"
    return attachment_url, jpg_attachment


async def aio_download_event(
    ctx: Context,
    tmpdirname: str,
    cmd_metadata: cmd_factory.CmdSerializer,
    is_dropbox_upload: bool = False,
    recursive: bool = False,
):
    #######################################################
    # add event to system channel
    #######################################################
    json_file_list = glob_file_by_extension(f"{tmpdirname}", extension="*.json", recursive=recursive)

    json_file = f"{json_file_list[0]}"
    LOGGER.debug(f"json_file = {json_file}")
    print(f"json_file = {json_file}")

    try:
        json_data = await run_aio_json_loads(json_file)
    except Exception as ex:
        await ctx.send(embed=discord.Embed(description="Could not open json metadata file"))
        print(ex)
        exc_type, exc_value, exc_traceback = sys.exc_info()
        LOGGER.error(f"Error Class: {str(ex.__class__)}")
        output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
        await ctx.send(embed=discord.Embed(description=f"{output}"))
        LOGGER.warning(output)
        LOGGER.error(f"exc_type: {exc_type}")
        LOGGER.error(f"exc_value: {exc_value}")
        traceback.print_tb(exc_traceback)

    current_message: discord.Message
    current_message = ctx.message
    current_channel: discord.TextChannel
    current_channel = ctx.channel
    current_guild: discord.Guild
    current_guild = current_channel.guild

    if "youtu.be" in f"{cmd_metadata.uri}" or "youtube" in f"{cmd_metadata.uri}":
        try:
            # 1. Get guild
            # ctx.guild.id
            # = await guild_factory.Guild(id=guild.id)

            ##########################################
            full_description = json_data["description"]
            description = f"{full_description[:75]}.." if len(full_description) > 75 else full_description
            embed_event = discord.Embed(
                title=f"Downloaded: '{json_data['fulltitle']}' in channel #{current_channel.name}",
                url=f"{current_message.jump_url}",
                description=css_syntax_highlight(description),
                color=discord.Color.blue(),
            )
            # set author
            embed_event.set_author(
                name=json_data["channel"],
                url=json_data["uploader_url"],
                icon_url=json_data["thumbnail"],
            )

            # set thumbnail
            embed_event.set_thumbnail(url=json_data["thumbnail"])
            embed_event.set_image(url=json_data["thumbnail"])

            embed_event.add_field(name="Url", value=f"{cmd_metadata.uri}", inline=False)
            embed_event.add_field(
                name="View Count",
                value=css_syntax_highlight(json_data["view_count"]),
                inline=True,
            )
            embed_event.add_field(
                name="Duration in seconds",
                value=css_syntax_highlight(json_data["duration"]),
                inline=True,
            )
            embed_event.set_footer(text=f'Is dropbox upload? "{is_dropbox_upload}"')
            ##########################################
            # rich.inspect(current_guild, methods=True)
            if current_guild.system_channel is not None:
                # to_send = 'Welcome {0.mention} to {1.name}!'.format(member, current_guild)
                await current_guild.system_channel.send(embed=embed_event)
        except Exception as ex:
            await ctx.send(embed=discord.Embed(description="Could not send download event to general"))
            print(ex)
            exc_type, exc_value, exc_traceback = sys.exc_info()
            LOGGER.error(f"Error Class: {str(ex.__class__)}")
            output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
            await ctx.send(embed=discord.Embed(description=f"{output}"))
            LOGGER.warning(output)
            LOGGER.error(f"exc_type: {exc_type}")
            LOGGER.error(f"exc_value: {exc_value}")
            traceback.print_tb(exc_traceback)

    elif "instagram" in f"{cmd_metadata.uri}":
        # 1. first grab the first media file we can find since IG can techincally download multiple media types
        file_to_upload = get_all_media_files_to_upload(f"{tmpdirname}")

        media_file_api = pathlib.Path(f"{file_to_upload[0]}")
        # eg 280546359_2873025409665148_6148590927180637067_n.mp4.json
        json_metadata_fname = f"{media_file_api.name}.json"

        # For instagram we want to use the metadata json file instead of the info.json
        json_file_list = glob_file_by_extension(f"{tmpdirname}", extension=json_metadata_fname, recursive=recursive)

        json_file = f"{json_file_list[0]}"
        LOGGER.debug(f"json_file = {json_file}")
        print(f"json_file = {json_file}")

        json_data = await run_aio_json_loads(json_file)

        if "display_url" in json_data:
            json_data_description = json_data["description"]
            json_data_title = json_data["description"]
            json_data_uploader_id = json_data["username"]
            json_data_uploader_url = f"https://instagram.com/{json_data_uploader_id}"

            dest_override = f"{tmpdirname}/{json_data['filename']}.jpg"
            thumbnail, _ = await downloader.download_and_save(json_data["display_url"], dest_override)
            rich.print(f"WE HAVE THE DISPLAY URL thumbnail => {thumbnail}")
            rich.print(f"WE HAVE THE DISPLAY URL dest_override => {dest_override}")

            # since we are not using recursive, it should just find the first jpg in directory which will be at tmpdirname/image.jpg
            attachment_url, jpg_attachment = aio_create_thumbnail_attachment(f"{tmpdirname}")

            rich.print(f"WE HAVE THE DISPLAY URL attachment_url => {attachment_url}")
            rich.print(f"WE HAVE THE DISPLAY URL jpg_attachment => {jpg_attachment}")

            json_data_icon_url = attachment_url
            json_data_thumbnail = attachment_url
            json_data_like_count = json_data["likes"] if "likes" in json_data else "n/a"
        else:
            await ctx.send(embed=discord.Embed(description="Key 'display_url' is not in dictonary 'json_data'"))

        try:
            ##########################################
            full_description = json_data_description
            description = f"{full_description[:75]}.." if len(full_description) > 75 else full_description
            embed_event = discord.Embed(
                title=f"Downloaded: '{description}' in channel #{current_channel.name}",
                url=f"{current_message.jump_url}",
                description=css_syntax_highlight(description),
                color=discord.Color.blue(),
            )
            # set author
            embed_event.set_author(
                name=json_data_uploader_id,
                url=json_data_uploader_url,
                icon_url=attachment_url,
            )

            # set thumbnail
            embed_event.set_thumbnail(url=attachment_url)
            embed_event.set_image(url=attachment_url)

            embed_event.add_field(name="Url", value=f"{cmd_metadata.uri}", inline=False)
            embed_event.add_field(
                name="Likes",
                value=css_syntax_highlight(json_data_like_count),
                inline=True,
            )
            # embed_event.add_field(
            #     name="Type",
            #     value=css_syntax_highlight(ig_type(json_data["typename"])),
            #     inline=True,
            # )
            embed_event.set_footer(text=f'Is dropbox upload? "{is_dropbox_upload}"')
            ##########################################
            if current_guild.system_channel is not None:
                await current_guild.system_channel.send(file=jpg_attachment, embed=embed_event)
        except Exception as ex:
            await ctx.send(embed=discord.Embed(description="Could not send download event to general"))
            print(ex)
            exc_type, exc_value, exc_traceback = sys.exc_info()
            LOGGER.error(f"Error Class: {str(ex.__class__)}")
            output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
            await ctx.send(embed=discord.Embed(description=f"{output}"))
            LOGGER.warning(output)
            LOGGER.error(f"exc_type: {exc_type}")
            LOGGER.error(f"exc_value: {exc_value}")
            traceback.print_tb(exc_traceback)

    elif "twitter" in f"{cmd_metadata.uri}":
        attachment_url = None
        jpg_attachment = None

        rich.print(json_data)

        # This means we used yt-dlp
        if "description" in json_data:
            json_data_description = json_data["description"]
            json_data_title = json_data["title"]
            json_data_uploader_id = json_data["uploader_id"]
            json_data_uploader_url = json_data["uploader_url"]
            json_data_icon_url = json_data["thumbnail"]
            json_data_thumbnail = json_data["thumbnail"]
            json_data_like_count = json_data["like_count"]
            json_data_repost_count = json_data["repost_count"]
            json_data_comment_count = json_data["comment_count"]
        # this means we are using gallery-dl to download a tweet
        elif "content" in json_data:
            json_data_description = json_data["content"]
            json_data_title = json_data["content"]
            json_data_uploader_id = json_data["author"]["name"]
            json_data_uploader_url = f"https://twitter.com/{json_data_uploader_id}"
            json_data_icon_url = json_data["author"]["profile_image"]
            attachment_url, jpg_attachment = aio_create_thumbnail_attachment(f"{tmpdirname}", recursive=True)
            json_data_thumbnail = attachment_url
            json_data_like_count = json_data["favorite_count"]
            json_data_repost_count = json_data["retweet_count"]
            json_data_comment_count = json_data["reply_count"]

        try:
            # 1. Get guild
            # ctx.guild.id
            # = await guild_factory.Guild(id=guild.id)

            ##########################################
            full_description = json_data_description
            description = f"{full_description[:75]}.." if len(full_description) > 75 else full_description
            embed_event = discord.Embed(
                title=f"Downloaded: '{json_data_title}' in channel #{current_channel.name}",
                url=f"{current_message.jump_url}",
                description=css_syntax_highlight(description),
                color=discord.Color.blue(),
            )
            # set author
            embed_event.set_author(
                name=json_data_uploader_id,
                url=json_data_uploader_url,
                icon_url=json_data_icon_url,
            )

            # set thumbnail
            embed_event.set_thumbnail(url=json_data_thumbnail)
            embed_event.set_image(url=json_data_thumbnail)

            embed_event.add_field(name="Url", value=f"{cmd_metadata.uri}", inline=False)
            embed_event.add_field(
                name="Like Count",
                value=css_syntax_highlight(json_data_like_count),
                inline=True,
            )
            embed_event.add_field(
                name="Retweets",
                value=css_syntax_highlight(json_data_repost_count),
                inline=True,
            )
            embed_event.add_field(
                name="Comments",
                value=css_syntax_highlight(json_data_comment_count),
                inline=True,
            )
            embed_event.set_footer(text=f'Is dropbox upload? "{is_dropbox_upload}"')
            if current_guild.system_channel is not None:
                if json_data_thumbnail is attachment_url:
                    await current_guild.system_channel.send(file=jpg_attachment, embed=embed_event)
                else:
                    await current_guild.system_channel.send(embed=embed_event)
        except Exception as ex:
            await ctx.send(embed=discord.Embed(description="Could not send download event to general"))
            print(ex)
            exc_type, exc_value, exc_traceback = sys.exc_info()
            LOGGER.error(f"Error Class: {str(ex.__class__)}")
            output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
            await ctx.send(embed=discord.Embed(description=f"{output}"))
            LOGGER.warning(output)
            LOGGER.error(f"exc_type: {exc_type}")
            LOGGER.error(f"exc_value: {exc_value}")
            traceback.print_tb(exc_traceback)
    elif "reddit" in f"{cmd_metadata.uri}" or "redd.it" in f"{cmd_metadata.uri}":
        # rich.print(json_data)

        try:
            # 1. Get guild
            # ctx.guild.id
            # = await guild_factory.Guild(id=guild.id)

            ##########################################
            full_description = json_data["title"]
            if "nsfw" in json_data["thumbnail"]:
                thumbnail = json_data["preview"]["images"][0]["source"]["url"]
            else:
                thumbnail = json_data["thumbnail"]

            description = f"{full_description[:75]}.." if len(full_description) > 75 else full_description
            embed_event = discord.Embed(
                title=f"Downloaded: '{json_data['title']}' in channel #{current_channel.name}",
                url=f"{current_message.jump_url}",
                description=css_syntax_highlight(description),
                color=discord.Color.blue(),
            )
            # set author
            embed_event.set_author(
                name=json_data["author"],
                url=f"https://www.reddit.com/user/{json_data['author']}/",
                icon_url=thumbnail,
            )

            # set thumbnail
            embed_event.set_thumbnail(url=thumbnail)
            embed_event.set_image(url=thumbnail)

            embed_event.add_field(name="Url", value=f"{cmd_metadata.uri}", inline=False)
            embed_event.add_field(
                name="Upvotes",
                value=css_syntax_highlight(json_data["score"]),
                inline=True,
            )
            embed_event.add_field(
                name="Comments",
                value=css_syntax_highlight(json_data["num_comments"]),
                inline=True,
            )
            embed_event.add_field(
                name="Subreddit",
                value=css_syntax_highlight(json_data["subreddit"]),
                inline=True,
            )
            embed_event.set_footer(text=f'Is dropbox upload? "{is_dropbox_upload}"')
            ##########################################
            # rich.inspect(current_guild, methods=True)
            if current_guild.system_channel is not None:
                await current_guild.system_channel.send(embed=embed_event)
        except Exception as ex:
            await ctx.send(embed=discord.Embed(description="Could not send download event to general"))
            print(ex)
            exc_type, exc_value, exc_traceback = sys.exc_info()
            LOGGER.error(f"Error Class: {str(ex.__class__)}")
            output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
            await ctx.send(embed=discord.Embed(description=f"{output}"))
            LOGGER.warning(output)
            LOGGER.error(f"exc_type: {exc_type}")
            LOGGER.error(f"exc_value: {exc_value}")
            traceback.print_tb(exc_traceback)

    elif "tiktok" in f"{cmd_metadata.uri}":
        # NOTE: Tiktok doesn't have a public thumbnail url, so we need to create an attachment and upload it
        attachment_url, jpg_attachment = aio_create_thumbnail_attachment(f"{tmpdirname}")

        try:
            # 1. Get guild
            # ctx.guild.id
            # = await guild_factory.Guild(id=guild.id)

            ##########################################
            full_description = json_data["description"]
            description = f"{full_description[:75]}.." if len(full_description) > 75 else full_description
            embed_event = discord.Embed(
                title=f"Downloaded: '{json_data['title']}' in channel #{current_channel.name}",
                url=f"{current_message.jump_url}",
                description=css_syntax_highlight(description),
                color=discord.Color.blue(),
            )
            # set author
            embed_event.set_author(
                name=json_data["uploader"],
                url=f"https://tiktok.com/@{json_data['uploader']}",
                icon_url=attachment_url,
            )

            # set thumbnail
            embed_event.set_thumbnail(url=attachment_url)
            embed_event.set_image(url=attachment_url)

            embed_event.add_field(name="Url", value=f"{cmd_metadata.uri}", inline=False)
            embed_event.add_field(
                name="View Count",
                value=css_syntax_highlight(json_data["view_count"]),
                inline=True,
            )
            embed_event.add_field(
                name="Like Count",
                value=css_syntax_highlight(json_data["like_count"]),
                inline=True,
            )
            embed_event.set_footer(text=f'Is dropbox upload? "{is_dropbox_upload}"')
            ##########################################
            # rich.inspect(current_guild, methods=True)
            if current_guild.system_channel is not None:
                # to_send = 'Welcome {0.mention} to {1.name}!'.format(member, current_guild)
                await current_guild.system_channel.send(file=jpg_attachment, embed=embed_event)
        except Exception as ex:
            await ctx.send(embed=discord.Embed(description="Could not send download event to general"))
            print(ex)
            exc_type, exc_value, exc_traceback = sys.exc_info()
            LOGGER.error(f"Error Class: {str(ex.__class__)}")
            output = f"[UNEXPECTED] {type(ex).__name__}: {ex}"
            await ctx.send(embed=discord.Embed(description=f"{output}"))
            LOGGER.warning(output)
            LOGGER.error(f"exc_type: {exc_type}")
            LOGGER.error(f"exc_value: {exc_value}")
            traceback.print_tb(exc_traceback)

    else:
        if current_guild.system_channel is not None:
            await current_guild.system_channel.send(
                embed=discord.Embed(
                    description=f"```css\nSorry, **aio_download_event** isn't configured to deal with these urls yet: {cmd_metadata.uri}\n```"
                )
            )

        rich.print(json_data)

</document_content>
</document>
<document index="34">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/file_functions.py</source>
<document_content>
"""cerebro_bot.file_functions"""

from __future__ import annotations

import glob
import json
import logging
import os
import pathlib
import string
import sys
from typing import List, Tuple, Union

import aiofiles
import pandas as pd
import rich
from rich.console import Console
from rich.table import Table

from cerebro_bot.bot_logger import get_logger
from cerebro_bot.constants import (
    FIFTY_THOUSAND,
    FIVE_HUNDRED_THOUSAND,
    MAX_BYTES_UPLOAD_DISCORD,
    ONE_HUNDRED_THOUSAND,
    ONE_MILLION,
    TEN_THOUSAND,
    THIRTY_THOUSAND,
    TWENTY_THOUSAND,
)

# # from cerebro_bot.fileobject import FileInfo
# # from cerebro_bot.utils.file_functions_mapping import FILE_FUNCTIONS_MAPPING
# from cerebro_bot.shell import ShellConsole, _popen, _popen_stdout

LOGGER = get_logger(__name__, provider="File Functions", level=logging.DEBUG)

PY2 = sys.version_info[0] == 2
PY3 = sys.version_info[0] == 3

# https://gist.github.com/wassname/1393c4a57cfcbf03641dbc31886123b8
# python convert string to safe filename
VALID_FILENAME_CHARS = f"-_.() {string.ascii_letters}{string.digits}"
CHAR_LIMIT = 255

JSON_EXTENSIONS = [".json", ".JSON"]
VIDEO_EXTENSIONS = [".mp4", ".mov", ".MP4", ".MOV"]
AUDIO_EXTENSIONS = [".mp3", ".MP3"]
GIF_EXTENSIONS = [".gif", ".GIF"]
MKV_EXTENSIONS = [".mkv", ".MKV"]
M3U8_EXTENSIONS = [".m3u8", ".M3U8"]
WEBM_EXTENSIONS = [".webm", ".WEBM"]
IMAGE_EXTENSIONS = [".png", ".jpeg", ".jpg", ".gif", ".PNG", ".JPEG", ".JPG", ".GIF"]
TORCH_MODEL_EXTENSIONS = [".pth", ".PTH"]


async def aio_read_jsonfile(jsonfile: str):
    print(f" [aio_read_jsonfile] jsonfile -> {jsonfile}")
    async with aiofiles.open(jsonfile, mode="r", encoding="utf-8") as f:
        contents = await f.read()
    json_data = json.loads(contents)
    print(f" [aio_read_jsonfile] json_data -> {json_data}")
    return json_data


async def aio_json_loads(uri: str):
    return json.loads(await (await aiofiles.open(uri, mode="r")).read())


async def run_aio_json_loads(uri: str):
    return await aio_json_loads(uri=uri)


# SOURCE: https://stackoverflow.com/questions/168409/how-do-you-get-a-directory-listing-sorted-by-creation-date-in-python
def sort_dir_by_mtime(dirpath: str) -> List[pathlib.Path]:
    return sorted(pathlib.Path(dirpath).iterdir(), key=os.path.getmtime)


# SOURCE: https://stackoverflow.com/questions/168409/how-do-you-get-a-directory-listing-sorted-by-creation-date-in-python
def sort_dir_by_ctime(dirpath: str) -> List[pathlib.Path]:
    return sorted(pathlib.Path(dirpath).iterdir(), key=os.path.getctime)


def get_all_media_files_to_upload(tmpdirname: str):
    # top level function that grabs all media files
    tree_list = tree(pathlib.Path(f"{tmpdirname}"))
    rich.print(tree_list)

    file_to_upload_list = [f"{p}" for p in tree_list]
    LOGGER.debug(f"get_all_media_files_to_upload -> file_to_upload_list = {file_to_upload_list}")
    rich.print(file_to_upload_list)

    return filter_media(file_to_upload_list)


def filter_pth(working_dir: List[str]) -> List[str]:
    return [
        f
        for f in working_dir
        if (pathlib.Path(f"{f}").is_file()) and pathlib.Path(f"{f}").suffix in TORCH_MODEL_EXTENSIONS
    ]


def filter_json(working_dir: List[str]) -> List[str]:
    return [
        f for f in working_dir if (pathlib.Path(f"{f}").is_file()) and pathlib.Path(f"{f}").suffix in JSON_EXTENSIONS
    ]


def rename_without_cachebuster(working_dir: List[str]) -> List[str]:
    working_dir_only = []
    for f in working_dir:
        if ("?updatedAt" in f"{f}") and (pathlib.Path(f"{f}").is_file()):
            orig = pathlib.Path(f"{f}").absolute()
            # tweetpik now adds cache buster, lets work around it
            without_cb = f"{orig}".split("?updatedAt")[0]
            orig.rename(f"{without_cb}")
            working_dir_only.append(f"{without_cb}")
    return working_dir_only


def filter_videos(working_dir: List[str]) -> List[str]:
    return [
        f for f in working_dir if (pathlib.Path(f"{f}").is_file()) and pathlib.Path(f"{f}").suffix in VIDEO_EXTENSIONS
    ]


def filter_audio(working_dir: List[str]) -> List[str]:
    return [
        f for f in working_dir if (pathlib.Path(f"{f}").is_file()) and pathlib.Path(f"{f}").suffix in AUDIO_EXTENSIONS
    ]


def filter_gif(working_dir: List[str]) -> List[str]:
    return [
        f for f in working_dir if (pathlib.Path(f"{f}").is_file()) and pathlib.Path(f"{f}").suffix in GIF_EXTENSIONS
    ]


def filter_mkv(working_dir: List[str]) -> List[str]:
    return [
        f for f in working_dir if (pathlib.Path(f"{f}").is_file()) and pathlib.Path(f"{f}").suffix in MKV_EXTENSIONS
    ]


def filter_m3u8(working_dir: List[str]) -> List[str]:
    return [
        f for f in working_dir if (pathlib.Path(f"{f}").is_file()) and pathlib.Path(f"{f}").suffix in M3U8_EXTENSIONS
    ]


def filter_webm(working_dir: List[str]) -> List[str]:
    return [
        f for f in working_dir if (pathlib.Path(f"{f}").is_file()) and pathlib.Path(f"{f}").suffix in WEBM_EXTENSIONS
    ]


def filter_images(working_dir: List[str]) -> List[str]:
    return [
        f for f in working_dir if (pathlib.Path(f"{f}").is_file()) and pathlib.Path(f"{f}").suffix in IMAGE_EXTENSIONS
    ]


def filter_pdfs(working_dir: List[str]) -> List[str]:
    return [
        f
        for f in working_dir
        if (pathlib.Path(f"{f}").is_file())
        and pathlib.Path(f"{f}").suffix
        in [
            ".pdf",
            ".PDF",
        ]
    ]


def filter_media(working_dir: List[str]) -> List[str]:
    imgs = filter_images(working_dir)
    videos = filter_videos(working_dir)
    return imgs + videos


def filter_pdf(working_dir: List[str]) -> List[str]:
    return filter_pdfs(working_dir)


def get_dataframe_from_csv(filename: str, return_parent_folder_name: bool = False) -> pd.core.frame.DataFrame:
    """Open csv files and return a dataframe from pandas

    Args:
        filename (str): path to file
    """
    src = pathlib.Path(f"{filename}").resolve()
    df = pd.read_csv(f"{src}")

    # import bpdb
    # bpdb.set_trace()

    return (df, f"{src.parent.stem}") if return_parent_folder_name else df


def sort_dataframe(df: pd.core.frame.DataFrame, columns: list = None, ascending: Tuple = ()) -> pd.core.frame.DataFrame:
    """Return dataframe sorted via columns

    Args:
        df (pd.core.frame.DataFrame): existing dataframe
        columns (list, optional): [description]. Defaults to []. Eg. ["Total Followers", "Total Likes", "Total Comments", "ERDay", "ERpost"]
        ascending (Tuple, optional): [description]. Defaults to (). Eg. (False, False, False, False, False)

    Returns:
        pd.core.frame.DataFrame: [description]
    """
    if columns is None:
        columns = []
    df = df.sort_values(columns, ascending=ascending)
    return df


def rich_format_followers(val: int) -> str:
    """Given a arbritary int, return a 'rich' string formatting

    Args:
        val (int): eg. followers = 4366347347457

    Returns:
        str: [description] eg. "[bold bright_yellow]4366347347457[/bold bright_yellow]"
    """

    if val > ONE_MILLION:
        return f"[bold bright_yellow]{val}[/bold bright_yellow]"
    elif FIVE_HUNDRED_THOUSAND < val < ONE_MILLION:
        return f"[bold dark_orange]{val}[/bold dark_orange]"
    elif ONE_HUNDRED_THOUSAND < val < FIVE_HUNDRED_THOUSAND:
        return f"[bold orange_red1]{val}[/bold orange_red1]"

    elif FIFTY_THOUSAND < val < ONE_HUNDRED_THOUSAND:
        return f"[bold dodger_blue2]{val}[/bold dodger_blue2]"
    elif THIRTY_THOUSAND < val < FIFTY_THOUSAND:
        return f"[bold purple3]{val}[/bold purple3]"
    elif TWENTY_THOUSAND < val < THIRTY_THOUSAND:
        return f"[bold rosy_brown]{val}[/bold rosy_brown]"
    elif TEN_THOUSAND < val < TWENTY_THOUSAND:
        return f"[bold green]{val}[/bold green]"
    else:
        return f"[bold bright_white]{val}[/bold bright_white]"


def rich_likes_or_comments(val: int) -> str:
    """Given a arbritary int, return a 'rich' string formatting

    Args:
        val (int): eg. followers = 4366347347457

    Returns:
        str: [description] eg. "[bold bright_yellow]4366347347457[/bold bright_yellow]"
    """

    if TEN_THOUSAND >= val:
        return f"[bold bright_yellow]{val}[/bold bright_yellow]"
    elif FIFTY_THOUSAND < val < ONE_HUNDRED_THOUSAND:
        return f"[bold dodger_blue2]{val}[/bold dodger_blue2]"
    elif THIRTY_THOUSAND < val < FIFTY_THOUSAND:
        return f"[bold purple3]{val}[/bold purple3]"
    elif TWENTY_THOUSAND < val < THIRTY_THOUSAND:
        return f"[bold rosy_brown]{val}[/bold rosy_brown]"
    elif TEN_THOUSAND < val < TWENTY_THOUSAND:
        return f"[bold green]{val}[/bold green]"
    else:
        return f"[bold bright_white]{val}[/bold bright_white]"


def rich_display_meme_pull_list(df: pd.core.frame.DataFrame):  # noqa
    console = Console()

    table = Table(show_header=True, header_style="bold magenta")

    table.add_column("Account")
    table.add_column("Social")
    table.add_column("Total Followers")
    table.add_column("Total Likes")
    table.add_column("Total Comments")
    table.add_column("Total Posts")
    table.add_column("Start Date")
    table.add_column("End Date")
    table.add_column("ERDay")
    table.add_column("ERpost")
    table.add_column("Average Likes")
    table.add_column("Average Comments")
    table.add_column("Links")

    for index, row in df.iterrows():
        account = f"[bold blue]{row['Account']}[/bold blue]"
        social = f"[bold]{row['Social']}[/bold]"
        total_followers = rich_format_followers(row["Total Followers"])
        total_likes = f"[bold]{row['Total Likes']}[/bold]"
        total_comments = f"[bold]{row['Total Comments']}[/bold]"
        total_posts = f"[bold]{row['Total Posts']}[/bold]"
        start_date = f"[bold]{row['Start Date']}[/bold]"
        end_date = f"[bold]{row['End Date']}[/bold]"
        erday = f"[bold]{row['ERDay']}[/bold]"
        erpost = f"[bold]{row['ERpost']}[/bold]"
        average_likes = f"[bold]{row['Average Likes']}[/bold]"
        average_comments = f"[bold]{row['Average Comments']}[/bold]"
        links = f"[bold]{row['Links']}[/bold]"

        table.add_row(
            account,
            social,
            total_followers,
            total_likes,
            total_comments,
            total_posts,
            start_date,
            end_date,
            erday,
            erpost,
            average_likes,
            average_comments,
            links,
        )

    console.print(table)


def rich_display_popstars_analytics(df: pd.core.frame.DataFrame):  # noqa
    console = Console()

    table = Table(show_header=True, header_style="bold magenta")

    table.add_column("Social")
    table.add_column("Author")
    table.add_column("Url")
    table.add_column("Likes")
    table.add_column("Comments")
    table.add_column("ER")
    table.add_column("Text")
    table.add_column("Date")
    table.add_column("Media 1")

    for index, row in df.iterrows():
        social = f"[bold]{row['Social']}[/bold]"
        author = f"[bold]{row['Author']}[/bold]"
        url = f"[bold]{row['Url']}[/bold]"
        likes = f"[bold]{rich_likes_or_comments(row['Likes'])}[/bold]"
        comments = f"[bold]{rich_likes_or_comments(row['Comments'])}[/bold]"
        er = f"[bold]{row['ER']}[/bold]"
        text = f"[bold]{row['Text']}[/bold]"
        date = f"[bold]{row['Date']}[/bold]"
        media = f"[bold]{row['Media 1']}[/bold]"

        table.add_row(social, author, url, likes, comments, er, text, date, media)

    console.print(table)


# # >>> import glob
# # >>> json_files = glob.glob(f"{metadata_path}/*.json")
# # >>> json_files


def glob_file_by_extension(working_dir: List[str], extension: str = "*.mp4", recursive: bool = False) -> List[str]:
    print(f"Searching dir -> {working_dir}/{extension}")

    if recursive:
        # NOTE: When recursive is set True "**"" followed by path separator('./**/') will match any files or directories.
        expression = f"{working_dir}/**/{extension}"
    else:
        expression = f"{working_dir}/{extension}"
    return glob.glob(expression, recursive=recursive)


def print_and_append(dir_listing: list, tree_str: str, silent: bool = False) -> None:
    if not silent:
        print(tree_str)
    dir_listing.append(tree_str)


def tree(directory: Union[pathlib.PosixPath, pathlib.Path], silent: bool = False) -> List[pathlib.PosixPath]:
    """"""
    # from ffmpeg_tools import fileobject
    file_system: List[pathlib.Path]
    file_system = []
    _tree = []
    print_and_append(_tree, f"+ {directory}", silent=silent)
    for path in sorted(directory.rglob("*")):
        file_system.append(pathlib.Path(f"{path.resolve()}"))
        depth = len(path.relative_to(directory).parts)
        spacer = "    " * depth
        print_and_append(_tree, f"{spacer}+ {path.name}", silent=silent)

    return sorted(file_system, key=os.path.getmtime)


# SOURCE: https://python.hotexamples.com/site/file?hash=0xda3708e60cd1ddb3012abd7dba205f48214aee7366f452e93807887c6a04db42&fullName=spring_cleaning.py&project=pambot/SpringCleaning
def format_size(a_file: str):
    if a_file > 1024**3:
        return "{:.0f} GB".format(a_file / float(2**30))
    elif a_file > 1024**2:
        return "{:.0f} MB".format(a_file / float(2**20))
    elif a_file > 1024:
        return "{:.0f} KB".format(a_file / float(2**10))
    else:
        return "{:.0f} B".format(a_file)


async def aiowrite_file(data: str, dl_dir: str = "./", fname: str = "", ext: str = ""):
    p_dl_dir = pathlib.Path(dl_dir)
    full_path_dl_dir = f"{p_dl_dir.absolute()}"
    p_new = pathlib.Path(f"{full_path_dl_dir}/{fname}.{ext}")
    LOGGER.debug(f"Writing to {p_new.absolute()}")
    async with aiofiles.open(f"{p_new.absolute()}", mode="w") as f:
        await f.write(data)


async def aioread_file(data: str, dl_dir: str = "./", fname: str = "", ext: str = ""):
    p_dl_dir = pathlib.Path(dl_dir)
    full_path_dl_dir = f"{p_dl_dir.absolute()}"
    p_new = pathlib.Path(f"{full_path_dl_dir}/{fname}.{ext}")
    LOGGER.debug(f"Writing to {p_new.absolute()}")
    async with aiofiles.open(f"{p_new.absolute()}", mode="r") as f:
        await f.read(data)


def check_file_size(a_file: str) -> Tuple[bool, str]:
    p = pathlib.Path(a_file)
    file_size = p.stat().st_size
    LOGGER.debug(f"File: {p} | Size(bytes): {file_size} | Size(type): {type(file_size)}")
    check = file_size > MAX_BYTES_UPLOAD_DISCORD
    msg = f"Is file size greater than {MAX_BYTES_UPLOAD_DISCORD}: {check}"
    LOGGER.debug(msg)
    return check, msg


# ------------------------------------------------------------
# NOTE: MOVE THIS TO A FILE UTILITIES LIBRARY
# ------------------------------------------------------------
# SOURCE: https://github.com/tgbugs/pyontutils/blob/05dc32b092b015233f4a6cefa6c157577d029a40/ilxutils/tools.py
def is_file(path: str):
    """Check if path contains a file

    Args:
        path (_type_): _description_

    Returns:
        _type_: _description_
    """
    return bool(pathlib.Path(path).is_file())


def is_directory(path: str):
    """Check if path contains a dir

    Args:
        path (str): _description_

    Returns:
        _type_: _description_
    """
    return bool(pathlib.Path(path).is_dir())


def is_a_symlink(path: str):
    """Check if path contains a dir

    Args:
        path (str): _description_

    Returns:
        _type_: _description_
    """
    return bool(pathlib.Path(path).is_symlink())


def expand_path_str(path: str) -> pathlib.PosixPath:
    """_summary_

    Args:
        path (str): _description_

    Returns:
        pathlib.PosixPath: _description_
    """
    return pathlib.Path(tilda(path))


def tilda(obj):
    """wrapper for linux ~/ shell notation

    Args:
        obj (_type_): _description_

    Returns:
        _type_: _description_
    """
    if isinstance(obj, list):
        return [str(pathlib.Path(o).expanduser()) if isinstance(o, str) else o for o in obj]
    elif isinstance(obj, str):
        return str(pathlib.Path(obj).expanduser())
    else:
        return obj


def fix_path(path: str):
    """Automatically convert path to fully qualifies file uri.

    Args:
        path (_type_): _description_
    """

    def __fix_path(path):
        if not isinstance(path, str):
            return path
        elif "~" == path[0]:
            tilda_fixed_path = tilda(path)
            if is_file(tilda_fixed_path):
                return tilda_fixed_path
            else:
                exit(path, ": does not exit.")
        elif is_file(pathlib.Path.home() / path):
            return str(pathlib.Path().home() / path)
        elif is_directory(pathlib.Path.home() / path):
            return str(pathlib.Path().home() / path)
        else:
            return path

    if isinstance(path, str):
        return __fix_path(path)
    elif isinstance(path, list):
        return [__fix_path(p) for p in path]
    else:
        return path


# smoke tests

</document_content>
</document>
<document index="35">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/imgops.py</source>
<document_content>
# https://github.com/universityofprofessorex/ESRGAN-Bot
# Attribution - NonCommercial - ShareAlike 4.0 International

# == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == =

# Creative Commons Corporation("Creative Commons") is not a law firm and
# does not provide legal services or legal advice. Distribution of
# Creative Commons public licenses does not create a lawyer - client or
# other relationship. Creative Commons makes its licenses and related
# information available on an "as-is" basis. Creative Commons gives no
# warranties regarding its licenses, any material licensed under their
# terms and conditions, or any related information. Creative Commons
# disclaims all liability for damages resulting from their use to the
# fullest extent possible.

# Using Creative Commons Public Licenses

# Creative Commons public licenses provide a standard set of terms and
# conditions that creators and other rights holders may use to share
# original works of authorship and other material subject to copyright
# and certain other rights specified in the public license below. The
# following considerations are for informational purposes only, are not
# exhaustive, and do not form part of our licenses.

#      Considerations for licensors: Our public licenses are
#      intended for use by those authorized to give the public
#      permission to use material in ways otherwise restricted by
#      copyright and certain other rights. Our licenses are
#      irrevocable. Licensors should read and understand the terms
#      and conditions of the license they choose before applying it.
#      Licensors should also secure all rights necessary before
#      applying our licenses so that the public can reuse the
#      material as expected. Licensors should clearly mark any
#      material not subject to the license. This includes other CC-
#      licensed material, or material used under an exception or
#      limitation to copyright. More considerations for licensors:
#     wiki.creativecommons.org/Considerations_for_licensors

#      Considerations for the public: By using one of our public
#      licenses, a licensor grants the public permission to use the
#      licensed material under specified terms and conditions. If
#      the licensor's permission is not necessary for any reason--for
#      example, because of any applicable exception or limitation to
#      copyright--then that use is not regulated by the license. Our
#      licenses grant only permissions under copyright and certain
#      other rights that a licensor has authority to grant. Use of
#      the licensed material may still be restricted for other
#      reasons, including because others have copyright or other
#      rights in the material. A licensor may make special requests,
#      such as asking that all changes be marked or described.
#      Although not required by our licenses, you are encouraged to
#      respect those requests where reasonable. More considerations
#      for the public:
#     wiki.creativecommons.org/Considerations_for_licensees

# =======================================================================

# Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International
# Public License

# By exercising the Licensed Rights (defined below), You accept and agree
# to be bound by the terms and conditions of this Creative Commons
# Attribution-NonCommercial-ShareAlike 4.0 International Public License
# ("Public License"). To the extent this Public License may be
# interpreted as a contract, You are granted the Licensed Rights in
# consideration of Your acceptance of these terms and conditions, and the
# Licensor grants You such rights in consideration of benefits the
# Licensor receives from making the Licensed Material available under
# these terms and conditions.


# Section 1 -- Definitions.

#   a. Adapted Material means material subject to Copyright and Similar
#      Rights that is derived from or based upon the Licensed Material
#      and in which the Licensed Material is translated, altered,
#      arranged, transformed, or otherwise modified in a manner requiring
#      permission under the Copyright and Similar Rights held by the
#      Licensor. For purposes of this Public License, where the Licensed
#      Material is a musical work, performance, or sound recording,
#      Adapted Material is always produced where the Licensed Material is
#      synched in timed relation with a moving image.

#   b. Adapter's License means the license You apply to Your Copyright
#      and Similar Rights in Your contributions to Adapted Material in
#      accordance with the terms and conditions of this Public License.

#   c. BY-NC-SA Compatible License means a license listed at
#      creativecommons.org/compatiblelicenses, approved by Creative
#      Commons as essentially the equivalent of this Public License.

#   d. Copyright and Similar Rights means copyright and/or similar rights
#      closely related to copyright including, without limitation,
#      performance, broadcast, sound recording, and Sui Generis Database
#      Rights, without regard to how the rights are labeled or
#      categorized. For purposes of this Public License, the rights
#      specified in Section 2(b)(1)-(2) are not Copyright and Similar
#      Rights.

#   e. Effective Technological Measures means those measures that, in the
#      absence of proper authority, may not be circumvented under laws
#      fulfilling obligations under Article 11 of the WIPO Copyright
#      Treaty adopted on December 20, 1996, and/or similar international
#      agreements.

#   f. Exceptions and Limitations means fair use, fair dealing, and/or
#      any other exception or limitation to Copyright and Similar Rights
#      that applies to Your use of the Licensed Material.

#   g. License Elements means the license attributes listed in the name
#      of a Creative Commons Public License. The License Elements of this
#      Public License are Attribution, NonCommercial, and ShareAlike.

#   h. Licensed Material means the artistic or literary work, database,
#      or other material to which the Licensor applied this Public
#      License.

#   i. Licensed Rights means the rights granted to You subject to the
#      terms and conditions of this Public License, which are limited to
#      all Copyright and Similar Rights that apply to Your use of the
#      Licensed Material and that the Licensor has authority to license.

#   j. Licensor means the individual(s) or entity(ies) granting rights
#      under this Public License.

#   k. NonCommercial means not primarily intended for or directed towards
#      commercial advantage or monetary compensation. For purposes of
#      this Public License, the exchange of the Licensed Material for
#      other material subject to Copyright and Similar Rights by digital
#      file-sharing or similar means is NonCommercial provided there is
#      no payment of monetary compensation in connection with the
#      exchange.

#   l. Share means to provide material to the public by any means or
#      process that requires permission under the Licensed Rights, such
#      as reproduction, public display, public performance, distribution,
#      dissemination, communication, or importation, and to make material
#      available to the public including in ways that members of the
#      public may access the material from a place and at a time
#      individually chosen by them.

#   m. Sui Generis Database Rights means rights other than copyright
#      resulting from Directive 96/9/EC of the European Parliament and of
#      the Council of 11 March 1996 on the legal protection of databases,
#      as amended and/or succeeded, as well as other essentially
#      equivalent rights anywhere in the world.

#   n. You means the individual or entity exercising the Licensed Rights
#      under this Public License. Your has a corresponding meaning.


# Section 2 -- Scope.

#   a. License grant.

#        1. Subject to the terms and conditions of this Public License,
#           the Licensor hereby grants You a worldwide, royalty-free,
#           non-sublicensable, non-exclusive, irrevocable license to
#           exercise the Licensed Rights in the Licensed Material to:

#             a. reproduce and Share the Licensed Material, in whole or
#                in part, for NonCommercial purposes only; and

#             b. produce, reproduce, and Share Adapted Material for
#                NonCommercial purposes only.

#        2. Exceptions and Limitations. For the avoidance of doubt, where
#           Exceptions and Limitations apply to Your use, this Public
#           License does not apply, and You do not need to comply with
#           its terms and conditions.

#        3. Term. The term of this Public License is specified in Section
#           6(a).

#        4. Media and formats; technical modifications allowed. The
#           Licensor authorizes You to exercise the Licensed Rights in
#           all media and formats whether now known or hereafter created,
#           and to make technical modifications necessary to do so. The
#           Licensor waives and/or agrees not to assert any right or
#           authority to forbid You from making technical modifications
#           necessary to exercise the Licensed Rights, including
#           technical modifications necessary to circumvent Effective
#           Technological Measures. For purposes of this Public License,
#           simply making modifications authorized by this Section 2(a)
#           (4) never produces Adapted Material.

#        5. Downstream recipients.

#             a. Offer from the Licensor -- Licensed Material. Every
#                recipient of the Licensed Material automatically
#                receives an offer from the Licensor to exercise the
#                Licensed Rights under the terms and conditions of this
#                Public License.

#             b. Additional offer from the Licensor -- Adapted Material.
#                Every recipient of Adapted Material from You
#                automatically receives an offer from the Licensor to
#                exercise the Licensed Rights in the Adapted Material
#                under the conditions of the Adapter's License You apply.

#             c. No downstream restrictions. You may not offer or impose
#                any additional or different terms or conditions on, or
#                apply any Effective Technological Measures to, the
#                Licensed Material if doing so restricts exercise of the
#                Licensed Rights by any recipient of the Licensed
#                Material.

#        6. No endorsement. Nothing in this Public License constitutes or
#           may be construed as permission to assert or imply that You
#           are, or that Your use of the Licensed Material is, connected
#           with, or sponsored, endorsed, or granted official status by,
#           the Licensor or others designated to receive attribution as
#           provided in Section 3(a)(1)(A)(i).

#   b. Other rights.

#        1. Moral rights, such as the right of integrity, are not
#           licensed under this Public License, nor are publicity,
#           privacy, and/or other similar personality rights; however, to
#           the extent possible, the Licensor waives and/or agrees not to
#           assert any such rights held by the Licensor to the limited
#           extent necessary to allow You to exercise the Licensed
#           Rights, but not otherwise.

#        2. Patent and trademark rights are not licensed under this
#           Public License.

#        3. To the extent possible, the Licensor waives any right to
#           collect royalties from You for the exercise of the Licensed
#           Rights, whether directly or through a collecting society
#           under any voluntary or waivable statutory or compulsory
#           licensing scheme. In all other cases the Licensor expressly
#           reserves any right to collect such royalties, including when
#           the Licensed Material is used other than for NonCommercial
#           purposes.


# Section 3 -- License Conditions.

# Your exercise of the Licensed Rights is expressly made subject to the
# following conditions.

#   a. Attribution.

#        1. If You Share the Licensed Material (including in modified
#           form), You must:

#             a. retain the following if it is supplied by the Licensor
#                with the Licensed Material:

#                  i. identification of the creator(s) of the Licensed
#                     Material and any others designated to receive
#                     attribution, in any reasonable manner requested by
#                     the Licensor (including by pseudonym if
#                     designated);

#                 ii. a copyright notice;

#                iii. a notice that refers to this Public License;

#                 iv. a notice that refers to the disclaimer of
#                     warranties;

#                  v. a URI or hyperlink to the Licensed Material to the
#                     extent reasonably practicable;

#             b. indicate if You modified the Licensed Material and
#                retain an indication of any previous modifications; and

#             c. indicate the Licensed Material is licensed under this
#                Public License, and include the text of, or the URI or
#                hyperlink to, this Public License.

#        2. You may satisfy the conditions in Section 3(a)(1) in any
#           reasonable manner based on the medium, means, and context in
#           which You Share the Licensed Material. For example, it may be
#           reasonable to satisfy the conditions by providing a URI or
#           hyperlink to a resource that includes the required
#           information.
#        3. If requested by the Licensor, You must remove any of the
#           information required by Section 3(a)(1)(A) to the extent
#           reasonably practicable.

#   b. ShareAlike.

#      In addition to the conditions in Section 3(a), if You Share
#      Adapted Material You produce, the following conditions also apply.

#        1. The Adapter's License You apply must be a Creative Commons
#           license with the same License Elements, this version or
#           later, or a BY-NC-SA Compatible License.

#        2. You must include the text of, or the URI or hyperlink to, the
#           Adapter's License You apply. You may satisfy this condition
#           in any reasonable manner based on the medium, means, and
#           context in which You Share Adapted Material.

#        3. You may not offer or impose any additional or different terms
#           or conditions on, or apply any Effective Technological
#           Measures to, Adapted Material that restrict exercise of the
#           rights granted under the Adapter's License You apply.


# Section 4 -- Sui Generis Database Rights.

# Where the Licensed Rights include Sui Generis Database Rights that
# apply to Your use of the Licensed Material:

#   a. for the avoidance of doubt, Section 2(a)(1) grants You the right
#      to extract, reuse, reproduce, and Share all or a substantial
#      portion of the contents of the database for NonCommercial purposes
#      only;

#   b. if You include all or a substantial portion of the database
#      contents in a database in which You have Sui Generis Database
#      Rights, then the database in which You have Sui Generis Database
#      Rights (but not its individual contents) is Adapted Material,
#      including for purposes of Section 3(b); and

#   c. You must comply with the conditions in Section 3(a) if You Share
#      all or a substantial portion of the contents of the database.

# For the avoidance of doubt, this Section 4 supplements and does not
# replace Your obligations under this Public License where the Licensed
# Rights include other Copyright and Similar Rights.


# Section 5 -- Disclaimer of Warranties and Limitation of Liability.

#   a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE
#      EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS
#      AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF
#      ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,
#      IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,
#      WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR
#      PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,
#      ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT
#      KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT
#      ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.

#   b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE
#      TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,
#      NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,
#      INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,
#      COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR
#      USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN
#      ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR
#      DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR
#      IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.

#   c. The disclaimer of warranties and limitation of liability provided
#      above shall be interpreted in a manner that, to the extent
#      possible, most closely approximates an absolute disclaimer and
#      waiver of all liability.


# Section 6 -- Term and Termination.

#   a. This Public License applies for the term of the Copyright and
#      Similar Rights licensed here. However, if You fail to comply with
#      this Public License, then Your rights under this Public License
#      terminate automatically.

#   b. Where Your right to use the Licensed Material has terminated under
#      Section 6(a), it reinstates:

#        1. automatically as of the date the violation is cured, provided
#           it is cured within 30 days of Your discovery of the
#           violation; or

#        2. upon express reinstatement by the Licensor.

#      For the avoidance of doubt, this Section 6(b) does not affect any
#      right the Licensor may have to seek remedies for Your violations
#      of this Public License.

#   c. For the avoidance of doubt, the Licensor may also offer the
#      Licensed Material under separate terms or conditions or stop
#      distributing the Licensed Material at any time; however, doing so
#      will not terminate this Public License.

#   d. Sections 1, 5, 6, 7, and 8 survive termination of this Public
#      License.


# Section 7 -- Other Terms and Conditions.

#   a. The Licensor shall not be bound by any additional or different
#      terms or conditions communicated by You unless expressly agreed.

#   b. Any arrangements, understandings, or agreements regarding the
#      Licensed Material not stated herein are separate from and
#      independent of the terms and conditions of this Public License.


# Section 8 -- Interpretation.

#   a. For the avoidance of doubt, this Public License does not, and
#      shall not be interpreted to, reduce, limit, restrict, or impose
#      conditions on any use of the Licensed Material that could lawfully
#      be made without permission under this Public License.

#   b. To the extent possible, if any provision of this Public License is
#      deemed unenforceable, it shall be automatically reformed to the
#      minimum extent necessary to make it enforceable. If the provision
#      cannot be reformed, it shall be severed from this Public License
#      without affecting the enforceability of the remaining terms and
#      conditions.

#   c. No term or condition of this Public License will be waived and no
#      failure to comply consented to unless expressly agreed to by the
#      Licensor.

#   d. Nothing in this Public License constitutes or may be interpreted
#      as a limitation upon, or waiver of, any privileges and immunities
#      that apply to the Licensor or You, including from the legal
#      processes of any jurisdiction or authority.

# =======================================================================

# Creative Commons is not a party to its public
# licenses. Notwithstanding, Creative Commons may elect to apply one of
# its public licenses to material it publishes and in those instances
# will be considered the "Licensor." The text of the Creative Commons
# public licenses is dedicated to the public domain under the CC0 Public
# Domain Dedication. Except for the limited purpose of indicating that
# material is shared under a Creative Commons public license or as
# otherwise permitted by the Creative Commons policies published at
# creativecommons.org/policies, Creative Commons does not authorize the
# use of the trademark "Creative Commons" or any other trademark or logo
# of Creative Commons without its prior written consent including,
# without limitation, in connection with any unauthorized modifications
# to any of its public licenses or any other arrangements,
# understandings, or agreements concerning use of licensed material. For
# the avoidance of doubt, this paragraph does not form part of the
# public licenses.

# Creative Commons may be contacted at creativecommons.org.
# NOTE: For more examples tqdm + aiofile, search https://github.com/search?l=Python&q=aiofile+tqdm&type=Code

from __future__ import annotations

# import aiofile
import gc
import math
import time
from typing import List

from PIL import Image
import numpy as np

# from tqdm.asyncio import tqdm
import pytz

# import aiorwlock
import rich
from scipy.spatial import KDTree
import torch
from torchvision.utils import make_grid
from tqdm.auto import tqdm
from webcolors import CSS3_HEX_TO_NAMES, hex_to_rgb

# import aiohttp


# import aiosqlite

# from icecream import ic


utc = pytz.utc


def convert_rgb_to_names(rgb_tuple):
    # a dictionary of all the hex and their respective names in css3
    css3_db = CSS3_HEX_TO_NAMES
    names = []
    rgb_values = []
    for color_hex, color_name in css3_db.items():
        names.append(color_name)
        rgb_values.append(hex_to_rgb(color_hex))

    kdt_db = KDTree(rgb_values)
    distance, index = kdt_db.query(rgb_tuple)
    rich.print(f"closest match: {names[index]}")
    return f"{names[index]}"


def get_all_corners_color(urls):
    pbar = tqdm(urls)
    pixel_data = {
        "top_left": "",
        "top_right": "",
        "bottom_left": "",
        "bottom_right": "",
    }
    for url in pbar:
        img = Image.open(url).convert("RGB")
        # breakpoint()
        width, height = img.size
        pixel_layout = img.load()
        pixel_data["top_left"] = top_left = pixel_layout[0, 0]
        pixel_data["top_right"] = top_right = pixel_layout[width - 1, 0]
        pixel_data["bottom_left"] = bottom_left = pixel_layout[0, height - 1]
        pixel_data["bottom_right"] = bottom_right = pixel_layout[width - 1, height - 1]
        rich.print(pixel_data)
    return pixel_data


def rgb2hex(r, g, b):
    return "#{:02x}{:02x}{:02x}".format(r, g, b)


def handle_get_dominant_color(urls: List[str], return_type="name"):
    start_time = time.time()
    corner_pixels = get_all_corners_color(urls)

    if (
        corner_pixels["top_left"]
        == corner_pixels["top_right"]
        == corner_pixels["bottom_left"]
        == corner_pixels["bottom_right"]
    ):
        r, g, b = corner_pixels["top_left"]
    else:
        r, g, b = corner_pixels["top_right"]
    background_color = rgb2hex(r, g, b)
    rich.print(background_color)
    color_name = convert_rgb_to_names((r, g, b))
    rich.print(color_name)

    duration = time.time() - start_time
    print(f"Calculated 1 image in {duration} seconds")
    if return_type == "name":
        return color_name
    elif return_type == "hex":
        return background_color


def bgr_to_rgb(image: torch.Tensor) -> torch.Tensor:
    # flip image channels
    # https://github.com/pytorch/pytorch/issues/229
    out: torch.Tensor = image.flip(-3)
    # out: torch.Tensor = image[[2, 1, 0], :, :] #RGB to BGR #may be faster
    return out


def rgb_to_bgr(image: torch.Tensor) -> torch.Tensor:
    # same operation as bgr_to_rgb(), flip image channels
    return bgr_to_rgb(image)


def bgra_to_rgba(image: torch.Tensor) -> torch.Tensor:
    out: torch.Tensor = image[[2, 1, 0, 3], :, :]
    return out


def rgba_to_bgra(image: torch.Tensor) -> torch.Tensor:
    # same operation as bgra_to_rgba(), flip image channels
    return bgra_to_rgba(image)


# TODO: Could also automatically detect the possible range with min and max, like in def ssim()


def denorm(x, min_max=(-1.0, 1.0)):
    """
    Denormalize from [-1,1] range to [0,1]
    formula: xi' = (xi - mu)/sigma
    Example: "out = (x + 1.0) / 2.0" for denorm
        range (-1,1) to (0,1)
    for use with proper act in Generator output (ie. tanh)
    """
    out = (x - min_max[0]) / (min_max[1] - min_max[0])
    if isinstance(x, torch.Tensor):
        return out.clamp(0, 1)
    elif isinstance(x, np.ndarray):
        return np.clip(out, 0, 1)
    else:
        raise TypeError(
            "Got unexpected object type, expected torch.Tensor or \
        np.ndarray"
        )


def norm(x):
    # Normalize (z-norm) from [0,1] range to [-1,1]
    out = (x - 0.5) * 2.0
    if isinstance(x, torch.Tensor):
        return out.clamp(-1, 1)
    elif isinstance(x, np.ndarray):
        return np.clip(out, -1, 1)
    else:
        raise TypeError(
            "Got unexpected object type, expected torch.Tensor or \
        np.ndarray"
        )


# 2tensor


async def np2tensor(
    img,
    bgr2rgb=True,
    data_range=1.0,
    normalize=False,
    change_range=True,
    add_batch=True,
):
    """
    Converts a numpy image array into a Tensor array.
    Parameters:
        img (numpy array): the input image numpy array
        add_batch (bool): choose if new tensor needs batch dimension added
    """
    if not isinstance(img, np.ndarray):  # images expected to be uint8 -> 255
        raise TypeError("Got unexpected object type, expected np.ndarray")
    # check how many channels the image has, then condition, like in my BasicSR. ie. RGB, RGBA, Gray
    # if bgr2rgb:
    # img = img[:, :, [2, 1, 0]] #BGR to RGB -> in numpy, if using OpenCV, else not needed. Only if image has colors.
    if change_range:
        if np.issubdtype(img.dtype, np.integer):
            info = np.iinfo
        elif np.issubdtype(img.dtype, np.floating):
            info = np.finfo
        img = img * data_range / info(img.dtype).max  # uint8 = /255
    img = torch.from_numpy(
        np.ascontiguousarray(np.transpose(img, (2, 0, 1)))
    ).float()  # "HWC to CHW" and "numpy to tensor"
    if bgr2rgb:
        if img.shape[0] == 3:  # RGB
            # BGR to RGB -> in tensor, if using OpenCV, else not needed. Only if image has colors.
            img = bgr_to_rgb(img)
        elif img.shape[0] == 4:  # RGBA
            # BGR to RGB -> in tensor, if using OpenCV, else not needed. Only if image has colors.)
            img = bgra_to_rgba(img)
    if add_batch:
        # Add fake batch dimension = 1 . squeeze() will remove the dimensions of size 1
        img.unsqueeze_(0)
    if normalize:
        img = norm(img)
    return img


# 2np


async def tensor2np(
    img,
    rgb2bgr=True,
    remove_batch=True,
    data_range=255,
    denormalize=False,
    change_range=True,
    imtype=np.uint8,
):
    """
    Converts a Tensor array into a numpy image array.
    Parameters:
        img (tensor): the input image tensor array
            4D(B,(3/1),H,W), 3D(C,H,W), or 2D(H,W), any range, RGB channel order
        remove_batch (bool): choose if tensor of shape BCHW needs to be squeezed
        denormalize (bool): Used to denormalize from [-1,1] range back to [0,1]
        imtype (type): the desired type of the converted numpy array (np.uint8
            default)
    Output:
        img (np array): 3D(H,W,C) or 2D(H,W), [0,255], np.uint8 (default)
    """
    if not isinstance(img, torch.Tensor):
        raise TypeError("Got unexpected object type, expected torch.Tensor")
    n_dim = img.dim()

    # TODO: Check: could denormalize here in tensor form instead, but end result is the same

    img = img.float().cpu()

    if n_dim in [4, 3]:
        # if n_dim == 4, has to convert to 3 dimensions, either removing batch or by creating a grid
        if n_dim == 4 and remove_batch:
            if img.shape[0] > 1:
                # leave only the first image in the batch
                img = img[0, ...]
            else:
                # remove a fake batch dimension
                img = img.squeeze()
                # squeeze removes batch and channel of grayscale images (dimensions = 1)
                if len(img.shape) < 3:
                    # add back the lost channel dimension
                    img = img.unsqueeze(dim=0)
        # convert images in batch (BCHW) to a grid of all images (C B*H B*W)
        else:
            n_img = len(img)
            img = make_grid(img, nrow=int(math.sqrt(n_img)), normalize=False)

        if img.shape[0] == 3 and rgb2bgr:  # RGB
            # RGB to BGR -> in tensor, if using OpenCV, else not needed. Only if image has colors.
            img_np = rgb_to_bgr(img).numpy()
        elif img.shape[0] == 4 and rgb2bgr:  # RGBA
            # RGBA to BGRA -> in tensor, if using OpenCV, else not needed. Only if image has colors.
            img_np = rgba_to_bgra(img).numpy()
        else:
            img_np = img.numpy()
        img_np = np.transpose(img_np, (1, 2, 0))  # "CHW to HWC" -> # HWC, BGR
    elif n_dim == 2:
        img_np = img.numpy()
    else:
        raise TypeError("Only support 4D, 3D and 2D tensor. But received with dimension: {:d}".format(n_dim))

    # if rgb2bgr:
    # img_np = img_np[[2, 1, 0], :, :] #RGB to BGR -> in numpy, if using OpenCV, else not needed. Only if image has colors.
    # TODO: Check: could denormalize in the begining in tensor form instead
    if denormalize:
        img_np = denorm(img_np)  # denormalize if needed
    if change_range:
        # clip to the data_range
        img_np = np.clip(data_range * img_np, 0, data_range).round()
        # Important. Unlike matlab, numpy.unit8() WILL NOT round by default.
    # has to be in range (0,255) before changing to np.uint8, else np.float32
    return img_np.astype(imtype)


def auto_split_upscale(lr_img, upscale_function, scale=4, overlap=32, max_depth=None, current_depth=1):
    if current_depth > 1 and (lr_img.shape[0] == lr_img.shape[1] == overlap):
        raise RecursionError("Reached bottom of recursion depth.")

    # Attempt to upscale if unknown depth or if reached known max depth
    if max_depth is None or max_depth == current_depth:
        try:
            result = upscale_function(lr_img)
            return result, current_depth
        except RuntimeError as e:
            if "allocate" not in str(e):
                raise RuntimeError(e) from e

            # Collect garbage (clear VRAM)
            torch.cuda.empty_cache()
            gc.collect()
    h, w, c = lr_img.shape

    # Split image into 4ths
    top_left = lr_img[: h // 2 + overlap, : w // 2 + overlap, :]
    top_right = lr_img[: h // 2 + overlap, w // 2 - overlap :, :]
    bottom_left = lr_img[h // 2 - overlap :, : w // 2 + overlap, :]
    bottom_right = lr_img[h // 2 - overlap :, w // 2 - overlap :, :]

    # Recursively upscale the quadrants
    # After we go through the top left quadrant, we know the maximum depth and no longer need to test for out-of-memory
    top_left_rlt, depth = auto_split_upscale(
        top_left,
        upscale_function,
        scale=scale,
        overlap=overlap,
        current_depth=current_depth + 1,
    )
    top_right_rlt, _ = auto_split_upscale(
        top_right,
        upscale_function,
        scale=scale,
        overlap=overlap,
        max_depth=depth,
        current_depth=current_depth + 1,
    )
    bottom_left_rlt, _ = auto_split_upscale(
        bottom_left,
        upscale_function,
        scale=scale,
        overlap=overlap,
        max_depth=depth,
        current_depth=current_depth + 1,
    )
    bottom_right_rlt, _ = auto_split_upscale(
        bottom_right,
        upscale_function,
        scale=scale,
        overlap=overlap,
        max_depth=depth,
        current_depth=current_depth + 1,
    )

    # Define output shape
    out_h = h * scale
    out_w = w * scale

    # Create blank output image
    output_img = np.zeros((out_h, out_w, c), np.uint8)

    # Fill output image with tiles, cropping out the overlaps
    output_img[: out_h // 2, : out_w // 2, :] = top_left_rlt[: out_h // 2, : out_w // 2, :]
    output_img[: out_h // 2, -out_w // 2 :, :] = top_right_rlt[: out_h // 2, -out_w // 2 :, :]
    output_img[-out_h // 2 :, : out_w // 2, :] = bottom_left_rlt[-out_h // 2 :, : out_w // 2, :]
    output_img[-out_h // 2 :, -out_w // 2 :, :] = bottom_right_rlt[-out_h // 2 :, -out_w // 2 :, :]

    return output_img, depth

</document_content>
</document>
<document index="36">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/io.py</source>
<document_content>
"""io.py"""
import csv
from glob import glob
import os
from pathlib import Path
import re
from typing import List, Optional, Tuple, Union

from dask import array as da, delayed
import numpy as np

from cerebro_bot.utils.misc import abspath_or_url


# SOURCE: https://github.com/napari/napari/blob/5f96d5d814aad697c367bdadbb1a57750e2114ad/napari/utils/io.py
def imread(filename: str) -> np.ndarray:
    """Custom implementation of imread to avoid skimage dependency.
    Parameters
    ----------
    filename : string
        The path from which to read the image.
    Returns
    -------
    data : np.ndarray
        The image data.
    """
    filename = abspath_or_url(filename)

    import imageio

    return imageio.imread(filename)


def _alphanumeric_key(s):
    """Convert string to list of strings and ints that gives intuitive sorting.

    Parameters
    ----------
    s : string

    Returns
    -------
    k : a list of strings and ints

    Examples
    --------
    >>> _alphanumeric_key('z23a')
    ['z', 23, 'a']
    >>> filenames = ['f9.10.png', 'e10.png', 'f9.9.png', 'f10.10.png',
    ...              'f10.9.png']
    >>> sorted(filenames)
    ['e10.png', 'f10.10.png', 'f10.9.png', 'f9.10.png', 'f9.9.png']
    >>> sorted(filenames, key=_alphanumeric_key)
    ['e10.png', 'f9.9.png', 'f9.10.png', 'f10.9.png', 'f10.10.png']
    """
    return [int(c) if c.isdigit() else c for c in re.split("([0-9]+)", s)]


# SOURCE: https://github.com/napari/napari/blob/main/napari/plugins/io.py
def magic_imread(filenames, *, use_dask=None, stack=True):
    """Dispatch the appropriate reader given some files.

    The files are assumed to all have the same shape.

    Parameters
    ----------
    filenames : list
        List of filenames or directories to be opened.
        A list of `pathlib.Path` objects and a single filename or `Path` object
        are also accepted.
    use_dask : bool
        Whether to use dask to create a lazy array, rather than NumPy.
        Default of None will resolve to True if filenames contains more than
        one image, False otherwise.
    stack : bool
        Whether to stack the images in multiple files into a single array. If
        False, a list of arrays will be returned.

    Returns
    -------
    image : array-like
        Array or list of images
    """
    # cast Path to string
    if isinstance(filenames, Path):
        filenames = filenames.as_posix()

    if len(filenames) == 0:
        return None
    if isinstance(filenames, str):
        filenames = [filenames]  # ensure list

    # replace folders with their contents
    filenames_expanded = []
    for filename in filenames:
        # zarr files are folders, but should be read as 1 file
        if os.path.isdir(filename):
            dir_contents = sorted(glob(os.path.join(filename, "*.*")), key=_alphanumeric_key)
            # remove subdirectories
            dir_contents_files = filter(lambda f: not os.path.isdir(f), dir_contents)
            filenames_expanded.extend(dir_contents_files)
        else:
            filenames_expanded.append(filename)

    if use_dask is None:
        use_dask = len(filenames_expanded) > 1

    if not filenames_expanded:
        raise ValueError(f"No files found in {filenames} after removing subdirectories")

    # then, read in images
    images = []
    shape = None
    for filename in filenames_expanded:
        if shape is None:
            image = imread(filename)
            shape = image.shape
            dtype = image.dtype
        if use_dask:
            image = da.from_delayed(delayed(imread)(filename), shape=shape, dtype=dtype)
        elif len(images) > 0:  # not read by shape clause
            image = imread(filename)
        images.append(image)
    if len(images) == 1:
        image = images[0]
    elif stack:
        if use_dask:
            image = da.stack(images)
        else:
            try:
                image = np.stack(images)
            except ValueError as e:
                if "input arrays must have the same shape" not in str(e):
                    raise e
                msg = (
                    "To stack multiple files into a single array with "
                    "numpy, all input arrays must have the same shape."
                    " Set `use_dask` to True to stack arrays with "
                    "different shapes."
                )
                raise ValueError(msg) from e
    else:
        image = images  # return a list
    return image


# def guess_zarr_path(path):
#     """Guess whether string path is part of a zarr hierarchy.

#     Parameters
#     ----------
#     path : str
#         Path to a file or directory.

#     Returns
#     -------
#     bool
#         Whether path is for zarr.
#     >>> guess_zarr_path('dataset.zarr')
#     True
#     >>> guess_zarr_path('dataset.zarr/path/to/array')
#     True
#     >>> guess_zarr_path('dataset.zarr/component.png')
#     True
#     """
#     return any(part.endswith(".zarr") for part in Path(path).parts)


# def read_zarr_dataset(path):
#     """Read a zarr dataset, including an array or a group of arrays.

#     Parameters
#     ----------
#     path : str
#         Path to directory ending in '.zarr'. Path can contain either an array
#         or a group of arrays in the case of multiscale data.
#     Returns
#     -------
#     image : array-like
#         Array or list of arrays
#     shape : tuple
#         Shape of array or first array in list
#     """
#     if os.path.exists(os.path.join(path, ".zarray")):
#         # load zarr array
#         image = da.from_zarr(path)
#         shape = image.shape
#     elif os.path.exists(os.path.join(path, ".zgroup")):
#         # else load zarr all arrays inside file, useful for multiscale data
#         image = []
#         for subpath in sorted(os.listdir(path)):
#             if not subpath.startswith("."):
#                 image.append(read_zarr_dataset(os.path.join(path, subpath))[0])
#         shape = image[0].shape
#     else:
#         raise ValueError(f"Not a zarr dataset or group: {path}")
#     return image, shape


def write_csv(
    filename: str,
    data: Union[List, np.ndarray],
    column_names: Optional[List[str]] = None,
):
    """Write a csv file.

    Parameters
    ----------
    filename : str
        Filename for saving csv.
    data : list or ndarray
        Table values, contained in a list of lists or an ndarray.
    column_names : list, optional
        List of column names for table data.
    """
    with open(filename, mode="w", newline="") as csvfile:
        writer = csv.writer(
            csvfile,
            delimiter=",",
            quotechar='"',
            quoting=csv.QUOTE_MINIMAL,
        )
        if column_names is not None:
            writer.writerow(column_names)
        for row in data:
            writer.writerow(row)


def guess_layer_type_from_column_names(
    column_names: List[str],
) -> Optional[str]:
    """Guess layer type based on column names from a csv file.

    Parameters
    ----------
    column_names : list of str
        List of the column names from the csv.

    Returns
    -------
    str or None
        Layer type if recognized, otherwise None.
    """

    if {"index", "shape-type", "vertex-index", "axis-0", "axis-1"}.issubset(column_names):
        return "shapes"
    elif {"axis-0", "axis-1"}.issubset(column_names):
        return "points"
    else:
        return None


def read_csv(filename: str, require_type: str = None) -> Tuple[np.array, List[str], Optional[str]]:
    """Return CSV data only if column names match format for ``require_type``.

    Reads only the first line of the CSV at first, then optionally raises an
    exception if the column names are not consistent with a known format, as
    determined by the ``require_type`` argument and
    :func:`guess_layer_type_from_column_names`.

    Parameters
    ----------
    filename : str
        Path of file to open
    require_type : str, optional
        The desired layer type. If provided, should be one of the keys in
        ``csv_reader_functions`` or the string "any".  If ``None``, data, will
        not impose any format requirements on the csv, and data will always be
        returned.  If ``any``, csv must be recognized as one of the valid layer
        data formats, otherwise a ``ValueError`` will be raised.  If a specific
        layer type string, then a ``ValueError`` will be raised if the column
        names are not of the predicted format.

    Returns
    -------
    (data, column_names, layer_type) : Tuple[np.array, List[str], str]
        The table data and column names from the CSV file, along with the
        detected layer type (string).

    Raises
    ------
    ValueError
        If the column names do not match the format requested by
        ``require_type``.
    """
    with open(filename, newline="") as csvfile:
        reader = csv.reader(csvfile, delimiter=",")
        column_names = next(reader)

        layer_type = guess_layer_type_from_column_names(column_names)
        if require_type:
            if not layer_type:
                raise ValueError(f'File "{filename}" not recognized as valid Layer data')
            elif layer_type != require_type and require_type.lower() != "any":
                raise ValueError(f'File "{filename}" not recognized as {require_type} data')

        data = np.array(list(reader))
    return data, column_names, layer_type


# def csv_to_layer_data(path: str, require_type: str = None) -> Optional[FullLayerData]:
#     """Return layer data from a CSV file if detected as a valid type.

#     Parameters
#     ----------
#     path : str
#         Path of file to open
#     require_type : str, optional
#         The desired layer type. If provided, should be one of the keys in
#         ``csv_reader_functions`` or the string "any".  If ``None``,
#         unrecognized CSV files will simply return ``None``.  If ``any``,
#         unrecognized CSV files will raise a ``ValueError``.  If a specific
#         layer type string, then a ``ValueError`` will be raised if the column
#         names are not of the predicted format.

#     Returns
#     -------
#     layer_data : tuple, or None
#         3-tuple ``(array, dict, str)`` (points data, metadata, layer_type) if
#         CSV is recognized as a valid type.

#     Raises
#     ------
#     ValueError
#         If ``require_type`` is not ``None``, but the CSV is not detected as a
#         valid data format.
#     """
#     try:
#         # pass at least require "any" here so that we don't bother reading the
#         # full dataset if it's not going to yield valid layer_data.
#         _require = require_type or "any"
#         table, column_names, _type = read_csv(path, require_type=_require)
#     except ValueError:
#         if not require_type:
#             return None
#         raise
#     if _type in csv_reader_functions:
#         return csv_reader_functions[_type](table, column_names)
#     return None  # only reachable if it is a valid layer type without a reader


# def _points_csv_to_layerdata(
#     table: np.ndarray, column_names: List[str]
# ) -> FullLayerData:
#     """Convert table data and column names from a csv file to Points LayerData.

#     Parameters
#     ----------
#     table : np.ndarray
#         CSV data.
#     column_names : list of str
#         The column names of the csv file

#     Returns
#     -------
#     layer_data : tuple
#         3-tuple ``(array, dict, str)`` (points data, metadata, 'points')
#     """

#     data_axes = [cn.startswith("axis-") for cn in column_names]
#     data = np.array(table[:, data_axes]).astype("float")

#     # Add properties to metadata if provided
#     prop_axes = np.logical_not(data_axes)
#     if column_names[0] == "index":
#         prop_axes[0] = False
#     meta = {}
#     if np.any(prop_axes):
#         meta["properties"] = {}
#         for ind in np.nonzero(prop_axes)[0]:
#             values = table[:, ind]
#             try:
#                 values = np.array(values).astype("int")
#             except ValueError:
#                 try:
#                     values = np.array(values).astype("float")
#                 except ValueError:
#                     pass
#             meta["properties"][column_names[ind]] = values

#     return data, meta, "points"


# def _shapes_csv_to_layerdata(
#     table: np.ndarray, column_names: List[str]
# ) -> FullLayerData:
#     """Convert table data and column names from a csv file to Shapes LayerData.

#     Parameters
#     ----------
#     table : np.ndarray
#         CSV data.
#     column_names : list of str
#         The column names of the csv file

#     Returns
#     -------
#     layer_data : tuple
#         3-tuple ``(array, dict, str)`` (points data, metadata, 'shapes')
#     """

#     data_axes = [cn.startswith("axis-") for cn in column_names]
#     raw_data = np.array(table[:, data_axes]).astype("float")

#     inds = np.array(table[:, 0]).astype("int")
#     n_shapes = max(inds) + 1
#     # Determine when shape id changes
#     transitions = list((np.diff(inds)).nonzero()[0] + 1)
#     shape_boundaries = [0] + transitions + [len(table)]
#     if n_shapes != len(shape_boundaries) - 1:
#         raise ValueError("Expected number of shapes not found")

#     data = []
#     shape_type = []
#     for ind_a, ind_b in zip(shape_boundaries[:-1], shape_boundaries[1:]):
#         data.append(raw_data[ind_a:ind_b])
#         shape_type.append(table[ind_a, 1])

#     return data, {"shape_type": shape_type}, "shapes"


# csv_reader_functions = {
#     "points": _points_csv_to_layerdata,
#     "shapes": _shapes_csv_to_layerdata,
# }

</document_content>
</document>
<document index="37">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/misc.py</source>
<document_content>
"""Miscellaneous utility functions."""

# pylint: disable=no-member
from __future__ import annotations

# import collections
import inspect
import itertools
from os import PathLike, fspath, path
import re
import sys
from typing import TYPE_CHECKING, List, Optional, Sequence, Type, TypeVar

import numpy as np

if TYPE_CHECKING:
    import packaging.version


ROOT_DIR = path.dirname(path.dirname(__file__))

try:
    from importlib import metadata as importlib_metadata
except ImportError:
    import importlib_metadata  # noqa


def parse_version(v) -> "packaging.version._BaseVersion":
    """Parse a version string and return a packaging.version.Version obj."""
    import packaging.version

    # try:
    return packaging.version.Version(v)
    # except packaging.version.InvalidVersion:
    # return packaging.version.LegacyVersion(v)


def running_as_bundled_app() -> bool:
    """Infer whether we are running as a briefcase bundle"""
    # https://github.com/beeware/briefcase/issues/412
    # https://github.com/beeware/briefcase/pull/425
    app_module = sys.modules["__main__"].__package__
    try:
        metadata = importlib_metadata.metadata(app_module)
    except importlib_metadata.PackageNotFoundError:
        return False

    return "Briefcase-Version" in metadata


def bundle_bin_dir() -> Optional[str]:
    """Return path to briefcase app_packages/bin if it exists."""
    bin = path.join(path.dirname(sys.exec_prefix), "app_packages", "bin")
    if path.isdir(bin):
        return bin


# def in_jupyter() -> bool:
#     """Return true if we're running in jupyter notebook/lab or qtconsole."""
#     try:
#         from IPython import get_ipython

#         return get_ipython().__class__.__name__ == "ZMQInteractiveShell"
#     except Exception:
#         pass
#     return False


# def in_ipython() -> bool:
#     """Return true if we're running in an IPython interactive shell."""
#     try:
#         from IPython import get_ipython

#         return get_ipython().__class__.__name__ == "TerminalInteractiveShell"
#     except Exception:
#         pass
#     return False


def str_to_rgb(arg):
    """Convert an rgb string 'rgb(x,y,z)' to a list of ints [x,y,z]."""
    return list(map(int, re.match(r"rgb\((\d+),\s*(\d+),\s*(\d+)\)", arg).groups()))


def ensure_iterable(arg, color=False):
    """Ensure an argument is an iterable. Useful when an input argument
    can either be a single value or a list. If a color is passed then it
    will be treated specially to determine if it is iterable.
    """
    return arg if is_iterable(arg, color=color) else itertools.repeat(arg)


def is_iterable(arg, color=False):
    """Determine if a single argument is an iterable. If a color is being
    provided and the argument is a 1-D array of length 3 or 4 then the input
    is taken to not be iterable.
    """
    if arg is None:
        return False
    elif type(arg) is str:
        return False
    elif np.isscalar(arg):
        return False
    elif color and isinstance(arg, (list, np.ndarray)):
        return np.array(arg).ndim != 1 or len(arg) not in [3, 4]
    else:
        return True


def is_sequence(arg):
    """Check if ``arg`` is a sequence like a list or tuple.

    return True:
        list
        tuple
    return False
        string
        numbers
        dict
        set
    """
    return isinstance(arg, Sequence) and not isinstance(arg, str)


def ensure_sequence_of_iterables(obj, length: Optional[int] = None):
    """Ensure that ``obj`` behaves like a (nested) sequence of iterables.

    If length is provided and the object is already a sequence of iterables,
    a ValueError will be raised if ``len(obj) != length``.

    Parameters
    ----------
    obj : Any
        the object to check
    length : int, optional
        If provided, assert that obj has len ``length``, by default None

    Returns
    -------
    iterable
        nested sequence of iterables, or an itertools.repeat instance

    Examples
    --------
    In [1]: ensure_sequence_of_iterables([1, 2])
    Out[1]: repeat([1, 2])

    In [2]: ensure_sequence_of_iterables([(1, 2), (3, 4)])
    Out[2]: [(1, 2), (3, 4)]

    In [3]: ensure_sequence_of_iterables({'a':1})
    Out[3]: repeat({'a': 1})

    In [4]: ensure_sequence_of_iterables(None)
    Out[4]: repeat(None)
    """

    if obj is not None and is_sequence(obj) and is_iterable(obj[0]):
        if length is not None and len(obj) != length:
            raise ValueError(f"length of {obj} must equal {length}")
        return obj
    return itertools.repeat(obj)


def formatdoc(obj):
    """Substitute globals and locals into an object's docstring."""
    frame = inspect.currentframe().f_back
    try:
        obj.__doc__ = obj.__doc__.format(**{**frame.f_globals, **frame.f_locals})
        return obj
    finally:
        del frame


camel_to_snake_pattern = re.compile(r"(.)([A-Z][a-z]+)")
camel_to_spaces_pattern = re.compile(r"((?<=[a-z])[A-Z]|(?<!\A)[A-R,T-Z](?=[a-z]))")


def camel_to_snake(name):
    # https://gist.github.com/jaytaylor/3660565
    return camel_to_snake_pattern.sub(r"\1_\2", name).lower()


def camel_to_spaces(val):
    return camel_to_spaces_pattern.sub(r" \1", val)


T = TypeVar("T", str, Sequence[str])


def abspath_or_url(relpath: T) -> T:
    """Utility function that normalizes paths or a sequence thereof.

    Expands user directory and converts relpaths to abspaths... but ignores
    URLS that begin with "http", "ftp", or "file".

    Parameters
    ----------
    relpath : str or list or tuple
        A path, or list or tuple of paths.

    Returns
    -------
    abspath : str or list or tuple
        An absolute path, or list or tuple of absolute paths (same type as
        input).
    """
    from urllib.parse import urlparse

    if isinstance(relpath, (tuple, list)):
        return type(relpath)(abspath_or_url(p) for p in relpath)

    if isinstance(relpath, (str, PathLike)):
        relpath = fspath(relpath)
        urlp = urlparse(relpath)
        if urlp.scheme and urlp.netloc:
            return relpath
        return path.abspath(path.expanduser(relpath))

    raise TypeError("Argument must be a string, PathLike, or sequence thereof")


class CallDefault(inspect.Parameter):
    def __str__(self):
        """wrap defaults"""
        kind = self.kind
        formatted = self._name

        # Fill in defaults
        if self._default is not inspect._empty or kind == inspect._KEYWORD_ONLY:
            formatted = f"{formatted}={formatted}"

        if kind == inspect._VAR_POSITIONAL:
            formatted = f"*{formatted}"
        elif kind == inspect._VAR_KEYWORD:
            formatted = f"**{formatted}"

        return formatted


class CallSignature(inspect.Signature):
    _parameter_cls = CallDefault

    def __str__(self):
        """do not render separators

        commented code is what was taken out from
        the copy/pasted inspect module code :)
        """
        result = [str(param) for param in self.parameters.values()]
        rendered = f'({", ".join(result)})'

        if self.return_annotation is not inspect._empty:
            anno = inspect.formatannotation(self.return_annotation)
            rendered += f" -> {anno}"

        return rendered


callsignature = CallSignature.from_callable


def all_subclasses(cls: Type) -> set:
    """Recursively find all subclasses of class ``cls``.

    Parameters
    ----------
    cls : class
        A python class (or anything that implements a __subclasses__ method).

    Returns
    -------
    set
        the set of all classes that are subclassed from ``cls``
    """
    return set(cls.__subclasses__()).union([s for c in cls.__subclasses__() for s in all_subclasses(c)])


def ensure_n_tuple(val, n, fill=0):
    """Ensure input is a length n tuple.

    Parameters
    ----------
    val : iterable
        Iterable to be forced into length n-tuple.
    n : int
        Length of tuple.

    Returns
    -------
    tuple
        Coerced tuple.
    """
    assert n > 0, "n must be greater than 0"
    tuple_value = tuple(val)
    return (fill,) * (n - len(tuple_value)) + tuple_value[-n:]


def ensure_layer_data_tuple(val):
    if not (isinstance(val, tuple) and (0 < len(val) <= 3)):
        raise TypeError(f"Not a valid layer data tuple: {val!r}")
    return val


def ensure_list_of_layer_data_tuple(val):
    if isinstance(val, list) and len(val):
        try:
            return [ensure_layer_data_tuple(v) for v in val]
        except TypeError:
            pass
    raise TypeError("Not a valid list of layer data tuples!")


# SOURCE: https://gist.github.com/garrettdreyfus/8153571
def yesno(question, force: bool = False):
    """Simple Yes/No Function."""
    force = force
    prompt = f"{question} ? (y/n): "
    ans = input(prompt).strip().lower()
    if ans not in ["y", "n"] and not force:
        print(f"{ans} is invalid, please try again...")
        return yesno(question)
    return ans == "y" or force


# Yield successive n-sized
# chunks from l.
# SOURCE: https://www.geeksforgeeks.org/break-list-chunks-size-n-python/
def divide_chunks(l: List[str], n: int = 10):
    # looping till length l
    for i in range(0, len(l), n):
        yield l[i : i + n]

</document_content>
</document>
<document index="38">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/naming.py</source>
<document_content>
"""Automatically generate names.
"""

import collections

# try:  # python 3
#     pass
# except ImportError:  # python 2
#     pass
import inspect
import re

from cerebro_bot.utils.misc import formatdoc

sep = " "
start = 1

# Match integer between square brackets at end of string if after space
# or at beginning of string or just match end of string
numbered_patt = re.compile(r"((?<=\A\[)|(?<=\s\[))(?:\d+|)(?=\]$)|$")


def _inc_name_count_sub(match):
    count = match.group(0)

    try:
        count = int(count)
    except ValueError:  # not an int
        count = f"{sep}[{start}]"
    else:
        count = f"{count + 1}"

    return count


@formatdoc
def inc_name_count(name):
    """Increase a name's count matching `{numbered_patt}` by ``1``.

    If the name is not already numbered, append '{sep}[{start}]'.

    Parameters
    ----------
    name : str
        Original name.

    Returns
    -------
    incremented_name : str
        Numbered name incremented by ``1``.
    """
    return numbered_patt.sub(_inc_name_count_sub, name, count=1)


def magic_name(value, *, path_prefix):
    """Fetch the name of the variable with the given value passed to the calling function.

    Parameters
    ----------
    value : any
        The value of the desired variable.
    path_prefix : absolute path-like, kwonly
        The path prefixes to ignore.

    Returns
    -------
    name : str or None
        Name of the variable, if found.
    """
    frame = inspect.currentframe()
    try:
        # See issue #1635 regarding potential AttributeError
        # since frame could be None.
        # https://github.com/cerebro_bot/cerebro_bot/pull/1635
        if inspect.isframe(frame):
            frame = frame.f_back

        # Iterate frames while filename starts with path_prefix (part of cerebro_bot)
        # or is autogenerated such as for the add_* for layers (#1694 / #1709)
        while (
            inspect.isframe(frame)
            and inspect.iscode(frame.f_code)
            and (frame.f_code.co_filename.startswith(path_prefix) or frame.f_code.co_filename == "<string>")
        ):
            frame = frame.f_back

        if inspect.isframe(frame) and inspect.iscode(frame.f_code):
            varmap = collections.ChainMap(frame.f_locals, frame.f_globals)
            names = *frame.f_code.co_varnames, *frame.f_code.co_names

            for name in names:
                if name.isidentifier() and name in varmap and varmap[name] is value:
                    return name
        return None
    finally:
        # We need to delete the frame explicitly according to the inspect
        # documentation for deterministic removal of the frame.
        # Otherwise, proper deletion is dependent on a cycle detector and
        # automatic garbage collection.
        # See handle_stackframe_without_leak example at the following URLs:
        # https://docs.python.org/3/library/inspect.html#the-interpreter-stack
        # https://bugs.python.org/issue543148
        del frame
        del frame

</document_content>
</document>
<document index="39">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/paths.py</source>
<document_content>
# inspired by boucanpy
from os.path import abspath, dirname, join

_utils_dir = abspath(dirname(__file__))


def _ajoin(target: str, path: str) -> str:
    return abspath(join(target, path))


# # smoke tests
# if __name__ == "__main__":
#     from cerebro_bot.utils import paths

#     print(paths._utils_dir)
#     print(paths._ajoin("foo", "bar"))

</document_content>
</document>
<document index="40">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/tables.py</source>
<document_content>
# importing required library
from prettytable import PrettyTable


def get_model_lookup_table():
    # creating an empty PrettyTable
    x = PrettyTable()

    # adding data into the table
    # row by row
    x.field_names = ["Model", "Description", "Samples"]
    x.add_row(
        [
            "1x_ArtClarity.pth",
            "Texture retaining denoiser and sharpener for digital artwork",
            "n/a",
        ]
    )
    x.add_row(
        [
            "1x_ArtClarity_strong.pth",
            "Texture retaining denoiser and sharpener for digital artwork",
            "n/a",
        ]
    )
    x.add_row(
        [
            "1x_DeSharpen.pth",
            "Made for rare particular cases when the image was destroyed by applying noise, i.e. game textures or any badly exported photos. If your image does not have any oversharpening, it won't hurt them, leaving as is. In theory, this model knows when to activate and when to skip, also can successfully remove artifacts if only some parts of the image are oversharpened, for example in image consisting of several combined images, 1 of them with sharpen noise.",
            "n/a",
        ]
    )
    x.add_row(["1x_NoiseToner-Poisson-Detailed_108000_G.pth", "Noise remover", "n/a"])
    x.add_row(["1x_NoiseToner-Poisson-Soft_101000_G.pth", "Noise remover", "n/a"])
    x.add_row(["1x_NoiseToner-Uniform-Detailed_100000_G.pth", "Noise remover", "n/a"])
    x.add_row(["1x_NoiseToner-Uniform-Soft_100000_G.pth", "Noise remover", "n/a"])
    x.add_row(["1x_NoiseTonerV1_110000_G.pth", "Noise remover", "n/a"])
    x.add_row(["1x_NoiseTonerV2_105000_G.pth", "Noise remover", "n/a"])
    x.add_row(["1x_NoiseToner_Poisson_150000_G.pth", "Noise remover", "n/a"])
    x.add_row(["1x_NoiseToner_Uniform_100000_G.pth", "Noise remover", "n/a"])
    x.add_row(["1x_PixelSharpen_v2.pth", "Restores blurry/upscaled pixel art.", "n/a"])
    x.add_row(["1x_PixelSharpen_v2_strong.pth", "Restores blurry/upscaled pixel art.", "n/a"])
    x.add_row(["1x_ReContrast.pth", "n/a", "n/a"])
    x.add_row(
        [
            "2x_KemonoScale_v2.pth",
            "Anime. Upscaling frames from Irodori anime (namely kemono friends) from 540p (the source render resolution) to 1080p, low resolution flat shaded art, de-JPEG of the aforementioned",
            "n/a",
        ]
    )
    x.add_row(
        [
            "2x_MangaScaleV3.pth",
            "To upscale manga including halftones, instead of trying to smooth them out.",
            "n/a",
        ]
    )
    x.add_row(
        [
            "4x-UltraSharp.pth",
            "Universal Upscaler. This is my best model yet! It generates lots and lots of detail and leaves a nice texture on images. It works on most images, whether compressed or not. It does work best on JPEG compression though, as that's mostly what it was trained on. It has the ability to restore highly compressed images as well!",
            "n/a",
        ]
    )
    x.add_row(
        [
            "4xFSMangaV2.pth",
            "Manga-style images with or without dithering - cartoons, maybe pixel art, etc	",
            "n/a",
        ]
    )
    x.add_row(["4x_BigFace_v3.pth", "Art/People", "n/a"])
    x.add_row(["4x_BigFace_v3_Blend.pth", "Art/People", "n/a"])
    x.add_row(["4x_BigFace_v3_Clear.pth", "Art/People", "n/a"])
    x.add_row(
        [
            "4x_BooruGan_600k.pth",
            "Anime This model is designed to mainly upscale anime artworks. If you have issues with chroma then try the 600k iterations release.",
            "n/a",
        ]
    )
    x.add_row(
        [
            "4x_BooruGan_650k.pth",
            "Anime This model is designed to mainly upscale anime artworks. If you have issues with chroma then try the 600k iterations release.",
            "n/a",
        ]
    )
    x.add_row(
        [
            "4x_CountryRoads_377000_G.pth",
            "Universal Upscaler. Streets with dense foliage in the background. Outdoor scenes.",
            "n/a",
        ]
    )
    x.add_row(
        [
            "4x_FArtDIV3_Base.pth",
            "Art. Painting style with larger shaped features",
            "n/a",
        ]
    )
    x.add_row(
        [
            "4x_FArtDIV3_Blend.pth",
            "Art. Painting style with larger shaped features",
            "n/a",
        ]
    )
    x.add_row(
        [
            "4x_FArtDIV3_Fine.pth",
            "Art. Painting style with larger shaped features",
            "n/a",
        ]
    )
    x.add_row(
        [
            "4x_FArtDIV3_UltraMix4.pth",
            "Art. Painting style with larger shaped features",
            "n/a",
        ]
    )
    x.add_row(["4x_FArtFace.pth", "Art. Painting style with larger shaped features", "n/a"])
    x.add_row(
        [
            "4x_FArtSuperBlend.pth",
            "Art. Painting style with larger shaped features",
            "n/a",
        ]
    )
    x.add_row(
        [
            "4x_FatalPixels_340000_G.pth",
            "Pixel Art/Sprites. Dataset. Anime, Manga",
            "n/a",
        ]
    )
    x.add_row(
        [
            "4x_Fatality_Faces_310000_G.pth",
            "Pixel Art/Sprites. Upscales medium resolution Sprites, dithered or undithered, can also upscale manga/anime and gameboy camera images.",
            "n/a",
        ]
    )
    x.add_row(["4x_Unholy_FArt.pth", "description", "n/a"])
    x.add_row(
        [
            "4x_Valar_v1.pth",
            "Realistic Photos. Meant as an experiment to test latest techniques implemented on traiNNer, including: AdaTarget, KernelGAN, UNet discriminator, nESRGAN+ arch, noise patches, camera noise, isotropic/anisotropic/sinc blur, frequency separation, contextual loss, mixup, clipL1 pixel loss, AdamP optimizer, etc. The config file is provided on the download link above. I encourage everybody to mirror the model, distribute and modify it in anywway you want.",
            "n/a",
        ]
    )
    x.add_row(
        [
            "4x_detoon_225k.pth",
            "Pixel art/sprites. For upscaling character sprites",
            "n/a",
        ]
    )
    x.add_row(
        [
            "8x_BoyMeBob-Redux_200000_G.pth",
            "Upscaling cartoons. ESRGAN+ (Joey's fork, eFonte fork, or iNNfer required to use)",
            "n/a",
        ]
    )
    x.add_row(
        [
            "8x_NMKD-Typescale_175k.pth",
            "Text. Low-resolution text/typography and symbols",
            "n/a",
        ]
    )
    x.add_row(["KemonoClean.pth", "n/a", "n/a"])
    x.add_row(
        [
            "LADDIER1_282500_G.pth",
            "Denoise. Remove noise, grain, box blur, lens blur and gaussian blur and increase overall image quality.",
            "n/a",
        ]
    )
    x.add_row(
        [
            "RRDB_ESRGAN_x4.pth",
            "Game textures. Various game textures. Primary wood, metal, stone",
            "n/a",
        ]
    )
    x.add_row(
        [
            "RRDB_ESRGAN_x4_old_arch.pth",
            "Game textures. Various game textures. Primary wood, metal, stone",
            "n/a",
        ]
    )
    x.add_row(
        [
            "RRDB_PSNR_x4.pth",
            "pretrained model. The original RRDB_PSNR_x4.pth model converted to 1x, 2x, 8x and 16x scales, intended to be used as pretrained models for new models at those scales. These are compatible with victor's 4xESRGAN.pth conversions",
            "n/a",
        ]
    )
    x.add_row(
        [
            "RRDB_PSNR_x4_old_arch.pth",
            "pretrained model. The original RRDB_PSNR_x4.pth model converted to 1x, 2x, 8x and 16x scales, intended to be used as pretrained models for new models at those scales. These are compatible with victor's 4xESRGAN.pth conversions",
            "n/a",
        ]
    )
    x.add_row(["RealESRGANv2-animevideo-xsx2.pth", "anime", "n/a"])
    x.add_row(["RealESRGANv2-animevideo-xsx4.pth", "anime", "n/a"])
    x.add_row(["TGHQFace8x_500k.pth", "Painted humans", "n/a"])
    x.add_row(["detoon_alt.pth", "cartoons", "n/a"])
    x.add_row(["furry_12400_G.pth", "description", "n/a"])

    # printing generated table
    print(x)
    return x

</document_content>
</document>
<document index="41">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/temporary_file.py</source>
<document_content>
"""temporary_file.py"""
from contextlib import contextmanager
import os
from tempfile import NamedTemporaryFile


@contextmanager
def temporary_file(suffix=""):
    """Yield a writable temporary filename that is deleted on context exit.
    Parameters
    ----------
    suffix : string, optional
        The suffix for the file.
    Examples
    --------
    >>> import numpy as np
    >>> from cerebro_bot.utils import io
    >>> with temporary_file('.tif') as tempfile:
    ...     im = np.arange(25, dtype=np.uint8).reshape((5, 5))
    ...     io.imsave(tempfile, im)
    ...     assert np.all(io.imread(tempfile) == im)
    """
    tempfile_stream = NamedTemporaryFile(suffix=suffix, delete=False)
    tempfile = tempfile_stream.name
    tempfile_stream.close()
    yield tempfile
    os.remove(tempfile)

</document_content>
</document>
<document index="42">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/unpickler.py</source>
<document_content>
"""unpickler.py"""
# https://github.com/universityofprofessorex/ESRGAN-Bot
# Attribution - NonCommercial - ShareAlike 4.0 International

# == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == == =

# Creative Commons Corporation("Creative Commons") is not a law firm and
# does not provide legal services or legal advice. Distribution of
# Creative Commons public licenses does not create a lawyer - client or
# other relationship. Creative Commons makes its licenses and related
# information available on an "as-is" basis. Creative Commons gives no
# warranties regarding its licenses, any material licensed under their
# terms and conditions, or any related information. Creative Commons
# disclaims all liability for damages resulting from their use to the
# fullest extent possible.

# Using Creative Commons Public Licenses

# Creative Commons public licenses provide a standard set of terms and
# conditions that creators and other rights holders may use to share
# original works of authorship and other material subject to copyright
# and certain other rights specified in the public license below. The
# following considerations are for informational purposes only, are not
# exhaustive, and do not form part of our licenses.

#      Considerations for licensors: Our public licenses are
#      intended for use by those authorized to give the public
#      permission to use material in ways otherwise restricted by
#      copyright and certain other rights. Our licenses are
#      irrevocable. Licensors should read and understand the terms
#      and conditions of the license they choose before applying it.
#      Licensors should also secure all rights necessary before
#      applying our licenses so that the public can reuse the
#      material as expected. Licensors should clearly mark any
#      material not subject to the license. This includes other CC-
#      licensed material, or material used under an exception or
#      limitation to copyright. More considerations for licensors:
#     wiki.creativecommons.org/Considerations_for_licensors

#      Considerations for the public: By using one of our public
#      licenses, a licensor grants the public permission to use the
#      licensed material under specified terms and conditions. If
#      the licensor's permission is not necessary for any reason--for
#      example, because of any applicable exception or limitation to
#      copyright--then that use is not regulated by the license. Our
#      licenses grant only permissions under copyright and certain
#      other rights that a licensor has authority to grant. Use of
#      the licensed material may still be restricted for other
#      reasons, including because others have copyright or other
#      rights in the material. A licensor may make special requests,
#      such as asking that all changes be marked or described.
#      Although not required by our licenses, you are encouraged to
#      respect those requests where reasonable. More considerations
#      for the public:
#     wiki.creativecommons.org/Considerations_for_licensees

# =======================================================================

# Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International
# Public License

# By exercising the Licensed Rights (defined below), You accept and agree
# to be bound by the terms and conditions of this Creative Commons
# Attribution-NonCommercial-ShareAlike 4.0 International Public License
# ("Public License"). To the extent this Public License may be
# interpreted as a contract, You are granted the Licensed Rights in
# consideration of Your acceptance of these terms and conditions, and the
# Licensor grants You such rights in consideration of benefits the
# Licensor receives from making the Licensed Material available under
# these terms and conditions.


# Section 1 -- Definitions.

#   a. Adapted Material means material subject to Copyright and Similar
#      Rights that is derived from or based upon the Licensed Material
#      and in which the Licensed Material is translated, altered,
#      arranged, transformed, or otherwise modified in a manner requiring
#      permission under the Copyright and Similar Rights held by the
#      Licensor. For purposes of this Public License, where the Licensed
#      Material is a musical work, performance, or sound recording,
#      Adapted Material is always produced where the Licensed Material is
#      synched in timed relation with a moving image.

#   b. Adapter's License means the license You apply to Your Copyright
#      and Similar Rights in Your contributions to Adapted Material in
#      accordance with the terms and conditions of this Public License.

#   c. BY-NC-SA Compatible License means a license listed at
#      creativecommons.org/compatiblelicenses, approved by Creative
#      Commons as essentially the equivalent of this Public License.

#   d. Copyright and Similar Rights means copyright and/or similar rights
#      closely related to copyright including, without limitation,
#      performance, broadcast, sound recording, and Sui Generis Database
#      Rights, without regard to how the rights are labeled or
#      categorized. For purposes of this Public License, the rights
#      specified in Section 2(b)(1)-(2) are not Copyright and Similar
#      Rights.

#   e. Effective Technological Measures means those measures that, in the
#      absence of proper authority, may not be circumvented under laws
#      fulfilling obligations under Article 11 of the WIPO Copyright
#      Treaty adopted on December 20, 1996, and/or similar international
#      agreements.

#   f. Exceptions and Limitations means fair use, fair dealing, and/or
#      any other exception or limitation to Copyright and Similar Rights
#      that applies to Your use of the Licensed Material.

#   g. License Elements means the license attributes listed in the name
#      of a Creative Commons Public License. The License Elements of this
#      Public License are Attribution, NonCommercial, and ShareAlike.

#   h. Licensed Material means the artistic or literary work, database,
#      or other material to which the Licensor applied this Public
#      License.

#   i. Licensed Rights means the rights granted to You subject to the
#      terms and conditions of this Public License, which are limited to
#      all Copyright and Similar Rights that apply to Your use of the
#      Licensed Material and that the Licensor has authority to license.

#   j. Licensor means the individual(s) or entity(ies) granting rights
#      under this Public License.

#   k. NonCommercial means not primarily intended for or directed towards
#      commercial advantage or monetary compensation. For purposes of
#      this Public License, the exchange of the Licensed Material for
#      other material subject to Copyright and Similar Rights by digital
#      file-sharing or similar means is NonCommercial provided there is
#      no payment of monetary compensation in connection with the
#      exchange.

#   l. Share means to provide material to the public by any means or
#      process that requires permission under the Licensed Rights, such
#      as reproduction, public display, public performance, distribution,
#      dissemination, communication, or importation, and to make material
#      available to the public including in ways that members of the
#      public may access the material from a place and at a time
#      individually chosen by them.

#   m. Sui Generis Database Rights means rights other than copyright
#      resulting from Directive 96/9/EC of the European Parliament and of
#      the Council of 11 March 1996 on the legal protection of databases,
#      as amended and/or succeeded, as well as other essentially
#      equivalent rights anywhere in the world.

#   n. You means the individual or entity exercising the Licensed Rights
#      under this Public License. Your has a corresponding meaning.


# Section 2 -- Scope.

#   a. License grant.

#        1. Subject to the terms and conditions of this Public License,
#           the Licensor hereby grants You a worldwide, royalty-free,
#           non-sublicensable, non-exclusive, irrevocable license to
#           exercise the Licensed Rights in the Licensed Material to:

#             a. reproduce and Share the Licensed Material, in whole or
#                in part, for NonCommercial purposes only; and

#             b. produce, reproduce, and Share Adapted Material for
#                NonCommercial purposes only.

#        2. Exceptions and Limitations. For the avoidance of doubt, where
#           Exceptions and Limitations apply to Your use, this Public
#           License does not apply, and You do not need to comply with
#           its terms and conditions.

#        3. Term. The term of this Public License is specified in Section
#           6(a).

#        4. Media and formats; technical modifications allowed. The
#           Licensor authorizes You to exercise the Licensed Rights in
#           all media and formats whether now known or hereafter created,
#           and to make technical modifications necessary to do so. The
#           Licensor waives and/or agrees not to assert any right or
#           authority to forbid You from making technical modifications
#           necessary to exercise the Licensed Rights, including
#           technical modifications necessary to circumvent Effective
#           Technological Measures. For purposes of this Public License,
#           simply making modifications authorized by this Section 2(a)
#           (4) never produces Adapted Material.

#        5. Downstream recipients.

#             a. Offer from the Licensor -- Licensed Material. Every
#                recipient of the Licensed Material automatically
#                receives an offer from the Licensor to exercise the
#                Licensed Rights under the terms and conditions of this
#                Public License.

#             b. Additional offer from the Licensor -- Adapted Material.
#                Every recipient of Adapted Material from You
#                automatically receives an offer from the Licensor to
#                exercise the Licensed Rights in the Adapted Material
#                under the conditions of the Adapter's License You apply.

#             c. No downstream restrictions. You may not offer or impose
#                any additional or different terms or conditions on, or
#                apply any Effective Technological Measures to, the
#                Licensed Material if doing so restricts exercise of the
#                Licensed Rights by any recipient of the Licensed
#                Material.

#        6. No endorsement. Nothing in this Public License constitutes or
#           may be construed as permission to assert or imply that You
#           are, or that Your use of the Licensed Material is, connected
#           with, or sponsored, endorsed, or granted official status by,
#           the Licensor or others designated to receive attribution as
#           provided in Section 3(a)(1)(A)(i).

#   b. Other rights.

#        1. Moral rights, such as the right of integrity, are not
#           licensed under this Public License, nor are publicity,
#           privacy, and/or other similar personality rights; however, to
#           the extent possible, the Licensor waives and/or agrees not to
#           assert any such rights held by the Licensor to the limited
#           extent necessary to allow You to exercise the Licensed
#           Rights, but not otherwise.

#        2. Patent and trademark rights are not licensed under this
#           Public License.

#        3. To the extent possible, the Licensor waives any right to
#           collect royalties from You for the exercise of the Licensed
#           Rights, whether directly or through a collecting society
#           under any voluntary or waivable statutory or compulsory
#           licensing scheme. In all other cases the Licensor expressly
#           reserves any right to collect such royalties, including when
#           the Licensed Material is used other than for NonCommercial
#           purposes.


# Section 3 -- License Conditions.

# Your exercise of the Licensed Rights is expressly made subject to the
# following conditions.

#   a. Attribution.

#        1. If You Share the Licensed Material (including in modified
#           form), You must:

#             a. retain the following if it is supplied by the Licensor
#                with the Licensed Material:

#                  i. identification of the creator(s) of the Licensed
#                     Material and any others designated to receive
#                     attribution, in any reasonable manner requested by
#                     the Licensor (including by pseudonym if
#                     designated);

#                 ii. a copyright notice;

#                iii. a notice that refers to this Public License;

#                 iv. a notice that refers to the disclaimer of
#                     warranties;

#                  v. a URI or hyperlink to the Licensed Material to the
#                     extent reasonably practicable;

#             b. indicate if You modified the Licensed Material and
#                retain an indication of any previous modifications; and

#             c. indicate the Licensed Material is licensed under this
#                Public License, and include the text of, or the URI or
#                hyperlink to, this Public License.

#        2. You may satisfy the conditions in Section 3(a)(1) in any
#           reasonable manner based on the medium, means, and context in
#           which You Share the Licensed Material. For example, it may be
#           reasonable to satisfy the conditions by providing a URI or
#           hyperlink to a resource that includes the required
#           information.
#        3. If requested by the Licensor, You must remove any of the
#           information required by Section 3(a)(1)(A) to the extent
#           reasonably practicable.

#   b. ShareAlike.

#      In addition to the conditions in Section 3(a), if You Share
#      Adapted Material You produce, the following conditions also apply.

#        1. The Adapter's License You apply must be a Creative Commons
#           license with the same License Elements, this version or
#           later, or a BY-NC-SA Compatible License.

#        2. You must include the text of, or the URI or hyperlink to, the
#           Adapter's License You apply. You may satisfy this condition
#           in any reasonable manner based on the medium, means, and
#           context in which You Share Adapted Material.

#        3. You may not offer or impose any additional or different terms
#           or conditions on, or apply any Effective Technological
#           Measures to, Adapted Material that restrict exercise of the
#           rights granted under the Adapter's License You apply.


# Section 4 -- Sui Generis Database Rights.

# Where the Licensed Rights include Sui Generis Database Rights that
# apply to Your use of the Licensed Material:

#   a. for the avoidance of doubt, Section 2(a)(1) grants You the right
#      to extract, reuse, reproduce, and Share all or a substantial
#      portion of the contents of the database for NonCommercial purposes
#      only;

#   b. if You include all or a substantial portion of the database
#      contents in a database in which You have Sui Generis Database
#      Rights, then the database in which You have Sui Generis Database
#      Rights (but not its individual contents) is Adapted Material,
#      including for purposes of Section 3(b); and

#   c. You must comply with the conditions in Section 3(a) if You Share
#      all or a substantial portion of the contents of the database.

# For the avoidance of doubt, this Section 4 supplements and does not
# replace Your obligations under this Public License where the Licensed
# Rights include other Copyright and Similar Rights.


# Section 5 -- Disclaimer of Warranties and Limitation of Liability.

#   a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE
#      EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS
#      AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF
#      ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,
#      IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,
#      WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR
#      PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,
#      ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT
#      KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT
#      ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.

#   b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE
#      TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,
#      NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,
#      INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,
#      COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR
#      USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN
#      ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR
#      DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR
#      IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.

#   c. The disclaimer of warranties and limitation of liability provided
#      above shall be interpreted in a manner that, to the extent
#      possible, most closely approximates an absolute disclaimer and
#      waiver of all liability.


# Section 6 -- Term and Termination.

#   a. This Public License applies for the term of the Copyright and
#      Similar Rights licensed here. However, if You fail to comply with
#      this Public License, then Your rights under this Public License
#      terminate automatically.

#   b. Where Your right to use the Licensed Material has terminated under
#      Section 6(a), it reinstates:

#        1. automatically as of the date the violation is cured, provided
#           it is cured within 30 days of Your discovery of the
#           violation; or

#        2. upon express reinstatement by the Licensor.

#      For the avoidance of doubt, this Section 6(b) does not affect any
#      right the Licensor may have to seek remedies for Your violations
#      of this Public License.

#   c. For the avoidance of doubt, the Licensor may also offer the
#      Licensed Material under separate terms or conditions or stop
#      distributing the Licensed Material at any time; however, doing so
#      will not terminate this Public License.

#   d. Sections 1, 5, 6, 7, and 8 survive termination of this Public
#      License.


# Section 7 -- Other Terms and Conditions.

#   a. The Licensor shall not be bound by any additional or different
#      terms or conditions communicated by You unless expressly agreed.

#   b. Any arrangements, understandings, or agreements regarding the
#      Licensed Material not stated herein are separate from and
#      independent of the terms and conditions of this Public License.


# Section 8 -- Interpretation.

#   a. For the avoidance of doubt, this Public License does not, and
#      shall not be interpreted to, reduce, limit, restrict, or impose
#      conditions on any use of the Licensed Material that could lawfully
#      be made without permission under this Public License.

#   b. To the extent possible, if any provision of this Public License is
#      deemed unenforceable, it shall be automatically reformed to the
#      minimum extent necessary to make it enforceable. If the provision
#      cannot be reformed, it shall be severed from this Public License
#      without affecting the enforceability of the remaining terms and
#      conditions.

#   c. No term or condition of this Public License will be waived and no
#      failure to comply consented to unless expressly agreed to by the
#      Licensor.

#   d. Nothing in this Public License constitutes or may be interpreted
#      as a limitation upon, or waiver of, any privileges and immunities
#      that apply to the Licensor or You, including from the legal
#      processes of any jurisdiction or authority.

# =======================================================================

# Creative Commons is not a party to its public
# licenses. Notwithstanding, Creative Commons may elect to apply one of
# its public licenses to material it publishes and in those instances
# will be considered the "Licensor." The text of the Creative Commons
# public licenses is dedicated to the public domain under the CC0 Public
# Domain Dedication. Except for the limited purpose of indicating that
# material is shared under a Creative Commons public license or as
# otherwise permitted by the Creative Commons policies published at
# creativecommons.org/policies, Creative Commons does not authorize the
# use of the trademark "Creative Commons" or any other trademark or logo
# of Creative Commons without its prior written consent including,
# without limitation, in connection with any unauthorized modifications
# to any of its public licenses or any other arrangements,
# understandings, or agreements concerning use of licensed material. For
# the avoidance of doubt, this paragraph does not form part of the
# public licenses.

# Creative Commons may be contacted at creativecommons.org.

# Safe unpickler to prevent arbitrary code execution
import pickle
from types import SimpleNamespace
from typing import Any

safe_list = {
    ("collections", "OrderedDict"),
    ("torch._utils", "_rebuild_tensor_v2"),
    ("torch", "FloatStorage"),
}


class RestrictedUnpickler(pickle.Unpickler):
    """_summary_

    Args:
        pickle (_type_): _description_
    """

    def find_class(self, module: Any, name: Any) -> Any:
        """_summary_

        Args:
            module (_type_): _description_
            name (_type_): _description_

        Raises:
            pickle.UnpicklingError: _description_

        Returns:
            _type_: _description_
        """
        # Only allow required classes to load state dict
        if (module, name) not in safe_list:
            raise pickle.UnpicklingError(f"Global '{module}.{name}' is forbidden")
        return super().find_class(module, name)


RestrictedUnpickle = SimpleNamespace(
    Unpickler=RestrictedUnpickler,
    __name__="pickle",
    load=lambda *args, **kwargs: RestrictedUnpickler(*args, **kwargs).load(),
)

</document_content>
</document>
<document index="43">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/writer.py</source>
<document_content>
"""Write to disk asynchronously."""
# https://github.com/hackersandslackers/asyncio-tutorial/blob/0f4c99776b61ca3eafd850c43202bc7c52349552/asyncio_tutorial/part_II_aiohttp_aiofiles/writer.py
import logging

import aiofiles

from cerebro_bot.bot_logger import get_logger

LOGGER = get_logger(__name__, provider="Writer", level=logging.DEBUG)


async def write_file(fname: str, body: bytes, filetype: str, directory: str):
    """
    Write contents of fetched URL to new file in local directory.
    :param str fname: URL which was fetched.
    :param bytes body: Source HTML of a single fetched URL.
    :param str filetype: File extension to save fetched data as.
    :param str directory: Local directory to save exports to.
    """
    try:
        filename = f"{directory}/{fname}.{filetype}"
        LOGGER.info(f"writing file -> {filename} ....")
        async with aiofiles.open(filename, mode="wb+") as f:
            await f.write(body)
            await f.close()
    except Exception as e:
        LOGGER.error(f"Unexpected error while writing from `{fname}`: {e}")
    return filename

</document_content>
</document>
<document index="44">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/arch/RRDB.py</source>
<document_content>
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""RRDB"""

from collections import OrderedDict
import functools
import math
import re

import torch
import torch.nn as nn

import cerebro_bot.utils.arch.block as B


# Borrowed from https://github.com/rlaphoenix/VSGAN/blob/master/vsgan/archs/ESRGAN.py
# Which enhanced stuff that was already here
class RRDBNet(nn.Module):
    def __init__(
        self,
        state_dict,
        norm=None,
        act: str = "leakyrelu",
        upsampler: str = "upconv",
        mode: str = "CNA",
    ) -> None:
        """
        ESRGAN - Enhanced Super-Resolution Generative Adversarial Networks.
        By Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, Yihao Liu, Chao Dong, Yu Qiao,
        and Chen Change Loy.
        This is old-arch Residual in Residual Dense Block Network and is not
        the newest revision that's available at github.com/xinntao/ESRGAN.
        This is on purpose, the newest Network has severely limited the
        potential use of the Network with no benefits.
        This network supports model files from both new and old-arch.
        Args:
            norm: Normalization layer
            act: Activation layer
            upsampler: Upsample layer. upconv, pixel_shuffle
            mode: Convolution mode
        """
        super(RRDBNet, self).__init__()

        self.state = state_dict
        self.norm = norm
        self.act = act
        self.upsampler = upsampler
        self.mode = mode

        self.state_map = {
            # currently supports old, new, and newer RRDBNet arch models
            # ESRGAN, BSRGAN/RealSR, Real-ESRGAN
            "model.0.weight": ("conv_first.weight",),
            "model.0.bias": ("conv_first.bias",),
            "model.1.sub./NB/.weight": ("trunk_conv.weight", "conv_body.weight"),
            "model.1.sub./NB/.bias": ("trunk_conv.bias", "conv_body.bias"),
            "model.3.weight": ("upconv1.weight", "conv_up1.weight"),
            "model.3.bias": ("upconv1.bias", "conv_up1.bias"),
            "model.6.weight": ("upconv2.weight", "conv_up2.weight"),
            "model.6.bias": ("upconv2.bias", "conv_up2.bias"),
            "model.8.weight": ("HRconv.weight", "conv_hr.weight"),
            "model.8.bias": ("HRconv.bias", "conv_hr.bias"),
            "model.10.weight": ("conv_last.weight",),
            "model.10.bias": ("conv_last.bias",),
            r"model.1.sub.\1.RDB\2.conv\3.0.\4": (
                r"RRDB_trunk\.(\d+)\.RDB(\d)\.conv(\d+)\.(weight|bias)",
                r"body\.(\d+)\.rdb(\d)\.conv(\d+)\.(weight|bias)",
            ),
        }
        if "params_ema" in self.state:
            self.state = self.state["params_ema"]
        self.num_blocks = self.get_num_blocks()
        self.plus = any("conv1x1" in k for k in self.state.keys())

        self.state = self.new_to_old_arch(self.state)

        self.key_arr = list(self.state.keys())

        self.in_nc = self.state[self.key_arr[0]].shape[1]
        self.out_nc = self.state[self.key_arr[-1]].shape[0]

        self.scale = self.get_scale()
        self.num_filters = self.state[self.key_arr[0]].shape[0]

        # Detect if pixelunshuffle was used (Real-ESRGAN)
        if self.in_nc in (self.out_nc * 4, self.out_nc * 16) and self.out_nc in (
            self.in_nc / 4,
            self.in_nc / 16,
        ):
            self.shuffle_factor = int(math.sqrt(self.in_nc / self.out_nc))
        else:
            self.shuffle_factor = None

        upsample_block = {
            "upconv": B.upconv_block,
            "pixel_shuffle": B.pixelshuffle_block,
        }.get(self.upsampler)
        if upsample_block is None:
            raise NotImplementedError(f"Upsample mode [{self.upsampler}] is not found")

        if self.scale == 3:
            upsample_blocks = upsample_block(
                in_nc=self.num_filters,
                out_nc=self.num_filters,
                upscale_factor=3,
                act_type=self.act,
            )
        else:
            upsample_blocks = [
                upsample_block(in_nc=self.num_filters, out_nc=self.num_filters, act_type=self.act)
                for _ in range(int(math.log(self.scale, 2)))
            ]

        self.model = B.sequential(
            # fea conv
            B.conv_block(
                in_nc=self.in_nc,
                out_nc=self.num_filters,
                kernel_size=3,
                norm_type=None,
                act_type=None,
            ),
            B.ShortcutBlock(
                B.sequential(
                    # rrdb blocks
                    *[
                        B.RRDB(
                            nf=self.num_filters,
                            kernel_size=3,
                            gc=32,
                            stride=1,
                            bias=True,
                            pad_type="zero",
                            norm_type=self.norm,
                            act_type=self.act,
                            mode="CNA",
                            plus=self.plus,
                        )
                        for _ in range(self.num_blocks)
                    ],
                    # lr conv
                    B.conv_block(
                        in_nc=self.num_filters,
                        out_nc=self.num_filters,
                        kernel_size=3,
                        norm_type=self.norm,
                        act_type=None,
                        mode=self.mode,
                    ),
                )
            ),
            *upsample_blocks,
            # hr_conv0
            B.conv_block(
                in_nc=self.num_filters,
                out_nc=self.num_filters,
                kernel_size=3,
                norm_type=None,
                act_type=self.act,
            ),
            # hr_conv1
            B.conv_block(
                in_nc=self.num_filters,
                out_nc=self.out_nc,
                kernel_size=3,
                norm_type=None,
                act_type=None,
            ),
        )

        self.load_state_dict(self.state, strict=False)

    def new_to_old_arch(self, state):
        """Convert a new-arch model state dictionary to an old-arch dictionary."""
        if "params_ema" in state:
            state = state["params_ema"]

        if "conv_first.weight" not in state:
            # model is already old arch, this is a loose check, but should be sufficient
            return state

        # add nb to state keys
        for kind in ("weight", "bias"):
            self.state_map[f"model.1.sub.{self.num_blocks}.{kind}"] = self.state_map[f"model.1.sub./NB/.{kind}"]
            del self.state_map[f"model.1.sub./NB/.{kind}"]

        old_state = OrderedDict()
        for old_key, new_keys in self.state_map.items():
            for new_key in new_keys:
                if r"\1" in old_key:
                    for k, v in state.items():
                        sub = re.sub(new_key, old_key, k)
                        if sub != k:
                            old_state[sub] = v
                else:
                    if new_key in state:
                        old_state[old_key] = state[new_key]

        # Sort by first numeric value of each layer
        def compare(item1, item2):
            parts1 = item1.split(".")
            parts2 = item2.split(".")
            int1 = int(parts1[1])
            int2 = int(parts2[1])
            return int1 - int2

        sorted_keys = sorted(old_state.keys(), key=functools.cmp_to_key(compare))

        # Rebuild the output dict in the right order
        out_dict = OrderedDict((k, old_state[k]) for k in sorted_keys)

        return out_dict

    def get_scale(self, min_part: int = 6) -> int:
        n = 0
        for part in list(self.state):
            parts = part.split(".")[1:]
            if len(parts) == 2:
                part_num = int(parts[0])
                if part_num > min_part and parts[1] == "weight":
                    n += 1
        return 2**n

    def get_num_blocks(self) -> int:
        nbs = []
        state_keys = self.state_map[r"model.1.sub.\1.RDB\2.conv\3.0.\4"] + (
            r"model\.\d+\.sub\.(\d+)\.RDB(\d+)\.conv(\d+)\.0\.(weight|bias)",
        )
        for state_key in state_keys:
            for k in self.state:
                if m := re.search(state_key, k):
                    nbs.append(int(m[1]))
            if nbs:
                break
        return max(*nbs) + 1

    def forward(self, x):
        if self.shuffle_factor:
            x = torch.pixel_unshuffle(x, downscale_factor=self.shuffle_factor)
        return self.model(x)

</document_content>
</document>
<document index="45">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/arch/SPSR.py</source>
<document_content>
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""SPSR"""

import math

import torch
import torch.nn as nn
import torch.nn.functional as F

import cerebro_bot.utils.arch.block as B


class Get_gradient_nopadding(nn.Module):
    def __init__(self):
        super(Get_gradient_nopadding, self).__init__()
        kernel_v = [[0, -1, 0], [0, 0, 0], [0, 1, 0]]
        kernel_h = [[0, 0, 0], [-1, 0, 1], [0, 0, 0]]
        kernel_h = torch.FloatTensor(kernel_h).unsqueeze(0).unsqueeze(0)
        kernel_v = torch.FloatTensor(kernel_v).unsqueeze(0).unsqueeze(0)
        self.weight_h = nn.Parameter(data=kernel_h, requires_grad=False)

        self.weight_v = nn.Parameter(data=kernel_v, requires_grad=False)

    def forward(self, x):
        x_list = []
        for i in range(x.shape[1]):
            x_i = x[:, i]
            x_i_v = F.conv2d(x_i.unsqueeze(1), self.weight_v, padding=1)
            x_i_h = F.conv2d(x_i.unsqueeze(1), self.weight_h, padding=1)
            x_i = torch.sqrt(torch.pow(x_i_v, 2) + torch.pow(x_i_h, 2) + 1e-6)
            x_list.append(x_i)

        x = torch.cat(x_list, dim=1)

        return x


class SPSRNet(nn.Module):
    def __init__(
        self,
        state_dict,
        norm=None,
        act: str = "leakyrelu",
        upsampler: str = "upconv",
        mode: str = "CNA",
    ):
        super(SPSRNet, self).__init__()

        self.state = state_dict
        self.norm = norm
        self.act = act
        self.upsampler = upsampler
        self.mode = mode

        self.num_blocks = self.get_num_blocks()

        self.in_nc = self.state["model.0.weight"].shape[1]
        self.out_nc = self.state["f_HR_conv1.0.bias"].shape[0]

        self.scale = self.get_scale(4)
        print(self.scale)
        self.num_filters = self.state["model.0.weight"].shape[0]

        n_upscale = int(math.log(self.scale, 2))
        if self.scale == 3:
            n_upscale = 1

        fea_conv = B.conv_block(self.in_nc, self.num_filters, kernel_size=3, norm_type=None, act_type=None)
        rb_blocks = [
            B.RRDB(
                self.num_filters,
                kernel_size=3,
                gc=32,
                stride=1,
                bias=True,
                pad_type="zero",
                norm_type=norm,
                act_type=act,
                mode="CNA",
            )
            for _ in range(self.num_blocks)
        ]
        LR_conv = B.conv_block(
            self.num_filters,
            self.num_filters,
            kernel_size=3,
            norm_type=norm,
            act_type=None,
            mode=mode,
        )

        if upsampler == "upconv":
            upsample_block = B.upconv_block
        elif upsampler == "pixelshuffle":
            upsample_block = B.pixelshuffle_block
        else:
            raise NotImplementedError(f"upsample mode [{upsampler}] is not found")
        if self.scale == 3:
            a_upsampler = upsample_block(self.num_filters, self.num_filters, 3, act_type=act)
        else:
            a_upsampler = [upsample_block(self.num_filters, self.num_filters, act_type=act) for _ in range(n_upscale)]
        self.HR_conv0_new = B.conv_block(
            self.num_filters,
            self.num_filters,
            kernel_size=3,
            norm_type=None,
            act_type=act,
        )
        self.HR_conv1_new = B.conv_block(
            self.num_filters,
            self.num_filters,
            kernel_size=3,
            norm_type=None,
            act_type=None,
        )

        self.model = B.sequential(
            fea_conv,
            B.ShortcutBlockSPSR(B.sequential(*rb_blocks, LR_conv)),
            *a_upsampler,
            self.HR_conv0_new,
        )

        self.get_g_nopadding = Get_gradient_nopadding()

        self.b_fea_conv = B.conv_block(self.in_nc, self.num_filters, kernel_size=3, norm_type=None, act_type=None)

        self.b_concat_1 = B.conv_block(
            2 * self.num_filters,
            self.num_filters,
            kernel_size=3,
            norm_type=None,
            act_type=None,
        )
        self.b_block_1 = B.RRDB(
            self.num_filters * 2,
            kernel_size=3,
            gc=32,
            stride=1,
            bias=True,
            pad_type="zero",
            norm_type=norm,
            act_type=act,
            mode="CNA",
        )

        self.b_concat_2 = B.conv_block(
            2 * self.num_filters,
            self.num_filters,
            kernel_size=3,
            norm_type=None,
            act_type=None,
        )
        self.b_block_2 = B.RRDB(
            self.num_filters * 2,
            kernel_size=3,
            gc=32,
            stride=1,
            bias=True,
            pad_type="zero",
            norm_type=norm,
            act_type=act,
            mode="CNA",
        )

        self.b_concat_3 = B.conv_block(
            2 * self.num_filters,
            self.num_filters,
            kernel_size=3,
            norm_type=None,
            act_type=None,
        )
        self.b_block_3 = B.RRDB(
            self.num_filters * 2,
            kernel_size=3,
            gc=32,
            stride=1,
            bias=True,
            pad_type="zero",
            norm_type=norm,
            act_type=act,
            mode="CNA",
        )

        self.b_concat_4 = B.conv_block(
            2 * self.num_filters,
            self.num_filters,
            kernel_size=3,
            norm_type=None,
            act_type=None,
        )
        self.b_block_4 = B.RRDB(
            self.num_filters * 2,
            kernel_size=3,
            gc=32,
            stride=1,
            bias=True,
            pad_type="zero",
            norm_type=norm,
            act_type=act,
            mode="CNA",
        )

        self.b_LR_conv = B.conv_block(
            self.num_filters,
            self.num_filters,
            kernel_size=3,
            norm_type=norm,
            act_type=None,
            mode=mode,
        )

        if upsampler == "upconv":
            upsample_block = B.upconv_block
        elif upsampler == "pixelshuffle":
            upsample_block = B.pixelshuffle_block
        else:
            raise NotImplementedError(f"upsample mode [{upsampler}] is not found")
        if self.scale == 3:
            b_upsampler = upsample_block(self.num_filters, self.num_filters, 3, act_type=act)
        else:
            b_upsampler = [upsample_block(self.num_filters, self.num_filters, act_type=act) for _ in range(n_upscale)]

        b_HR_conv0 = B.conv_block(
            self.num_filters,
            self.num_filters,
            kernel_size=3,
            norm_type=None,
            act_type=act,
        )
        b_HR_conv1 = B.conv_block(
            self.num_filters,
            self.num_filters,
            kernel_size=3,
            norm_type=None,
            act_type=None,
        )

        self.b_module = B.sequential(*b_upsampler, b_HR_conv0, b_HR_conv1)

        self.conv_w = B.conv_block(self.num_filters, self.out_nc, kernel_size=1, norm_type=None, act_type=None)

        self.f_concat = B.conv_block(
            self.num_filters * 2,
            self.num_filters,
            kernel_size=3,
            norm_type=None,
            act_type=None,
        )

        self.f_block = B.RRDB(
            self.num_filters * 2,
            kernel_size=3,
            gc=32,
            stride=1,
            bias=True,
            pad_type="zero",
            norm_type=norm,
            act_type=act,
            mode="CNA",
        )

        self.f_HR_conv0 = B.conv_block(
            self.num_filters,
            self.num_filters,
            kernel_size=3,
            norm_type=None,
            act_type=act,
        )
        self.f_HR_conv1 = B.conv_block(self.num_filters, self.out_nc, kernel_size=3, norm_type=None, act_type=None)

        self.load_state_dict(self.state, strict=False)

    def get_scale(self, min_part: int = 4) -> int:
        n = 0
        for part in list(self.state):
            parts = part.split(".")
            if len(parts) == 3:
                part_num = int(parts[1])
                if part_num > min_part and parts[0] == "model" and parts[2] == "weight":
                    n += 1
        return 2**n

    def get_num_blocks(self) -> int:
        nb = 0
        for part in list(self.state):
            parts = part.split(".")
            n_parts = len(parts)
            if n_parts == 5 and parts[2] == "sub":
                nb = int(parts[3])
        return nb

    def forward(self, x):
        x_grad = self.get_g_nopadding(x)
        x = self.model[0](x)

        x, block_list = self.model[1](x)

        x_ori = x
        for i in range(5):
            x = block_list[i](x)
        x_fea1 = x

        for i in range(5):
            x = block_list[i + 5](x)
        x_fea2 = x

        for i in range(5):
            x = block_list[i + 10](x)
        x_fea3 = x

        for i in range(5):
            x = block_list[i + 15](x)
        x_fea4 = x

        x = block_list[20:](x)
        # short cut
        x = x_ori + x
        x = self.model[2:](x)
        x = self.HR_conv1_new(x)

        x_b_fea = self.b_fea_conv(x_grad)
        x_cat_1 = torch.cat([x_b_fea, x_fea1], dim=1)

        x_cat_1 = self.b_block_1(x_cat_1)
        x_cat_1 = self.b_concat_1(x_cat_1)

        x_cat_2 = torch.cat([x_cat_1, x_fea2], dim=1)

        x_cat_2 = self.b_block_2(x_cat_2)
        x_cat_2 = self.b_concat_2(x_cat_2)

        x_cat_3 = torch.cat([x_cat_2, x_fea3], dim=1)

        x_cat_3 = self.b_block_3(x_cat_3)
        x_cat_3 = self.b_concat_3(x_cat_3)

        x_cat_4 = torch.cat([x_cat_3, x_fea4], dim=1)

        x_cat_4 = self.b_block_4(x_cat_4)
        x_cat_4 = self.b_concat_4(x_cat_4)

        x_cat_4 = self.b_LR_conv(x_cat_4)

        # short cut
        x_cat_4 = x_cat_4 + x_b_fea
        x_branch = self.b_module(x_cat_4)

        # x_out_branch = self.conv_w(x_branch)
        ########
        x_branch_d = x_branch
        x_f_cat = torch.cat([x_branch_d, x], dim=1)
        x_f_cat = self.f_block(x_f_cat)
        x_out = self.f_concat(x_f_cat)
        x_out = self.f_HR_conv0(x_out)
        x_out = self.f_HR_conv1(x_out)

        #########
        # return x_out_branch, x_out, x_grad
        return x_out

</document_content>
</document>
<document index="46">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/arch/SRVGG.py</source>
<document_content>
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""SRVGG"""

import math

import torch.nn as nn
import torch.nn.functional as F


class SRVGGNetCompact(nn.Module):
    """A compact VGG-style network structure for super-resolution.
    It is a compact network structure, which performs upsampling in the last layer and no convolution is
    conducted on the HR feature space.
    Args:
        num_in_ch (int): Channel number of inputs. Default: 3.
        num_out_ch (int): Channel number of outputs. Default: 3.
        num_feat (int): Channel number of intermediate features. Default: 64.
        num_conv (int): Number of convolution layers in the body network. Default: 16.
        upscale (int): Upsampling factor. Default: 4.
        act_type (str): Activation type, options: 'relu', 'prelu', 'leakyrelu'. Default: prelu.
    """

    def __init__(
        self,
        state_dict,
        act_type: str = "prelu",
    ):
        super(SRVGGNetCompact, self).__init__()
        self.act_type = act_type

        self.state = state_dict

        if "params" in self.state:
            self.state = self.state["params"]

        self.key_arr = list(self.state.keys())

        self.num_in_ch = self.get_in_nc()
        self.num_feat = self.get_num_feats()
        self.num_conv = self.get_num_conv()
        self.num_out_ch = self.num_in_ch  # :(
        self.scale = self.get_scale()

        self.body = nn.ModuleList()
        # the first conv
        self.body.append(nn.Conv2d(self.num_in_ch, self.num_feat, 3, 1, 1))
        # the first activation
        if act_type == "relu":
            activation = nn.ReLU(inplace=True)
        elif act_type == "prelu":
            activation = nn.PReLU(num_parameters=self.num_feat)
        elif act_type == "leakyrelu":
            activation = nn.LeakyReLU(negative_slope=0.1, inplace=True)
        self.body.append(activation)

        # the body structure
        for _ in range(self.num_conv):
            self.body.append(nn.Conv2d(self.num_feat, self.num_feat, 3, 1, 1))
            # activation
            if act_type == "relu":
                activation = nn.ReLU(inplace=True)
            elif act_type == "prelu":
                activation = nn.PReLU(num_parameters=self.num_feat)
            elif act_type == "leakyrelu":
                activation = nn.LeakyReLU(negative_slope=0.1, inplace=True)
            self.body.append(activation)

        # the last conv
        self.body.append(nn.Conv2d(self.num_feat, self.pixelshuffle_shape, 3, 1, 1))
        # upsample
        self.upsampler = nn.PixelShuffle(self.scale)

        self.load_state_dict(self.state, strict=False)

    def get_num_conv(self) -> int:
        return (int(self.key_arr[-1].split(".")[1]) - 2) // 2

    def get_num_feats(self) -> int:
        return self.state[self.key_arr[0]].shape[0]

    def get_in_nc(self) -> int:
        return self.state[self.key_arr[0]].shape[1]

    def get_scale(self) -> int:
        self.pixelshuffle_shape = self.state[self.key_arr[-1]].shape[0]
        # Assume out_nc is the same as in_nc
        # I cant think of a better way to do that
        self.num_out_ch = self.num_in_ch
        scale = math.sqrt(self.pixelshuffle_shape / self.num_out_ch)
        if scale - int(scale) > 0:
            print("out_nc is probably different than in_nc, scale calculation might be wrong")
        scale = int(scale)
        return scale

    def forward(self, x):
        out = x
        for i in range(len(self.body)):
            out = self.body[i](out)

        out = self.upsampler(out)
        # add the nearest upsampled image, so that the network learns the residual
        base = F.interpolate(x, scale_factor=self.scale, mode="nearest")
        out += base
        return out

</document_content>
</document>
<document index="47">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/arch/ScreenCropNet.py</source>
<document_content>
"""ScreenCropNet"""

import timm
import torch.nn as nn
import torchvision.models as models

MODEL_NAMES = sorted(
    name for name in models.__dict__ if name.islower() and not name.startswith("__") and callable(models.__dict__[name])
)


class ObjLocModel(nn.Module):
    def __init__(self):
        super(ObjLocModel, self).__init__()
        self.backbone = timm.create_model("efficientnet_b0", pretrained=True, num_classes=4)

    def forward(self, images, gt_bboxes=None):
        bboxes_logits = self.backbone(images)  ## predicted bounding boxes

        # gt_bboxes = ground truth bounding boxes
        if gt_bboxes != None:
            # Creates a criterion that measures the mean squared error (squared L2 norm) between each element in the input xx and target yy.
            loss = nn.MSELoss()(bboxes_logits, gt_bboxes)
            return bboxes_logits, loss

        return bboxes_logits

</document_content>
</document>
<document index="48">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/arch/__init__.py</source>
<document_content>

</document_content>
</document>
<document index="49">
<source>/Users/malcolm/dev/universityofprofessorex/cerebro-bot/cerebro_bot/utils/arch/block.py</source>
<document_content>
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""block.py"""

# pylint: disable=not-callable

from collections import OrderedDict

import torch
import torch.nn as nn

####################
# Basic blocks
####################


def act(act_type, inplace=True, neg_slope=0.2, n_prelu=1):
    # helper selecting activation
    # neg_slope: for leakyrelu and init of prelu
    # n_prelu: for p_relu num_parameters
    act_type = act_type.lower()
    if act_type == "relu":
        layer = nn.ReLU(inplace)
    elif act_type == "leakyrelu":
        layer = nn.LeakyReLU(neg_slope, inplace)
    elif act_type == "prelu":
        layer = nn.PReLU(num_parameters=n_prelu, init=neg_slope)
    else:
        raise NotImplementedError("activation layer [{:s}] is not found".format(act_type))
    return layer


def norm(norm_type, nc):
    # helper selecting normalization layer
    norm_type = norm_type.lower()
    if norm_type == "batch":
        layer = nn.BatchNorm2d(nc, affine=True)
    elif norm_type == "instance":
        layer = nn.InstanceNorm2d(nc, affine=False)
    else:
        raise NotImplementedError("normalization layer [{:s}] is not found".format(norm_type))
    return layer


def pad(pad_type, padding):
    # helper selecting padding layer
    # if padding is 'zero', do by conv layers
    pad_type = pad_type.lower()
    if padding == 0:
        return None
    if pad_type == "reflect":
        layer = nn.ReflectionPad2d(padding)
    elif pad_type == "replicate":
        layer = nn.ReplicationPad2d(padding)
    else:
        raise NotImplementedError("padding layer [{:s}] is not implemented".format(pad_type))
    return layer


def get_valid_padding(kernel_size, dilation):
    kernel_size = kernel_size + (kernel_size - 1) * (dilation - 1)
    return (kernel_size - 1) // 2


class ConcatBlock(nn.Module):
    # Concat the output of a submodule to its input
    def __init__(self, submodule):
        super(ConcatBlock, self).__init__()
        self.sub = submodule

    def forward(self, x):
        return torch.cat((x, self.sub(x)), dim=1)

    def __repr__(self):
        tmpstr = "Identity .. \n|"
        modstr = self.sub.__repr__().replace("\n", "\n|")
        tmpstr += modstr
        return tmpstr


class ShortcutBlock(nn.Module):
    # Elementwise sum the output of a submodule to its input
    def __init__(self, submodule):
        super(ShortcutBlock, self).__init__()
        self.sub = submodule

    def forward(self, x):
        return x + self.sub(x)

    def __repr__(self):
        tmpstr = "Identity + \n|"
        modstr = self.sub.__repr__().replace("\n", "\n|")
        tmpstr += modstr
        return tmpstr


class ShortcutBlockSPSR(nn.Module):
    # Elementwise sum the output of a submodule to its input
    def __init__(self, submodule):
        super(ShortcutBlockSPSR, self).__init__()
        self.sub = submodule

    def forward(self, x):
        return x, self.sub

    def __repr__(self):
        tmpstr = "Identity + \n|"
        modstr = self.sub.__repr__().replace("\n", "\n|")
        tmpstr += modstr
        return tmpstr


def sequential(*args):
    # Flatten Sequential. It unwraps nn.Sequential.
    if len(args) == 1:
        if isinstance(args[0], OrderedDict):
            raise NotImplementedError("sequential does not support OrderedDict input.")
        return args[0]  # No sequential is needed.
    modules = []
    for module in args:
        if isinstance(module, nn.Sequential):
            modules.extend(iter(module.children()))
        elif isinstance(module, nn.Module):
            modules.append(module)
    return nn.Sequential(*modules)


def conv_block(
    in_nc,
    out_nc,
    kernel_size,
    stride=1,
    dilation=1,
    groups=1,
    bias=True,
    pad_type="zero",
    norm_type=None,
    act_type="relu",
    mode="CNA",
):
    """
    Conv layer with padding, normalization, activation
    mode: CNA --> Conv -> Norm -> Act
        NAC --> Norm -> Act --> Conv (Identity Mappings in Deep Residual Networks, ECCV16)
    """
    assert mode in ["CNA", "NAC", "CNAC"], "Wrong conv mode [{:s}]".format(mode)
    padding = get_valid_padding(kernel_size, dilation)
    p = pad(pad_type, padding) if pad_type and pad_type != "zero" else None
    padding = padding if pad_type == "zero" else 0

    c = nn.Conv2d(
        in_nc,
        out_nc,
        kernel_size=kernel_size,
        stride=stride,
        padding=padding,
        dilation=dilation,
        bias=bias,
        groups=groups,
    )
    a = act(act_type) if act_type else None
    if "CNA" in mode:
        n = norm(norm_type, out_nc) if norm_type else None
        return sequential(p, c, n, a)
    elif mode == "NAC":
        if norm_type is None and act_type is not None:
            a = act(act_type, inplace=False)
            # Important!
            # input----ReLU(inplace)----Conv--+----output
            #        |________________________|
            # inplace ReLU will modify the input, therefore wrong output
        n = norm(norm_type, in_nc) if norm_type else None
        return sequential(n, a, p, c)


####################
# Useful blocks
####################


class ResNetBlock(nn.Module):
    """
    ResNet Block, 3-3 style
    with extra residual scaling used in EDSR
    (Enhanced Deep Residual Networks for Single Image Super-Resolution, CVPRW 17)
    """

    def __init__(
        self,
        in_nc,
        mid_nc,
        out_nc,
        kernel_size=3,
        stride=1,
        dilation=1,
        groups=1,
        bias=True,
        pad_type="zero",
        norm_type=None,
        act_type="relu",
        mode="CNA",
        res_scale=1,
    ):
        super(ResNetBlock, self).__init__()
        conv0 = conv_block(
            in_nc,
            mid_nc,
            kernel_size,
            stride,
            dilation,
            groups,
            bias,
            pad_type,
            norm_type,
            act_type,
            mode,
        )
        if mode == "CNA":
            act_type = None
        if mode == "CNAC":  # Residual path: |-CNAC-|
            act_type = None
            norm_type = None
        conv1 = conv_block(
            mid_nc,
            out_nc,
            kernel_size,
            stride,
            dilation,
            groups,
            bias,
            pad_type,
            norm_type,
            act_type,
            mode,
        )
        # if in_nc != out_nc:
        #     self.project = conv_block(in_nc, out_nc, 1, stride, dilation, 1, bias, pad_type, \
        #         None, None)
        #     print('Need a projecter in ResNetBlock.')
        # else:
        #     self.project = lambda x:x
        self.res = sequential(conv0, conv1)
        self.res_scale = res_scale

    def forward(self, x):
        res = self.res(x).mul(self.res_scale)
        return x + res


class RRDB(nn.Module):
    """
    Residual in Residual Dense Block
    (ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks)
    """

    def __init__(
        self,
        nf,
        kernel_size=3,
        gc=32,
        stride=1,
        bias=1,
        pad_type="zero",
        norm_type=None,
        act_type="leakyrelu",
        mode="CNA",
        convtype="Conv2D",
        spectral_norm=False,
        plus=False,
    ):
        super(RRDB, self).__init__()
        self.RDB1 = ResidualDenseBlock_5C(
            nf,
            kernel_size,
            gc,
            stride,
            bias,
            pad_type,
            norm_type,
            act_type,
            mode,
            plus=plus,
        )
        self.RDB2 = ResidualDenseBlock_5C(
            nf,
            kernel_size,
            gc,
            stride,
            bias,
            pad_type,
            norm_type,
            act_type,
            mode,
            plus=plus,
        )
        self.RDB3 = ResidualDenseBlock_5C(
            nf,
            kernel_size,
            gc,
            stride,
            bias,
            pad_type,
            norm_type,
            act_type,
            mode,
            plus=plus,
        )

    def forward(self, x):
        out = self.RDB1(x)
        out = self.RDB2(out)
        out = self.RDB3(out)
        return out * 0.2 + x


class ResidualDenseBlock_5C(nn.Module):
    """
    Residual Dense Block
    style: 5 convs
    The core module of paper: (Residual Dense Network for Image Super-Resolution, CVPR 18)
    Modified options that can be used:
        - "Partial Convolution based Padding" arXiv:1811.11718
        - "Spectral normalization" arXiv:1802.05957
        - "ICASSP 2020 - ESRGAN+ : Further Improving ESRGAN" N. C.
            {Rakotonirina} and A. {Rasoanaivo}

    Args:
        nf (int): Channel number of intermediate features (num_feat).
        gc (int): Channels for each growth (num_grow_ch: growth channel,
            i.e. intermediate channels).
        convtype (str): the type of convolution to use. Default: 'Conv2D'
        gaussian_noise (bool): enable the ESRGAN+ gaussian noise (no new
            trainable parameters)
        plus (bool): enable the additional residual paths from ESRGAN+
            (adds trainable parameters)
    """

    def __init__(
        self,
        nf=64,
        kernel_size=3,
        gc=32,
        stride=1,
        bias=1,
        pad_type="zero",
        norm_type=None,
        act_type="leakyrelu",
        mode="CNA",
        plus=False,
    ):
        super(ResidualDenseBlock_5C, self).__init__()

        ## +
        self.conv1x1 = conv1x1(nf, gc) if plus else None
        ## +

        self.conv1 = conv_block(
            nf,
            gc,
            kernel_size,
            stride,
            bias=bias,
            pad_type=pad_type,
            norm_type=norm_type,
            act_type=act_type,
            mode=mode,
        )
        self.conv2 = conv_block(
            nf + gc,
            gc,
            kernel_size,
            stride,
            bias=bias,
            pad_type=pad_type,
            norm_type=norm_type,
            act_type=act_type,
            mode=mode,
        )
        self.conv3 = conv_block(
            nf + 2 * gc,
            gc,
            kernel_size,
            stride,
            bias=bias,
            pad_type=pad_type,
            norm_type=norm_type,
            act_type=act_type,
            mode=mode,
        )
        self.conv4 = conv_block(
            nf + 3 * gc,
            gc,
            kernel_size,
            stride,
            bias=bias,
            pad_type=pad_type,
            norm_type=norm_type,
            act_type=act_type,
            mode=mode,
        )
        last_act = None if mode == "CNA" else act_type
        self.conv5 = conv_block(
            nf + 4 * gc,
            nf,
            3,
            stride,
            bias=bias,
            pad_type=pad_type,
            norm_type=norm_type,
            act_type=last_act,
            mode=mode,
        )

    def forward(self, x):
        x1 = self.conv1(x)
        x2 = self.conv2(torch.cat((x, x1), 1))
        if self.conv1x1:
            x2 = x2 + self.conv1x1(x)  # +
        x3 = self.conv3(torch.cat((x, x1, x2), 1))
        x4 = self.conv4(torch.cat((x, x1, x2, x3), 1))
        if self.conv1x1:
            x4 = x4 + x2  # +
        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))
        return x5 * 0.2 + x


def conv1x1(in_planes, out_planes, stride=1):
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


####################
# Upsampler
####################


def pixelshuffle_block(
    in_nc,
    out_nc,
    upscale_factor=2,
    kernel_size=3,
    stride=1,
    bias=True,
    pad_type="zero",
    norm_type=None,
    act_type="relu",
):
    """
    Pixel shuffle layer
    (Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional
    Neural Network, CVPR17)
    """
    conv = conv_block(
        in_nc,
        out_nc * (upscale_factor**2),
        kernel_size,
        stride,
        bias=bias,
        pad_type=pad_type,
        norm_type=None,
        act_type=None,
    )
    pixel_shuffle = nn.PixelShuffle(upscale_factor)

    n = norm(norm_type, out_nc) if norm_type else None
    a = act(act_type) if act_type else None
    return sequential(conv, pixel_shuffle, n, a)


def upconv_block(
    in_nc,
    out_nc,
    upscale_factor=2,
    kernel_size=3,
    stride=1,
    bias=True,
    pad_type="zero",
    norm_type=None,
    act_type="relu",
    mode="nearest",
):
    # Up conv
    # described in https://distill.pub/2016/deconv-checkerboard/
    upsample = nn.Upsample(scale_factor=upscale_factor, mode=mode)
    conv = conv_block(
        in_nc,
        out_nc,
        kernel_size,
        stride,
        bias=bias,
        pad_type=pad_type,
        norm_type=norm_type,
        act_type=act_type,
    )
    return sequential(upsample, conv)

</document_content>
</document>
</documents>
